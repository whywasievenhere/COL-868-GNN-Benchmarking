{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":" Protein_Test_Pairwise_Node.ipynb","provenance":[{"file_id":"1YQGWx_xUbitZv1NwDvCz9jfv6cT_EE5z","timestamp":1617295694264},{"file_id":"1LkgsPP5TzbnRBwTYHxOex5O0NPy4dSsg","timestamp":1617259568548},{"file_id":"1o8j-NtFBoeKQlPwufEPUdzqf_8yI1yb5","timestamp":1617045195624}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTS5Y9kIKcml","executionInfo":{"status":"ok","timestamp":1617338653438,"user_tz":-330,"elapsed":23331,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"4cd3a026-e55a-4619-f375-9a289815dbec"},"source":["!pip install --no-cache-dir torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","!pip install --no-cache-dir torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","!pip install --no-cache-dir torch-cluster -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","!pip install --no-cache-dir torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","!pip install --no-cache-dir torch-geometric\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","Collecting torch-scatter\n","\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_scatter-2.0.6-cp37-cp37m-linux_x86_64.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 4.4MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.6\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","Collecting torch-sparse\n","\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_sparse-0.6.9-cp37-cp37m-linux_x86_64.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.9\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","Collecting torch-cluster\n","\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 881kB/s \n","\u001b[?25hInstalling collected packages: torch-cluster\n","Successfully installed torch-cluster-1.5.9\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","Collecting torch-spline-conv\n","\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (386kB)\n","\u001b[K     |████████████████████████████████| 389kB 6.1MB/s \n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n","Collecting torch-geometric\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/5c/3e95b76321fb14f24cc2ace392075717f645c4632e796ee0db1bc7d17231/torch_geometric-1.6.3.tar.gz (186kB)\n","\u001b[K     |████████████████████████████████| 194kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.51.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Collecting rdflib\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n","\u001b[K     |████████████████████████████████| 235kB 13.2MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.10.0)\n","Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Collecting ase\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/36/de17e79f29e06d9a92746d0dd9ec4636487ab03f6af10e78586aae533f7a/ase-3.21.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 15.1MB/s \n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-geometric) (3.7.4.3)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (54.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n","Collecting isodate\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 55.7MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (2.4.7)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric) (3.2.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (1.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-1.6.3-cp37-none-any.whl size=322719 sha256=0b32c732f118aa40ec169241fd602d5f3ee31a6c153ad5572bb80d1ab67bfcc6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-z1ebyx6l/wheels/6d/47/1e/0af8ce3e21783c3e584c22502011a3367c091694eebc50a971\n","Successfully built torch-geometric\n","Installing collected packages: isodate, rdflib, ase, torch-geometric\n","Successfully installed ase-3.21.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.3\n","--2021-04-02 04:44:11--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.204.190.140, 34.196.154.11, 52.204.244.158, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.204.190.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14746350 (14M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  14.06M  17.6MB/s    in 0.8s    \n","\n","2021-04-02 04:44:12 (17.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14746350/14746350]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHYuRHk8KVJ7","executionInfo":{"status":"ok","timestamp":1617338681193,"user_tz":-330,"elapsed":20028,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"d131007b-9ac7-4415-b150-1d7f5d9c3ff2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tKGOHFvSK1Lk","executionInfo":{"status":"ok","timestamp":1617338723775,"user_tz":-330,"elapsed":10866,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}}},"source":["import torch\n","import torch.nn as nn\n","import networkx as nx\n","import numpy as np\n","import pickle as pkl\n","import scipy.sparse as sp\n","import torch.utils.data\n","import torch.nn.functional as F\n","from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n","import itertools\n","from collections import Counter\n","from random import shuffle\n","import json\n","\n","from networkx.readwrite import json_graph\n","from argparse import ArgumentParser\n","import matplotlib.pyplot as plt\n","\n","import pdb\n","import time\n","import random\n","import pickle\n","import os.path\n","import torch_geometric as tg\n","import torch_geometric.datasets\n","import time\n","\n","from torch_geometric.data import Data, DataLoader"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKBV1t9Gx9Ta","executionInfo":{"status":"ok","timestamp":1617338723776,"user_tz":-330,"elapsed":6836,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}}},"source":["class GATLayer(torch.nn.Module):\n","    \"\"\"\n","    Implementation #3 was inspired by PyTorch Geometric: https://github.com/rusty1s/pytorch_geometric\n","\n","    But, it's hopefully much more readable! (and of similar performance)\n","\n","    \"\"\"\n","    \n","    # We'll use these constants in many functions so just extracting them here as member fields\n","    src_nodes_dim = 0  # position of source nodes in edge index\n","    trg_nodes_dim = 1  # position of target nodes in edge index\n","\n","    # These may change in the inductive setting - leaving it like this for now (not future proof)\n","    nodes_dim = 0      # node dimension (axis is maybe a more familiar term nodes_dim is the position of \"N\" in tensor)\n","    head_dim = 1       # attention head dim\n","\n","    def __init__(self, num_in_features, num_out_features, num_of_heads, concat=True, activation=nn.ELU(),\n","                 dropout_prob=0.6, add_skip_connection=True, bias=True, log_attention_weights=False):\n","\n","        super().__init__()\n","\n","        self.num_of_heads = num_of_heads\n","        self.num_out_features = num_out_features\n","        self.concat = concat  # whether we should concatenate or average the attention heads\n","        self.add_skip_connection = add_skip_connection\n","\n","        #\n","        # Trainable weights: linear projection matrix (denoted as \"W\" in the paper), attention target/source\n","        # (denoted as \"a\" in the paper) and bias (not mentioned in the paper but present in the official GAT repo)\n","        #\n","\n","        # You can treat this one matrix as num_of_heads independent W matrices\n","        self.linear_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n","\n","        # After we concatenate target node (node i) and source node (node j) we apply the \"additive\" scoring function\n","        # which gives us un-normalized score \"e\". Here we split the \"a\" vector - but the semantics remain the same.\n","        # Basically instead of doing [x, y] (concatenation, x/y are node feature vectors) and dot product with \"a\"\n","        # we instead do a dot product between x and \"a_left\" and y and \"a_right\" and we sum them up\n","        self.scoring_fn_target = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n","        self.scoring_fn_source = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n","\n","        # Bias is definitely not crucial to GAT - feel free to experiment (I pinged the main author, Petar, on this one)\n","        if bias and concat:\n","            self.bias = nn.Parameter(torch.Tensor(num_of_heads * num_out_features))\n","        elif bias and not concat:\n","            self.bias = nn.Parameter(torch.Tensor(num_out_features))\n","        else:\n","            self.register_parameter('bias', None)\n","\n","        if add_skip_connection:\n","            self.skip_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n","        else:\n","            self.register_parameter('skip_proj', None)\n","\n","        #\n","        # End of trainable weights\n","        #\n","\n","        self.leakyReLU = nn.LeakyReLU(0.2)  # using 0.2 as in the paper, no need to expose every setting\n","        self.activation = activation\n","        # Probably not the nicest design but I use the same module in 3 locations, before/after features projection\n","        # and for attention coefficients. Functionality-wise it's the same as using independent modules.\n","        self.dropout = nn.Dropout(p=dropout_prob)\n","\n","        self.log_attention_weights = log_attention_weights  # whether we should log the attention weights\n","        self.attention_weights = None  # for later visualization purposes, I cache the weights here\n","\n","        self.init_params()\n","        \n","    def forward(self, data):\n","        #\n","        # Step 1: Linear Projection + regularization\n","        #\n","\n","        in_nodes_features, edge_index = data  # unpack data\n","        num_of_nodes = in_nodes_features.shape[self.nodes_dim]\n","        assert edge_index.shape[0] == 2, f'Expected edge index with shape=(2,E) got {edge_index.shape}'\n","\n","        # shape = (N, FIN) where N - number of nodes in the graph, FIN - number of input features per node\n","        # We apply the dropout to all of the input node features (as mentioned in the paper)\n","        in_nodes_features = self.dropout(in_nodes_features)\n","\n","        # shape = (N, FIN) * (FIN, NH*FOUT) -> (N, NH, FOUT) where NH - number of heads, FOUT - num of output features\n","        # We project the input node features into NH independent output features (one for each attention head)\n","        nodes_features_proj = self.linear_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n","\n","        nodes_features_proj = self.dropout(nodes_features_proj)  # in the official GAT imp they did dropout here as well\n","\n","        #\n","        # Step 2: Edge attention calculation\n","        #\n","\n","        # Apply the scoring function (* represents element-wise (a.k.a. Hadamard) product)\n","        # shape = (N, NH, FOUT) * (1, NH, FOUT) -> (N, NH, 1) -> (N, NH) because sum squeezes the last dimension\n","        # Optimization note: torch.sum() is as performant as .sum() in my experiments\n","        scores_source = (nodes_features_proj * self.scoring_fn_source).sum(dim=-1)\n","        scores_target = (nodes_features_proj * self.scoring_fn_target).sum(dim=-1)\n","\n","        # We simply copy (lift) the scores for source/target nodes based on the edge index. Instead of preparing all\n","        # the possible combinations of scores we just prepare those that will actually be used and those are defined\n","        # by the edge index.\n","        # scores shape = (E, NH), nodes_features_proj_lifted shape = (E, NH, FOUT), E - number of edges in the graph\n","        scores_source_lifted, scores_target_lifted, nodes_features_proj_lifted = self.lift(scores_source, scores_target, nodes_features_proj, edge_index)\n","        scores_per_edge = self.leakyReLU(scores_source_lifted + scores_target_lifted)\n","\n","        # shape = (E, NH, 1)\n","        attentions_per_edge = self.neighborhood_aware_softmax(scores_per_edge, edge_index[self.trg_nodes_dim], num_of_nodes)\n","        # Add stochasticity to neighborhood aggregation\n","        attentions_per_edge = self.dropout(attentions_per_edge)\n","\n","        #\n","        # Step 3: Neighborhood aggregation\n","        #\n","\n","        # Element-wise (aka Hadamard) product. Operator * does the same thing as torch.mul\n","        # shape = (E, NH, FOUT) * (E, NH, 1) -> (E, NH, FOUT), 1 gets broadcast into FOUT\n","        nodes_features_proj_lifted_weighted = nodes_features_proj_lifted * attentions_per_edge\n","\n","        # This part sums up weighted and projected neighborhood feature vectors for every target node\n","        # shape = (N, NH, FOUT)\n","        out_nodes_features = self.aggregate_neighbors(nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes)\n","\n","        #\n","        # Step 4: Residual/skip connections, concat and bias\n","        #\n","\n","        out_nodes_features = self.skip_concat_bias(attentions_per_edge, in_nodes_features, out_nodes_features)\n","        return (out_nodes_features, edge_index)\n","\n","    #\n","    # Helper functions (without comments there is very little code so don't be scared!)\n","    #\n","\n","    def neighborhood_aware_softmax(self, scores_per_edge, trg_index, num_of_nodes):\n","        \"\"\"\n","        As the fn name suggest it does softmax over the neighborhoods. Example: say we have 5 nodes in a graph.\n","        Two of them 1, 2 are connected to node 3. If we want to calculate the representation for node 3 we should take\n","        into account feature vectors of 1, 2 and 3 itself. Since we have scores for edges 1-3, 2-3 and 3-3\n","        in scores_per_edge variable, this function will calculate attention scores like this: 1-3/(1-3+2-3+3-3)\n","        (where 1-3 is overloaded notation it represents the edge 1-3 and its (exp) score) and similarly for 2-3 and 3-3\n","         i.e. for this neighborhood we don't care about other edge scores that include nodes 4 and 5.\n","\n","        Note:\n","        Subtracting the max value from logits doesn't change the end result but it improves the numerical stability\n","        and it's a fairly common \"trick\" used in pretty much every deep learning framework.\n","        Check out this link for more details:\n","\n","        https://stats.stackexchange.com/questions/338285/how-does-the-subtraction-of-the-logit-maximum-improve-learning\n","\n","        \"\"\"\n","        # Calculate the numerator. Make logits <= 0 so that e^logit <= 1 (this will improve the numerical stability)\n","        scores_per_edge = scores_per_edge - scores_per_edge.max()\n","        exp_scores_per_edge = scores_per_edge.exp()  # softmax\n","\n","        # Calculate the denominator. shape = (E, NH)\n","        neigborhood_aware_denominator = self.sum_edge_scores_neighborhood_aware(exp_scores_per_edge, trg_index, num_of_nodes)\n","\n","        # 1e-16 is theoretically not needed but is only there for numerical stability (avoid div by 0) - due to the\n","        # possibility of the computer rounding a very small number all the way to 0.\n","        attentions_per_edge = exp_scores_per_edge / (neigborhood_aware_denominator + 1e-16)\n","\n","        # shape = (E, NH) -> (E, NH, 1) so that we can do element-wise multiplication with projected node features\n","        return attentions_per_edge.unsqueeze(-1)\n","\n","    def sum_edge_scores_neighborhood_aware(self, exp_scores_per_edge, trg_index, num_of_nodes):\n","        # The shape must be the same as in exp_scores_per_edge (required by scatter_add_) i.e. from E -> (E, NH)\n","        trg_index_broadcasted = self.explicit_broadcast(trg_index, exp_scores_per_edge)\n","\n","        # shape = (N, NH), where N is the number of nodes and NH the number of attention heads\n","        size = list(exp_scores_per_edge.shape)  # convert to list otherwise assignment is not possible\n","        size[self.nodes_dim] = num_of_nodes\n","        neighborhood_sums = torch.zeros(size, dtype=exp_scores_per_edge.dtype, device=exp_scores_per_edge.device)\n","\n","        # position i will contain a sum of exp scores of all the nodes that point to the node i (as dictated by the\n","        # target index)\n","        neighborhood_sums.scatter_add_(self.nodes_dim, trg_index_broadcasted, exp_scores_per_edge)\n","\n","        # Expand again so that we can use it as a softmax denominator. e.g. node i's sum will be copied to\n","        # all the locations where the source nodes pointed to i (as dictated by the target index)\n","        # shape = (N, NH) -> (E, NH)\n","        return neighborhood_sums.index_select(self.nodes_dim, trg_index)\n","\n","    def aggregate_neighbors(self, nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes):\n","        size = list(nodes_features_proj_lifted_weighted.shape)  # convert to list otherwise assignment is not possible\n","        size[self.nodes_dim] = num_of_nodes  # shape = (N, NH, FOUT)\n","        out_nodes_features = torch.zeros(size, dtype=in_nodes_features.dtype, device=in_nodes_features.device)\n","\n","        # shape = (E) -> (E, NH, FOUT)\n","        trg_index_broadcasted = self.explicit_broadcast(edge_index[self.trg_nodes_dim], nodes_features_proj_lifted_weighted)\n","        # aggregation step - we accumulate projected, weighted node features for all the attention heads\n","        # shape = (E, NH, FOUT) -> (N, NH, FOUT)\n","        out_nodes_features.scatter_add_(self.nodes_dim, trg_index_broadcasted, nodes_features_proj_lifted_weighted)\n","\n","        return out_nodes_features\n","\n","    def lift(self, scores_source, scores_target, nodes_features_matrix_proj, edge_index):\n","        \"\"\"\n","        Lifts i.e. duplicates certain vectors depending on the edge index.\n","        One of the tensor dims goes from N -> E (that's where the \"lift\" comes from).\n","\n","        \"\"\"\n","        src_nodes_index = edge_index[self.src_nodes_dim]\n","        trg_nodes_index = edge_index[self.trg_nodes_dim]\n","\n","        # Using index_select is faster than \"normal\" indexing (scores_source[src_nodes_index]) in PyTorch!\n","        scores_source = scores_source.index_select(self.nodes_dim, src_nodes_index)\n","        scores_target = scores_target.index_select(self.nodes_dim, trg_nodes_index)\n","        nodes_features_matrix_proj_lifted = nodes_features_matrix_proj.index_select(self.nodes_dim, src_nodes_index)\n","\n","        return scores_source, scores_target, nodes_features_matrix_proj_lifted\n","\n","    def explicit_broadcast(self, this, other):\n","        # Append singleton dimensions until this.dim() == other.dim()\n","        for _ in range(this.dim(), other.dim()):\n","            this = this.unsqueeze(-1)\n","\n","        # Explicitly expand so that shapes are the same\n","        return this.expand_as(other)\n","\n","    def init_params(self):\n","        \"\"\"\n","        The reason we're using Glorot (aka Xavier uniform) initialization is because it's a default TF initialization:\n","            https://stackoverflow.com/questions/37350131/what-is-the-default-variable-initializer-in-tensorflow\n","\n","        The original repo was developed in TensorFlow (TF) and they used the default initialization.\n","        Feel free to experiment - there may be better initializations depending on your problem.\n","\n","        \"\"\"\n","        nn.init.xavier_uniform_(self.linear_proj.weight)\n","        nn.init.xavier_uniform_(self.scoring_fn_target)\n","        nn.init.xavier_uniform_(self.scoring_fn_source)\n","\n","        if self.bias is not None:\n","            torch.nn.init.zeros_(self.bias)\n","\n","    def skip_concat_bias(self, attention_coefficients, in_nodes_features, out_nodes_features):\n","        if self.log_attention_weights:  # potentially log for later visualization in playground.py\n","            self.attention_weights = attention_coefficients\n","\n","        if self.add_skip_connection:  # add skip or residual connection\n","            if out_nodes_features.shape[-1] == in_nodes_features.shape[-1]:  # if FIN == FOUT\n","                # unsqueeze does this: (N, FIN) -> (N, 1, FIN), out features are (N, NH, FOUT) so 1 gets broadcast to NH\n","                # thus we're basically copying input vectors NH times and adding to processed vectors\n","                out_nodes_features += in_nodes_features.unsqueeze(1)\n","            else:\n","                # FIN != FOUT so we need to project input feature vectors into dimension that can be added to output\n","                # feature vectors. skip_proj adds lots of additional capacity which may cause overfitting.\n","                out_nodes_features += self.skip_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n","\n","        if self.concat:\n","            # shape = (N, NH, FOUT) -> (N, NH*FOUT)\n","            out_nodes_features = out_nodes_features.view(-1, self.num_of_heads * self.num_out_features)\n","        else:\n","            # shape = (N, NH, FOUT) -> (N, FOUT)\n","            out_nodes_features = out_nodes_features.mean(dim=self.head_dim)\n","\n","        if self.bias is not None:\n","            out_nodes_features += self.bias\n","\n","        return out_nodes_features if self.activation is None else self.activation(out_nodes_features)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNHMVkykycWL","executionInfo":{"status":"ok","timestamp":1617338726193,"user_tz":-330,"elapsed":1093,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}}},"source":["class GAT1(torch.nn.Module):\n","    \"\"\"\n","    The most interesting and hardest implementation is implementation #3.\n","    Imp1 and imp2 differ in subtle details but are basically the same thing.\n","\n","    So I'll focus on imp #3 in this notebook.\n","\n","    \"\"\"\n","\n","    def __init__(self, num_of_layers, num_heads_per_layer, num_features_per_layer, add_skip_connection=True, bias=True,dropout=0.6, log_attention_weights=False):\n","        super().__init__()\n","        assert num_of_layers == len(num_heads_per_layer) == len(num_features_per_layer) - 1, f'Enter valid arch params.'\n","\n","        num_heads_per_layer = [1] + num_heads_per_layer  # trick - so that I can nicely create GAT layers below\n","        self.lin1 = nn.Linear(128, 256)\n","        self.lin2 = nn.Linear(256, 1)\n","        gat_layers = []  # collect GAT layers\n","        for i in range(num_of_layers):\n","            layer = GATLayer(\n","                num_in_features=num_features_per_layer[i] * num_heads_per_layer[i],  # consequence of concatenation\n","                num_out_features=num_features_per_layer[i+1],\n","                num_of_heads=num_heads_per_layer[i+1],\n","                concat=True if i < num_of_layers - 1 else False,  # last GAT layer does mean avg, the others do concat\n","                activation=nn.ELU() if i < num_of_layers - 1 else None,  # last layer just outputs raw scores\n","                dropout_prob=dropout,\n","                add_skip_connection=add_skip_connection,\n","                bias=bias,\n","                log_attention_weights=log_attention_weights\n","            )\n","            gat_layers.append(layer)\n","\n","        self.gat_net = nn.Sequential(\n","            *gat_layers,\n","        )\n","\n","    # data is just a (in_nodes_features, edge_index) tuple, I had to do it like this because of the nn.Sequential:\n","    # https://discuss.pytorch.org/t/forward-takes-2-positional-arguments-but-3-were-given-for-nn-sqeuential-with-linear-layers/65698\n","    def forward(self, data):\n","        return self.gat_net(data)\n","\n","    def decode(self, z, pos_edge_index, neg_edge_index):\n","        z = (z - torch.mean(z))/(torch.std(z))\n","        edge_list = torch.cat([pos_edge_index, neg_edge_index], dim=-1)\n","        #logits = (z[edge_list[0]] * z[edge_list[1]]).sum(dim=-1)\n","        logits = torch.cat([z[edge_list[0]], z[edge_list[1]]], dim=-1)\n","        logits = self.lin1(logits)\n","        logits = torch.tanh(logits)\n","        logits = self.lin2(logits)\n","        return logits"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oateWoBK322","executionInfo":{"status":"ok","timestamp":1617338728758,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}}},"source":["def Graph_load_batch(min_num_nodes = 20, max_num_nodes = 1000, name = 'ENZYMES',node_attributes = True,graph_labels=True):\n","    '''\n","    load many graphs, e.g. enzymes\n","    :return: a list of graphs\n","    '''\n","    print('Loading graph dataset: '+str(name))\n","    G = nx.Graph()\n","    # load data\n","    path = '/content/drive/My Drive/data/'+name+'/'\n","    data_adj = np.loadtxt(path+name+'_A.txt', delimiter=',').astype(int)\n","    if node_attributes:\n","        data_node_att = np.loadtxt(path+name+'_node_attributes.txt', delimiter=',')\n","    data_node_label = np.loadtxt(path+name+'_node_labels.txt', delimiter=',').astype(int)\n","    data_graph_indicator = np.loadtxt(path+name+'_graph_indicator.txt', delimiter=',').astype(int)\n","    if graph_labels:\n","        data_graph_labels = np.loadtxt(path+name+'_graph_labels.txt', delimiter=',').astype(int)\n","\n","    data_node_att = (data_node_att-np.mean(data_node_att,axis=-1,keepdims=True))/np.std(data_node_att,axis=-1,keepdims=True)\n","\n","    data_tuple = list(map(tuple, data_adj))\n","\n","    # add edges\n","    G.add_edges_from(data_tuple)\n","    # add node attributes\n","    for i in range(data_node_label.shape[0]):\n","        if node_attributes:\n","            G.add_node(i+1, feature = data_node_att[i])\n","        G.add_node(i+1, label = data_node_label[i])\n","    G.remove_nodes_from(list(nx.isolates(G)))\n","\n","    # split into graphs\n","    graph_num = data_graph_indicator.max()\n","    node_list = np.arange(data_graph_indicator.shape[0])+1\n","    graphs = []\n","    max_nodes = 0\n","    for i in range(graph_num):\n","        # find the nodes for each graph\n","        nodes = node_list[data_graph_indicator==i+1]\n","        G_sub = G.subgraph(nodes)\n","        if graph_labels:\n","            G_sub.graph['label'] = data_graph_labels[i]\n","        if G_sub.number_of_nodes()>=min_num_nodes and G_sub.number_of_nodes()<=max_num_nodes:\n","            graphs.append(G_sub)\n","            if G_sub.number_of_nodes() > max_nodes:\n","                max_nodes = G_sub.number_of_nodes()\n","    print('Loaded')\n","    return graphs, data_node_att, data_node_label"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"51-U5OuzLha9","executionInfo":{"status":"ok","timestamp":1617338732449,"user_tz":-330,"elapsed":950,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}}},"source":["def nx_to_tg_data(graphs, features, edge_labels=None):\n","    data_list = []\n","    for i in range(len(graphs)):\n","        feature = features[i]\n","        graph = graphs[i].copy()\n","        graph.remove_edges_from(nx.selfloop_edges(graph))\n","\n","        # relabel graphs\n","        keys = list(graph.nodes)\n","        vals = range(graph.number_of_nodes())\n","        mapping = dict(zip(keys, vals))\n","        nx.relabel_nodes(graph, mapping, copy=False)\n","\n","        x = np.zeros(feature.shape)\n","        graph_nodes = list(graph.nodes)\n","        for m in range(feature.shape[0]):\n","            x[graph_nodes[m]] = feature[m]\n","        x = torch.from_numpy(x).float()\n","\n","        # get edges\n","        edge_index = np.array(list(graph.edges))\n","        edge_index = np.concatenate((edge_index, edge_index[:,::-1]), axis=0)\n","        edge_index = torch.from_numpy(edge_index).long().permute(1,0)\n","\n","        data = Data(x=x, edge_index=edge_index)\n","        # get edge_labels\n","        \n","        edge_label = edge_labels[i]\n","        mask_link_positive = np.stack(np.nonzero(edge_label==1))\n","        data.mask_link_positive =  mask_link_positive\n","        mask_link_negative = np.stack(np.nonzero(edge_label==2))\n","        data.mask_link_negative =  mask_link_negative\n","        n = graph.number_of_nodes()\n","       # print(data.mask_link_negative.shape,data.mask_link_positive.shape,n)\n","        \n","        data_list.append(data)\n","    return data_list"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RRUVP53yLjmc","executionInfo":{"status":"ok","timestamp":1617338752016,"user_tz":-330,"elapsed":17257,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"731d1b67-2e74-4d3a-bc58-8840d954629b"},"source":["import math\n","\n","graphs_all, features_all, labels_all = Graph_load_batch(name='PROTEINS_full')\n","#Normalised node features\n","graphs = []\n","features = []\n","edge_labels = []\n","for graph in graphs_all:\n","    n = graph.number_of_nodes()\n","    label = np.zeros((n, n),dtype=int)\n","    for i,u in enumerate(graph.nodes()):\n","        for j,v in enumerate(graph.nodes()):\n","            if labels_all[u-1] == labels_all[v-1] and u>v:\n","                label[i,j] = 1\n","            if labels_all[u-1] != labels_all[v-1] and u>v:\n","                label[i,j] = 2\n","\n","    graphs.append(graph)\n","    edge_labels.append(label)\n","    idx = [node-1 for node in graph.nodes()]\n","    feature = features_all[idx,:]\n","    features.append(feature)\n","\n","print('final num', len(graphs))\n","dataset_1 = nx_to_tg_data(graphs, features, edge_labels)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Loading graph dataset: PROTEINS_full\n","Loaded\n","final num 739\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uYimOud9aYIQ","executionInfo":{"status":"ok","timestamp":1617338898901,"user_tz":-330,"elapsed":951,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}}},"source":["def get_link_labels(pos_edge_index, neg_edge_index):\n","    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n","    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n","    link_labels[:pos_edge_index.size(1)] = 1.\n","    return link_labels\n","\n","\n","def train_or_test(model, batch, loss_func, optimizer, phase):\n","    (node_features, edge_index, mask_link_positive, mask_link_negative) = batch.x, batch.edge_index, batch.mask_link_positive, batch.mask_link_negative\n","    edge_index = edge_index.to(device)\n","    node_features = node_features.to(device)\n","    mask_link_positive = torch.tensor(mask_link_positive[0]).to(device)\n","    mask_link_negative = torch.tensor(mask_link_negative[0]).to(device)\n","    graph_data = (node_features, edge_index)\n","    \n","    if phase=='Train':\n","        model.train()\n","    else:\n","        model.eval()\n","    \n","    embeddings = model(graph_data)[0]\n","    unnormalized_scores = model.decode(embeddings, mask_link_positive, mask_link_negative)\n","    unnormalized_scores = unnormalized_scores.squeeze(1)\n","    batch_target = get_link_labels(mask_link_positive, mask_link_negative)\n","    loss = loss_func(unnormalized_scores, batch_target)\n","\n","    if phase=='Train':\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    #Changing to Numpy to measure metrics\n","    batch_pred = (unnormalized_scores > 0).float().cpu().numpy()\n","    batch_target = batch_target.cpu().numpy()\n","    unnormalized_scores =  unnormalized_scores.float()\n","    unnormalized_scores = unnormalized_scores.cpu()\n","    unnormalized_scores = unnormalized_scores.detach()\n","    unnormalized_scores = unnormalized_scores.numpy() \n","    #Metrics\n","    micro_f1 = f1_score(batch_target, batch_pred, average='micro')\n","    return [batch_pred, batch_target, micro_f1, loss.item(),unnormalized_scores]\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkZD4tEIOi6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617350661251,"user_tz":-330,"elapsed":7869638,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"e203cea9-9c1b-442e-9878-5ac927e69330"},"source":["import time\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","config = {\n","        'number_of_epochs': 1000,\n","        'patience_period': 20,\n","        'path': '/content/drive/My Drive/data/',\n","        'num_of_layers': 2,  # PPI has got 42% of nodes with all 0 features - that's why 3 layers are useful\n","        'num_heads_per_layer': [1, 1],  # other values may give even better results from the reported ones\n","        'num_features_per_layer': [29, 64, 64],  # 64 would also give ~0.975 uF1!\n","        'add_skip_connection': True,  # skip connection is very important! (keep it otherwise micro-F1 is almost 0)\n","        'bias': True,  # bias doesn't matter that much\n","        'dropout': 0.0,  # dropout hurts the performance (best to keep it at 0)\n","}\n","\n","from sklearn.model_selection import KFold, train_test_split\n","dataset = np.empty(len(dataset_1), dtype=np.object)\n","dataset[:] = dataset_1\n","kf = KFold(n_splits=5)\n","\n","\n","val_acc_fin = []\n","val_f1_fin = []\n","val_roc_auc_fin = []\n","\n","train_acc_fin = []\n","train_f1_fin = []\n","train_roc_auc_fin = []\n","\n","begin = time.time()\n","\n","avg_test_loss, avg_test_micro_f1, avg_test_micro_recall, avg_test_micro_precision, avg_test_micro_roc_auc_score  = [0, 0, 0, 0, 0]\n","fold = 0\n","for dev_index, test_index in kf.split(dataset):\n","    fold = fold+1\n","    dev_dataset, test_dataset = dataset[dev_index], dataset[test_index]\n","    train_dataset, val_dataset = train_test_split(dev_dataset, test_size=0.2)\n","    train_dataset, test_dataset, val_dataset = list(train_dataset), list(test_dataset), list(val_dataset)\n","    \n","    train_dataloader = DataLoader(train_dataset, batch_size=1)\n","    val_dataloader = DataLoader(val_dataset, batch_size=1)\n","    test_dataloader = DataLoader(test_dataset, batch_size=1)\n","\n","    model = GAT1(\n","          num_of_layers=config['num_of_layers'],\n","          num_heads_per_layer=config['num_heads_per_layer'],\n","          num_features_per_layer=config['num_features_per_layer'],\n","          add_skip_connection=config['add_skip_connection'],\n","          bias=config['bias'],\n","          dropout=config['dropout'],\n","          log_attention_weights=False  # no need to store attentions, used only in playground.py for visualizations\n","          ).to(device)\n","    \n","    loss_func = nn.BCEWithLogitsLoss()\n","    #optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, eps=1e-3, amsgrad=True)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max', verbose=True)\n","\n","    best_val_micro_f1, best_val_loss, patience_cnt = [0, 999999, 0]\n","    \n","    train_acc_list = []\n","    train_f1_list = []\n","    train_roc_auc_list = []\n","    \n","    \n","    val_acc_list = []\n","    val_f1_list = []\n","    val_roc_auc_list = []\n","\n","\n","    for epoch in range(config['number_of_epochs']):\n","        epoch_loss = 0\n","        predictions, target, store_temp = np.array([]), np.array([]),np.array([])\n","        for batch_idx, batch in enumerate(train_dataloader):\n","            batch_pred, batch_target, micro_f1, loss, store = train_or_test(model, batch, loss_func, optimizer, 'Train')\n","            epoch_loss = epoch_loss+loss\n","            predictions = np.concatenate((predictions, batch_pred.flatten()), axis=0)\n","            store_temp = np.concatenate((store_temp,store.flatten()), axis=0)\n","            target = np.concatenate((target, batch_target.flatten()), axis=0)\n","        #epoch_loss = epoch_loss/len(train_dataloader)\n","        train_micro_f1 = f1_score(target, predictions, average='micro')\n","        train_acc = (predictions == target).sum()/(predictions.shape[0])\n","        train_acc_list.append(train_acc)\n","        train_f1_list.append(train_micro_f1)\n","        roc_auc_value = roc_auc_score(target, store_temp, average='micro')\n","        macro_roc = roc_auc_score(target, store_temp, average='macro')\n","        train_roc_auc_list.append(roc_auc_value)\n","        print(f\"Training Epoch Loss after {epoch} is {epoch_loss}\")\n","\n","        with torch.no_grad():\n","            model.eval()\n","            val_loss = 0\n","            predictions, target, store_temp = np.array([]), np.array([]),np.array([])\n","            for batch_idx, batch in enumerate(val_dataloader):\n","                batch_pred, batch_target, micro_f1, loss, store = train_or_test(model, batch, loss_func, None, 'Val')\n","                val_loss = val_loss + loss\n","                predictions = np.concatenate((predictions, batch_pred.flatten()), axis=0)\n","                store_temp = np.concatenate((store_temp,store.flatten()), axis=0)\n","                target = np.concatenate((target, batch_target.flatten()), axis=0)\n","            val_micro_f1 = f1_score(target, predictions, average='micro')\n","            val_acc = (predictions == target).sum()/(predictions.shape[0])\n","            val_acc_list.append(val_acc)\n","            val_f1_list.append(val_micro_f1)\n","            roc_auc_value = roc_auc_score(target, store_temp, average='micro')\n","            val_roc_auc_list.append(roc_auc_value)\n","            macro_roc = roc_auc_score(target, store_temp, average='macro')\n","\n","            if val_micro_f1 > best_val_micro_f1 or  best_val_loss - val_loss > 1e-5:\n","                best_val_micro_f1 = max(val_micro_f1, best_val_micro_f1)\n","                best_val_loss = min(val_loss, best_val_loss)\n","                patience_cnt = 0\n","                torch.save(model.state_dict(), config['path']+f'model_{fold}')\n","            else:\n","                patience_cnt = patience_cnt+1\n","            \n","            temp = {}\n","            temp[\"Validation Epoch Loss\"] = val_loss\n","            temp[\"Epoch\"] = epoch\n","            temp[\"Micro F1\"] = val_micro_f1\n","            temp[\"Patience Count\"] = patience_cnt\n","            temp[\"Best Val F1\"] = best_val_micro_f1\n","            temp[\"Best Val Loss\"] = best_val_loss\n","            temp[\"Micro ROC value\"] = roc_auc_value\n","            temp[\"Macro ROC value\"] = macro_roc\n","\n","\n","            print(temp)\n","\n","            if patience_cnt >= config['patience_period']:\n","                break\n","\n","        scheduler.step(val_acc_list[-1])\n","\n","    \n","    train_acc_fin.append(train_acc_list)  \n","    train_f1_fin.append(train_f1_list)\n","    train_roc_auc_fin.append(train_roc_auc_list)\n","    \n","    val_acc_fin.append(val_acc_list)  \n","    val_f1_fin.append(val_f1_list)\n","    val_roc_auc_fin.append(val_roc_auc_list)\n","\n","    with torch.no_grad():\n","        model.load_state_dict(torch.load(config['path']+f'model_{fold}'))\n","        model.eval()\n","        test_loss = 0\n","        predictions, target, store_temp = np.array([]), np.array([]),np.array([])\n","        for batch_idx, batch in enumerate(test_dataloader):\n","            batch_pred, batch_target, micro_f1, loss, store = train_or_test(model, batch, loss_func, None, 'Test')\n","            test_loss = test_loss + loss\n","            predictions = np.concatenate((predictions, batch_pred.flatten()), axis=0)\n","            target = np.concatenate((target, batch_target.flatten()), axis=0)\n","            store_temp = np.concatenate((store_temp,store.flatten()), axis=0)\n","        \n","        test_micro_f1 = f1_score(target, predictions, average='micro')\n","        test_micro_precision = precision_score(target, predictions, average='micro')\n","        test_micro_recall = recall_score(target, predictions, average='micro')\n","        test_micro_roc_auc_score = roc_auc_score(target, store_temp, average='micro')\n","        test_macro_roc_auc_score = roc_auc_score(target, store_temp, average='macro')\n","\n","        avg_test_loss = avg_test_loss + test_loss\n","        avg_test_micro_f1 = avg_test_micro_f1 + test_micro_f1\n","        avg_test_micro_recall = avg_test_micro_recall + test_micro_recall\n","        avg_test_micro_roc_auc_score = avg_test_micro_roc_auc_score + test_micro_roc_auc_score\n","        \n","\n","        temp = {}\n","        print(\"Testing stats.\\n\\n\\n\")\n","        temp[\"Micro F1\"] = test_micro_f1 \n","        temp[\"Micro Recall\"] = test_micro_recall\n","        temp[\"Micro Precision\"] = test_micro_precision\n","        temp[\"Micro ROC_AUC_Score\"] = test_micro_roc_auc_score\n","        temp[\"Macro ROC_AUC_Score\"] = test_macro_roc_auc_score\n","        print(temp)\n","        print(\"\\n\\n\\n\")\n","\n","\n","print(\"Average Statistics\")\n","average = {}\n","\n","average[\"avg_test_micro_f1\"] = avg_test_micro_f1\n","average[\"avg_test_loss\"] = avg_test_loss\n","average[\"avg_test_micro_recall\"] = avg_test_micro_recall\n","average[\"avg_test_micro_precision\"] = avg_test_micro_precision\n","average[\"avg_test_micro_roc_auc_score\"] = avg_test_micro_roc_auc_score\n","\n","\n","end = time.time()\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Training Epoch Loss after 0 is 339.85186713933945\n","{'Validation Epoch Loss': 77.97652494907379, 'Epoch': 0, 'Micro F1': 0.6188384603607836, 'Patience Count': 0, 'Best Val F1': 0.6188384603607836, 'Best Val Loss': 77.97652494907379, 'Micro ROC value': 0.6273918531015346, 'Macro ROC value': 0.6273918531015346}\n","Training Epoch Loss after 1 is 334.697776183486\n","{'Validation Epoch Loss': 81.07775840163231, 'Epoch': 1, 'Micro F1': 0.5839320877832975, 'Patience Count': 1, 'Best Val F1': 0.6188384603607836, 'Best Val Loss': 77.97652494907379, 'Micro ROC value': 0.5992903815627482, 'Macro ROC value': 0.5992903815627482}\n","Training Epoch Loss after 2 is 322.251365840435\n","{'Validation Epoch Loss': 77.99200123548508, 'Epoch': 2, 'Micro F1': 0.6131843882146119, 'Patience Count': 2, 'Best Val F1': 0.6188384603607836, 'Best Val Loss': 77.97652494907379, 'Micro ROC value': 0.6325055187185425, 'Macro ROC value': 0.6325055187185425}\n","Training Epoch Loss after 3 is 315.63717871904373\n","{'Validation Epoch Loss': 78.7126202583313, 'Epoch': 3, 'Micro F1': 0.6206545208820564, 'Patience Count': 0, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 77.97652494907379, 'Micro ROC value': 0.6361861928414835, 'Macro ROC value': 0.6361861928414835}\n","Training Epoch Loss after 4 is 313.7993026971817\n","{'Validation Epoch Loss': 78.93954220414162, 'Epoch': 4, 'Micro F1': 0.5764197211502421, 'Patience Count': 1, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 77.97652494907379, 'Micro ROC value': 0.6071634763535503, 'Macro ROC value': 0.6071634763535503}\n","Training Epoch Loss after 5 is 309.976065069437\n","{'Validation Epoch Loss': 78.60670521855354, 'Epoch': 5, 'Micro F1': 0.582839283923113, 'Patience Count': 2, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 77.97652494907379, 'Micro ROC value': 0.609605547620568, 'Macro ROC value': 0.609605547620568}\n","Training Epoch Loss after 6 is 308.5317025780678\n","{'Validation Epoch Loss': 78.53114393353462, 'Epoch': 6, 'Micro F1': 0.5936986923308397, 'Patience Count': 3, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 77.97652494907379, 'Micro ROC value': 0.6026288818612904, 'Macro ROC value': 0.6026288818612904}\n","Training Epoch Loss after 7 is 306.54997938871384\n","{'Validation Epoch Loss': 76.1871232688427, 'Epoch': 7, 'Micro F1': 0.6121813315313508, 'Patience Count': 0, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 76.1871232688427, 'Micro ROC value': 0.6193112002070191, 'Macro ROC value': 0.6193112002070191}\n","Training Epoch Loss after 8 is 304.85333105921745\n","{'Validation Epoch Loss': 77.1760570704937, 'Epoch': 8, 'Micro F1': 0.6014011118091447, 'Patience Count': 1, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 76.1871232688427, 'Micro ROC value': 0.5996443148707643, 'Macro ROC value': 0.5996443148707643}\n","Training Epoch Loss after 9 is 303.00997987389565\n","{'Validation Epoch Loss': 77.97734168171883, 'Epoch': 9, 'Micro F1': 0.605793444232688, 'Patience Count': 2, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 76.1871232688427, 'Micro ROC value': 0.6030301903500842, 'Macro ROC value': 0.6030301903500842}\n","Training Epoch Loss after 10 is 300.89498791098595\n","{'Validation Epoch Loss': 77.16370016336441, 'Epoch': 10, 'Micro F1': 0.601786496745345, 'Patience Count': 3, 'Best Val F1': 0.6206545208820564, 'Best Val Loss': 76.1871232688427, 'Micro ROC value': 0.6057860241343116, 'Macro ROC value': 0.6057860241343116}\n","Training Epoch Loss after 11 is 299.1083132326603\n","{'Validation Epoch Loss': 76.18372568488121, 'Epoch': 11, 'Micro F1': 0.6207548265503825, 'Patience Count': 0, 'Best Val F1': 0.6207548265503825, 'Best Val Loss': 76.18372568488121, 'Micro ROC value': 0.6138196061594922, 'Macro ROC value': 0.6138196061594922}\n","Training Epoch Loss after 12 is 296.74520418047905\n","{'Validation Epoch Loss': 75.20308724045753, 'Epoch': 12, 'Micro F1': 0.616431124320957, 'Patience Count': 0, 'Best Val F1': 0.6207548265503825, 'Best Val Loss': 75.20308724045753, 'Micro ROC value': 0.6305792248207907, 'Macro ROC value': 0.6305792248207907}\n","Training Epoch Loss after 13 is 293.51131668686867\n","{'Validation Epoch Loss': 73.87203800678253, 'Epoch': 13, 'Micro F1': 0.6185956150585205, 'Patience Count': 0, 'Best Val F1': 0.6207548265503825, 'Best Val Loss': 73.87203800678253, 'Micro ROC value': 0.6724926310477208, 'Macro ROC value': 0.6724926310477208}\n","Training Epoch Loss after 14 is 283.2243094444275\n","{'Validation Epoch Loss': 68.69001081585884, 'Epoch': 14, 'Micro F1': 0.6789901858822411, 'Patience Count': 0, 'Best Val F1': 0.6789901858822411, 'Best Val Loss': 68.69001081585884, 'Micro ROC value': 0.769786720975589, 'Macro ROC value': 0.769786720975589}\n","Training Epoch Loss after 15 is 266.09010648727417\n","{'Validation Epoch Loss': 67.32120588421822, 'Epoch': 15, 'Micro F1': 0.6662883207247349, 'Patience Count': 0, 'Best Val F1': 0.6789901858822411, 'Best Val Loss': 67.32120588421822, 'Micro ROC value': 0.7841254029200007, 'Macro ROC value': 0.7841254029200007}\n","Training Epoch Loss after 16 is 252.46998430788517\n","{'Validation Epoch Loss': 61.47691495716572, 'Epoch': 16, 'Micro F1': 0.6945006097528785, 'Patience Count': 0, 'Best Val F1': 0.6945006097528785, 'Best Val Loss': 61.47691495716572, 'Micro ROC value': 0.8009608184874384, 'Macro ROC value': 0.8009608184874384}\n","Training Epoch Loss after 17 is 243.3283340781927\n","{'Validation Epoch Loss': 63.948084607720375, 'Epoch': 17, 'Micro F1': 0.6815031068360953, 'Patience Count': 1, 'Best Val F1': 0.6945006097528785, 'Best Val Loss': 61.47691495716572, 'Micro ROC value': 0.8021143469990624, 'Macro ROC value': 0.8021143469990624}\n","Training Epoch Loss after 18 is 232.3930411785841\n","{'Validation Epoch Loss': 55.04917533695698, 'Epoch': 18, 'Micro F1': 0.7801194165377651, 'Patience Count': 0, 'Best Val F1': 0.7801194165377651, 'Best Val Loss': 55.04917533695698, 'Micro ROC value': 0.8518902953607768, 'Macro ROC value': 0.8518902953607768}\n","Training Epoch Loss after 19 is 249.91952116787434\n","{'Validation Epoch Loss': 61.88640823960304, 'Epoch': 19, 'Micro F1': 0.7359690847371728, 'Patience Count': 1, 'Best Val F1': 0.7801194165377651, 'Best Val Loss': 55.04917533695698, 'Micro ROC value': 0.82968115963216, 'Macro ROC value': 0.82968115963216}\n","Training Epoch Loss after 20 is 236.93431420624256\n","{'Validation Epoch Loss': 55.180834010243416, 'Epoch': 20, 'Micro F1': 0.77049535162416, 'Patience Count': 2, 'Best Val F1': 0.7801194165377651, 'Best Val Loss': 55.04917533695698, 'Micro ROC value': 0.8359235684815571, 'Macro ROC value': 0.8359235684815571}\n","Training Epoch Loss after 21 is 218.82695104926825\n","{'Validation Epoch Loss': 52.71028807759285, 'Epoch': 21, 'Micro F1': 0.7602905696834036, 'Patience Count': 0, 'Best Val F1': 0.7801194165377651, 'Best Val Loss': 52.71028807759285, 'Micro ROC value': 0.8482759904824958, 'Macro ROC value': 0.8482759904824958}\n","Training Epoch Loss after 22 is 226.97374802827835\n","{'Validation Epoch Loss': 56.91806147992611, 'Epoch': 22, 'Micro F1': 0.7110510450266866, 'Patience Count': 1, 'Best Val F1': 0.7801194165377651, 'Best Val Loss': 52.71028807759285, 'Micro ROC value': 0.83444616840919, 'Macro ROC value': 0.83444616840919}\n","Training Epoch Loss after 23 is 236.69832273572683\n","{'Validation Epoch Loss': 48.78031913936138, 'Epoch': 23, 'Micro F1': 0.7993094746622601, 'Patience Count': 0, 'Best Val F1': 0.7993094746622601, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.8729352617033599, 'Macro ROC value': 0.8729352617033599}\n","Training Epoch Loss after 24 is 206.96655450761318\n","{'Validation Epoch Loss': 72.36605796217918, 'Epoch': 24, 'Micro F1': 0.6099587690910723, 'Patience Count': 1, 'Best Val F1': 0.7993094746622601, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.6910690254864333, 'Macro ROC value': 0.6910690254864333}\n","Training Epoch Loss after 25 is 242.50205074995756\n","{'Validation Epoch Loss': 50.805409491062164, 'Epoch': 25, 'Micro F1': 0.7967965537084062, 'Patience Count': 2, 'Best Val F1': 0.7993094746622601, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.875833470337896, 'Macro ROC value': 0.875833470337896}\n","Training Epoch Loss after 26 is 216.0676409676671\n","{'Validation Epoch Loss': 49.00297977775335, 'Epoch': 26, 'Micro F1': 0.801859350336024, 'Patience Count': 0, 'Best Val F1': 0.801859350336024, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.8889636964234303, 'Macro ROC value': 0.8889636964234303}\n","Training Epoch Loss after 27 is 231.7295383810997\n","{'Validation Epoch Loss': 68.28141878545284, 'Epoch': 27, 'Micro F1': 0.6316089557124078, 'Patience Count': 1, 'Best Val F1': 0.801859350336024, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.8082882443811885, 'Macro ROC value': 0.8082882443811885}\n","Training Epoch Loss after 28 is 235.6001060307026\n","{'Validation Epoch Loss': 54.681337766349316, 'Epoch': 28, 'Micro F1': 0.7640705096055876, 'Patience Count': 2, 'Best Val F1': 0.801859350336024, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.8614422659636081, 'Macro ROC value': 0.8614422659636081}\n","Training Epoch Loss after 29 is 222.34535239636898\n","{'Validation Epoch Loss': 57.88180248439312, 'Epoch': 29, 'Micro F1': 0.711452267699991, 'Patience Count': 3, 'Best Val F1': 0.801859350336024, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.829974173239637, 'Macro ROC value': 0.829974173239637}\n","Training Epoch Loss after 30 is 220.34070966392756\n","{'Validation Epoch Loss': 53.902463771402836, 'Epoch': 30, 'Micro F1': 0.7062680484212416, 'Patience Count': 4, 'Best Val F1': 0.801859350336024, 'Best Val Loss': 48.78031913936138, 'Micro ROC value': 0.8353430893352646, 'Macro ROC value': 0.8353430893352646}\n","Training Epoch Loss after 31 is 202.64324674755335\n","{'Validation Epoch Loss': 47.00069122761488, 'Epoch': 31, 'Micro F1': 0.7836248356834776, 'Patience Count': 0, 'Best Val F1': 0.801859350336024, 'Best Val Loss': 47.00069122761488, 'Micro ROC value': 0.8885493382780443, 'Macro ROC value': 0.8885493382780443}\n","Training Epoch Loss after 32 is 189.47872713953257\n","{'Validation Epoch Loss': 44.86452279239893, 'Epoch': 32, 'Micro F1': 0.8140966418718093, 'Patience Count': 0, 'Best Val F1': 0.8140966418718093, 'Best Val Loss': 44.86452279239893, 'Micro ROC value': 0.899337217407085, 'Macro ROC value': 0.899337217407085}\n","Training Epoch Loss after 33 is 183.6459819972515\n","{'Validation Epoch Loss': 43.5703439116478, 'Epoch': 33, 'Micro F1': 0.8202522423596117, 'Patience Count': 0, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.89752124270868, 'Macro ROC value': 0.89752124270868}\n","Training Epoch Loss after 34 is 280.88772758468986\n","{'Validation Epoch Loss': 76.4069082736969, 'Epoch': 34, 'Micro F1': 0.6119596032118931, 'Patience Count': 1, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.6835596286313771, 'Macro ROC value': 0.6835596286313771}\n","Training Epoch Loss after 35 is 295.37441393733025\n","{'Validation Epoch Loss': 77.76173061132431, 'Epoch': 35, 'Micro F1': 0.6060310102892499, 'Patience Count': 2, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.6997738942454722, 'Macro ROC value': 0.6997738942454722}\n","Training Epoch Loss after 36 is 287.81444588303566\n","{'Validation Epoch Loss': 74.37591278553009, 'Epoch': 36, 'Micro F1': 0.6210874190295691, 'Patience Count': 3, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.7375996478545847, 'Macro ROC value': 0.7375996478545847}\n","Training Epoch Loss after 37 is 274.514152854681\n","{'Validation Epoch Loss': 71.77004435658455, 'Epoch': 37, 'Micro F1': 0.638313597753153, 'Patience Count': 4, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.7780044021257552, 'Macro ROC value': 0.7780044021257552}\n","Training Epoch Loss after 38 is 264.5128974467516\n","{'Validation Epoch Loss': 65.28121829032898, 'Epoch': 38, 'Micro F1': 0.669408354934247, 'Patience Count': 5, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.7534833072879035, 'Macro ROC value': 0.7534833072879035}\n","Training Epoch Loss after 39 is 261.0023953318596\n","{'Validation Epoch Loss': 63.74755024909973, 'Epoch': 39, 'Micro F1': 0.6922252548555863, 'Patience Count': 6, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.81719024203766, 'Macro ROC value': 0.81719024203766}\n","Training Epoch Loss after 40 is 252.37552218139172\n","{'Validation Epoch Loss': 62.44679248332977, 'Epoch': 40, 'Micro F1': 0.7188854456475259, 'Patience Count': 7, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8220759076972368, 'Macro ROC value': 0.8220759076972368}\n","Training Epoch Loss after 41 is 254.6217525601387\n","{'Validation Epoch Loss': 63.12642300128937, 'Epoch': 41, 'Micro F1': 0.6891685715944906, 'Patience Count': 8, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8163532607197949, 'Macro ROC value': 0.8163532607197949}\n","Training Epoch Loss after 42 is 247.77545580267906\n","{'Validation Epoch Loss': 67.1496534794569, 'Epoch': 42, 'Micro F1': 0.6752049667143558, 'Patience Count': 9, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8085577488794864, 'Macro ROC value': 0.8085577488794864}\n","Training Epoch Loss after 43 is 243.1651150584221\n","{'Validation Epoch Loss': 61.41362965106964, 'Epoch': 43, 'Micro F1': 0.732727627876529, 'Patience Count': 10, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8406966282090491, 'Macro ROC value': 0.8406966282090491}\n","Training Epoch Loss after 44 is 238.52788172662258\n","{'Validation Epoch Loss': 59.725660890340805, 'Epoch': 44, 'Micro F1': 0.7285200690525336, 'Patience Count': 11, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.818984906701349, 'Macro ROC value': 0.818984906701349}\n","Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n","Training Epoch Loss after 45 is 228.08043551445007\n","{'Validation Epoch Loss': 57.40912801027298, 'Epoch': 45, 'Micro F1': 0.762328358524134, 'Patience Count': 12, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8360968712997285, 'Macro ROC value': 0.8360968712997285}\n","Training Epoch Loss after 46 is 226.1962053924799\n","{'Validation Epoch Loss': 57.2218824326992, 'Epoch': 46, 'Micro F1': 0.7602166602435844, 'Patience Count': 13, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.836017729096162, 'Macro ROC value': 0.836017729096162}\n","Training Epoch Loss after 47 is 225.50562244653702\n","{'Validation Epoch Loss': 56.87370482087135, 'Epoch': 47, 'Micro F1': 0.7640863473426915, 'Patience Count': 14, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8397748740017319, 'Macro ROC value': 0.8397748740017319}\n","Training Epoch Loss after 48 is 224.34491488337517\n","{'Validation Epoch Loss': 56.65458744764328, 'Epoch': 48, 'Micro F1': 0.7765295294608306, 'Patience Count': 15, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8478198902507195, 'Macro ROC value': 0.8478198902507195}\n","Training Epoch Loss after 49 is 223.24898120760918\n","{'Validation Epoch Loss': 56.511753514409065, 'Epoch': 49, 'Micro F1': 0.7708385025947494, 'Patience Count': 16, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8443978282592355, 'Macro ROC value': 0.8443978282592355}\n","Training Epoch Loss after 50 is 222.79084260761738\n","{'Validation Epoch Loss': 56.31062276661396, 'Epoch': 50, 'Micro F1': 0.7801246957834665, 'Patience Count': 17, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.859971530328643, 'Macro ROC value': 0.859971530328643}\n","Training Epoch Loss after 51 is 221.2771376669407\n","{'Validation Epoch Loss': 56.25129073858261, 'Epoch': 51, 'Micro F1': 0.7813336430490812, 'Patience Count': 18, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8516461405153748, 'Macro ROC value': 0.8516461405153748}\n","Training Epoch Loss after 52 is 220.87835600972176\n","{'Validation Epoch Loss': 55.95330063998699, 'Epoch': 52, 'Micro F1': 0.7835562054893597, 'Patience Count': 19, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8544381348783594, 'Macro ROC value': 0.8544381348783594}\n","Training Epoch Loss after 53 is 220.27744048833847\n","{'Validation Epoch Loss': 55.74102318286896, 'Epoch': 53, 'Micro F1': 0.7884236700260268, 'Patience Count': 20, 'Best Val F1': 0.8202522423596117, 'Best Val Loss': 43.5703439116478, 'Micro ROC value': 0.8632613138547125, 'Macro ROC value': 0.8632613138547125}\n","Testing stats.\n","\n","\n","\n","{'Micro F1': 0.7268640467847775, 'Micro Recall': 0.7268640467847775, 'Micro Precision': 0.7268640467847775, 'Micro ROC_AUC_Score': 0.8210175712130855, 'Macro ROC_AUC_Score': 0.8210175712130855}\n","\n","\n","\n","\n","Training Epoch Loss after 0 is 339.74345387518406\n","{'Validation Epoch Loss': 85.1126506626606, 'Epoch': 0, 'Micro F1': 0.5805398952046164, 'Patience Count': 0, 'Best Val F1': 0.5805398952046164, 'Best Val Loss': 85.1126506626606, 'Micro ROC value': 0.6139984648812903, 'Macro ROC value': 0.6139984648812903}\n","Training Epoch Loss after 1 is 336.16169437766075\n","{'Validation Epoch Loss': 88.11932569742203, 'Epoch': 1, 'Micro F1': 0.4894508191284738, 'Patience Count': 1, 'Best Val F1': 0.5805398952046164, 'Best Val Loss': 85.1126506626606, 'Micro ROC value': 0.5684341760776749, 'Macro ROC value': 0.5684341760776749}\n","Training Epoch Loss after 2 is 326.1376677751541\n","{'Validation Epoch Loss': 79.22991704940796, 'Epoch': 2, 'Micro F1': 0.6066293029117198, 'Patience Count': 0, 'Best Val F1': 0.6066293029117198, 'Best Val Loss': 79.22991704940796, 'Micro ROC value': 0.6168694609558152, 'Macro ROC value': 0.6168694609558152}\n","Training Epoch Loss after 3 is 313.97127294540405\n","{'Validation Epoch Loss': 78.06177917122841, 'Epoch': 3, 'Micro F1': 0.6267161902235193, 'Patience Count': 0, 'Best Val F1': 0.6267161902235193, 'Best Val Loss': 78.06177917122841, 'Micro ROC value': 0.6620759404672376, 'Macro ROC value': 0.6620759404672376}\n","Training Epoch Loss after 4 is 310.15488773584366\n","{'Validation Epoch Loss': 78.20322188735008, 'Epoch': 4, 'Micro F1': 0.6304205080586324, 'Patience Count': 0, 'Best Val F1': 0.6304205080586324, 'Best Val Loss': 78.06177917122841, 'Micro ROC value': 0.660132938368535, 'Macro ROC value': 0.660132938368535}\n","Training Epoch Loss after 5 is 307.7741893231869\n","{'Validation Epoch Loss': 78.00757113099098, 'Epoch': 5, 'Micro F1': 0.6379850102805598, 'Patience Count': 0, 'Best Val F1': 0.6379850102805598, 'Best Val Loss': 78.00757113099098, 'Micro ROC value': 0.6732621353246075, 'Macro ROC value': 0.6732621353246075}\n","Training Epoch Loss after 6 is 307.6321769952774\n","{'Validation Epoch Loss': 75.57565894722939, 'Epoch': 6, 'Micro F1': 0.6386250580354181, 'Patience Count': 0, 'Best Val F1': 0.6386250580354181, 'Best Val Loss': 75.57565894722939, 'Micro ROC value': 0.6722657974797365, 'Macro ROC value': 0.6722657974797365}\n","Training Epoch Loss after 7 is 304.7623802423477\n","{'Validation Epoch Loss': 76.05795180797577, 'Epoch': 7, 'Micro F1': 0.6461995091861776, 'Patience Count': 0, 'Best Val F1': 0.6461995091861776, 'Best Val Loss': 75.57565894722939, 'Micro ROC value': 0.6770592424605686, 'Macro ROC value': 0.6770592424605686}\n","Training Epoch Loss after 8 is 300.94772374629974\n","{'Validation Epoch Loss': 82.8525915145874, 'Epoch': 8, 'Micro F1': 0.5946773230748823, 'Patience Count': 1, 'Best Val F1': 0.6461995091861776, 'Best Val Loss': 75.57565894722939, 'Micro ROC value': 0.6507608646239064, 'Macro ROC value': 0.6507608646239064}\n","Training Epoch Loss after 9 is 314.8689187467098\n","{'Validation Epoch Loss': 75.42818742990494, 'Epoch': 9, 'Micro F1': 0.637517410625456, 'Patience Count': 0, 'Best Val F1': 0.6461995091861776, 'Best Val Loss': 75.42818742990494, 'Micro ROC value': 0.66555845918261, 'Macro ROC value': 0.66555845918261}\n","Training Epoch Loss after 10 is 301.5534346103668\n","{'Validation Epoch Loss': 76.17988315224648, 'Epoch': 10, 'Micro F1': 0.6358658884393447, 'Patience Count': 1, 'Best Val F1': 0.6461995091861776, 'Best Val Loss': 75.42818742990494, 'Micro ROC value': 0.6403309240679633, 'Macro ROC value': 0.6403309240679633}\n","Training Epoch Loss after 11 is 291.9048465192318\n","{'Validation Epoch Loss': 72.87260928750038, 'Epoch': 11, 'Micro F1': 0.6754128805465278, 'Patience Count': 0, 'Best Val F1': 0.6754128805465278, 'Best Val Loss': 72.87260928750038, 'Micro ROC value': 0.6872165501164897, 'Macro ROC value': 0.6872165501164897}\n","Training Epoch Loss after 12 is 277.1218964755535\n","{'Validation Epoch Loss': 68.17737154662609, 'Epoch': 12, 'Micro F1': 0.6683458247662002, 'Patience Count': 0, 'Best Val F1': 0.6754128805465278, 'Best Val Loss': 68.17737154662609, 'Micro ROC value': 0.7433648255434168, 'Macro ROC value': 0.7433648255434168}\n","Training Epoch Loss after 13 is 264.9598343372345\n","{'Validation Epoch Loss': 65.92840586230159, 'Epoch': 13, 'Micro F1': 0.671240963056311, 'Patience Count': 0, 'Best Val F1': 0.6754128805465278, 'Best Val Loss': 65.92840586230159, 'Micro ROC value': 0.7201473628588034, 'Macro ROC value': 0.7201473628588034}\n","Training Epoch Loss after 14 is 263.10199251770973\n","{'Validation Epoch Loss': 69.23111744225025, 'Epoch': 14, 'Micro F1': 0.6758771638920209, 'Patience Count': 0, 'Best Val F1': 0.6758771638920209, 'Best Val Loss': 65.92840586230159, 'Micro ROC value': 0.7204545245883663, 'Macro ROC value': 0.7204545245883663}\n","Training Epoch Loss after 15 is 284.00570154190063\n","{'Validation Epoch Loss': 67.76927387714386, 'Epoch': 15, 'Micro F1': 0.6700603568349142, 'Patience Count': 1, 'Best Val F1': 0.6758771638920209, 'Best Val Loss': 65.92840586230159, 'Micro ROC value': 0.6929240903022904, 'Macro ROC value': 0.6929240903022904}\n","Training Epoch Loss after 16 is 261.121049657464\n","{'Validation Epoch Loss': 64.45153504610062, 'Epoch': 16, 'Micro F1': 0.7078397559196127, 'Patience Count': 0, 'Best Val F1': 0.7078397559196127, 'Best Val Loss': 64.45153504610062, 'Micro ROC value': 0.720138331180131, 'Macro ROC value': 0.720138331180131}\n","Training Epoch Loss after 17 is 251.2490972802043\n","{'Validation Epoch Loss': 69.14279633760452, 'Epoch': 17, 'Micro F1': 0.6914936658486436, 'Patience Count': 1, 'Best Val F1': 0.7078397559196127, 'Best Val Loss': 64.45153504610062, 'Micro ROC value': 0.7350988940709975, 'Macro ROC value': 0.7350988940709975}\n","Training Epoch Loss after 18 is 245.42098034918308\n","{'Validation Epoch Loss': 66.9231433570385, 'Epoch': 18, 'Micro F1': 0.6982688863832327, 'Patience Count': 2, 'Best Val F1': 0.7078397559196127, 'Best Val Loss': 64.45153504610062, 'Micro ROC value': 0.7566721457048068, 'Macro ROC value': 0.7566721457048068}\n","Training Epoch Loss after 19 is 254.17176535725594\n","{'Validation Epoch Loss': 63.51546312868595, 'Epoch': 19, 'Micro F1': 0.7129667705777012, 'Patience Count': 0, 'Best Val F1': 0.7129667705777012, 'Best Val Loss': 63.51546312868595, 'Micro ROC value': 0.7570237449130731, 'Macro ROC value': 0.7570237449130731}\n","Training Epoch Loss after 20 is 237.42975740134716\n","{'Validation Epoch Loss': 57.5635050535202, 'Epoch': 20, 'Micro F1': 0.7743682430191682, 'Patience Count': 0, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 57.5635050535202, 'Micro ROC value': 0.8132942365715017, 'Macro ROC value': 0.8132942365715017}\n","Training Epoch Loss after 21 is 229.70854404568672\n","{'Validation Epoch Loss': 57.19684115052223, 'Epoch': 21, 'Micro F1': 0.7552530344232938, 'Patience Count': 0, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 57.19684115052223, 'Micro ROC value': 0.7884426357277577, 'Macro ROC value': 0.7884426357277577}\n","Training Epoch Loss after 22 is 221.75086920708418\n","{'Validation Epoch Loss': 57.500213876366615, 'Epoch': 22, 'Micro F1': 0.7452079326125887, 'Patience Count': 1, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 57.19684115052223, 'Micro ROC value': 0.7855822720270763, 'Macro ROC value': 0.7855822720270763}\n","Training Epoch Loss after 23 is 245.25895019620657\n","{'Validation Epoch Loss': 71.17359917610884, 'Epoch': 23, 'Micro F1': 0.681335809511176, 'Patience Count': 2, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 57.19684115052223, 'Micro ROC value': 0.7024953779333954, 'Macro ROC value': 0.7024953779333954}\n","Training Epoch Loss after 24 is 267.11477755755186\n","{'Validation Epoch Loss': 79.16051399707794, 'Epoch': 24, 'Micro F1': 0.6445081912847384, 'Patience Count': 3, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 57.19684115052223, 'Micro ROC value': 0.7406230628140068, 'Macro ROC value': 0.7406230628140068}\n","Training Epoch Loss after 25 is 243.28176361322403\n","{'Validation Epoch Loss': 66.20006564259529, 'Epoch': 25, 'Micro F1': 0.6679080718975924, 'Patience Count': 4, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 57.19684115052223, 'Micro ROC value': 0.7815866760790162, 'Macro ROC value': 0.7815866760790162}\n","Training Epoch Loss after 26 is 228.6441686823964\n","{'Validation Epoch Loss': 62.42119751870632, 'Epoch': 26, 'Micro F1': 0.7085527624859057, 'Patience Count': 5, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 57.19684115052223, 'Micro ROC value': 0.8114761245405268, 'Macro ROC value': 0.8114761245405268}\n","Training Epoch Loss after 27 is 219.76578745245934\n","{'Validation Epoch Loss': 56.9591453820467, 'Epoch': 27, 'Micro F1': 0.7689726072826158, 'Patience Count': 0, 'Best Val F1': 0.7743682430191682, 'Best Val Loss': 56.9591453820467, 'Micro ROC value': 0.8106124393074445, 'Macro ROC value': 0.8106124393074445}\n","Training Epoch Loss after 28 is 210.9621072039008\n","{'Validation Epoch Loss': 53.19483909010887, 'Epoch': 28, 'Micro F1': 0.7806592823506002, 'Patience Count': 0, 'Best Val F1': 0.7806592823506002, 'Best Val Loss': 53.19483909010887, 'Micro ROC value': 0.8188231836365245, 'Macro ROC value': 0.8188231836365245}\n","Training Epoch Loss after 29 is 210.0859848037362\n","{'Validation Epoch Loss': 52.58023163676262, 'Epoch': 29, 'Micro F1': 0.7713901969887909, 'Patience Count': 0, 'Best Val F1': 0.7806592823506002, 'Best Val Loss': 52.58023163676262, 'Micro ROC value': 0.8190125868042384, 'Macro ROC value': 0.8190125868042384}\n","Training Epoch Loss after 30 is 208.9285824149847\n","{'Validation Epoch Loss': 51.023138239979744, 'Epoch': 30, 'Micro F1': 0.7826523844266101, 'Patience Count': 0, 'Best Val F1': 0.7826523844266101, 'Best Val Loss': 51.023138239979744, 'Micro ROC value': 0.8350370558869942, 'Macro ROC value': 0.8350370558869942}\n","Training Epoch Loss after 31 is 230.1078064069152\n","{'Validation Epoch Loss': 60.4150652885437, 'Epoch': 31, 'Micro F1': 0.7150494130131989, 'Patience Count': 1, 'Best Val F1': 0.7826523844266101, 'Best Val Loss': 51.023138239979744, 'Micro ROC value': 0.7392505109571479, 'Macro ROC value': 0.7392505109571479}\n","Training Epoch Loss after 32 is 232.8743270635605\n","{'Validation Epoch Loss': 58.74554240703583, 'Epoch': 32, 'Micro F1': 0.7118790210254028, 'Patience Count': 2, 'Best Val F1': 0.7826523844266101, 'Best Val Loss': 51.023138239979744, 'Micro ROC value': 0.7484014316621503, 'Macro ROC value': 0.7484014316621503}\n","Training Epoch Loss after 33 is 220.16275173425674\n","{'Validation Epoch Loss': 51.792818397283554, 'Epoch': 33, 'Micro F1': 0.7951681368972607, 'Patience Count': 0, 'Best Val F1': 0.7951681368972607, 'Best Val Loss': 51.023138239979744, 'Micro ROC value': 0.8207103298728486, 'Macro ROC value': 0.8207103298728486}\n","Training Epoch Loss after 34 is 199.40822535008192\n","{'Validation Epoch Loss': 48.86503751575947, 'Epoch': 34, 'Micro F1': 0.8026928434038602, 'Patience Count': 0, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 48.86503751575947, 'Micro ROC value': 0.8392357639532655, 'Macro ROC value': 0.8392357639532655}\n","Training Epoch Loss after 35 is 193.0319628417492\n","{'Validation Epoch Loss': 47.295410111546516, 'Epoch': 35, 'Micro F1': 0.7868906281090403, 'Patience Count': 0, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 47.295410111546516, 'Micro ROC value': 0.8614344483052458, 'Macro ROC value': 0.8614344483052458}\n","Training Epoch Loss after 36 is 200.46194932609797\n","{'Validation Epoch Loss': 51.32929269969463, 'Epoch': 36, 'Micro F1': 0.7807421900908669, 'Patience Count': 1, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 47.295410111546516, 'Micro ROC value': 0.8553784478393616, 'Macro ROC value': 0.8553784478393616}\n","Training Epoch Loss after 37 is 194.79254892095923\n","{'Validation Epoch Loss': 49.34699705243111, 'Epoch': 37, 'Micro F1': 0.7514525436094713, 'Patience Count': 2, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 47.295410111546516, 'Micro ROC value': 0.831594814090796, 'Macro ROC value': 0.831594814090796}\n","Training Epoch Loss after 38 is 187.55558835715055\n","{'Validation Epoch Loss': 49.33450427651405, 'Epoch': 38, 'Micro F1': 0.7832095244412018, 'Patience Count': 3, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 47.295410111546516, 'Micro ROC value': 0.8415096026658277, 'Macro ROC value': 0.8415096026658277}\n","Training Epoch Loss after 39 is 193.18399712443352\n","{'Validation Epoch Loss': 50.49450063705444, 'Epoch': 39, 'Micro F1': 0.7850965046096704, 'Patience Count': 4, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 47.295410111546516, 'Micro ROC value': 0.847794955530119, 'Macro ROC value': 0.847794955530119}\n","Training Epoch Loss after 40 is 186.78056963533163\n","{'Validation Epoch Loss': 47.64938996732235, 'Epoch': 40, 'Micro F1': 0.7935663593553094, 'Patience Count': 5, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 47.295410111546516, 'Micro ROC value': 0.8582488607345955, 'Macro ROC value': 0.8582488607345955}\n","Training Epoch Loss after 41 is 188.83202275633812\n","{'Validation Epoch Loss': 46.26187498867512, 'Epoch': 41, 'Micro F1': 0.8005604563242025, 'Patience Count': 0, 'Best Val F1': 0.8026928434038602, 'Best Val Loss': 46.26187498867512, 'Micro ROC value': 0.8690714114755789, 'Macro ROC value': 0.8690714114755789}\n","Training Epoch Loss after 42 is 183.82270090281963\n","{'Validation Epoch Loss': 44.582883171737194, 'Epoch': 42, 'Micro F1': 0.8127379452145652, 'Patience Count': 0, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.582883171737194, 'Micro ROC value': 0.8732274648787695, 'Macro ROC value': 0.8732274648787695}\n","Training Epoch Loss after 43 is 182.9459003061056\n","{'Validation Epoch Loss': 44.78740034997463, 'Epoch': 43, 'Micro F1': 0.8106851495655635, 'Patience Count': 1, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.582883171737194, 'Micro ROC value': 0.859651234699247, 'Macro ROC value': 0.859651234699247}\n","Training Epoch Loss after 44 is 178.51671901345253\n","{'Validation Epoch Loss': 44.40387471020222, 'Epoch': 44, 'Micro F1': 0.8106950984943955, 'Patience Count': 0, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.40387471020222, 'Micro ROC value': 0.8669566825799079, 'Macro ROC value': 0.8669566825799079}\n","Training Epoch Loss after 45 is 186.140471406281\n","{'Validation Epoch Loss': 44.27635107189417, 'Epoch': 45, 'Micro F1': 0.8025038137560523, 'Patience Count': 0, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.8916448263466639, 'Macro ROC value': 0.8916448263466639}\n","Training Epoch Loss after 46 is 193.7774418219924\n","{'Validation Epoch Loss': 49.37991552054882, 'Epoch': 46, 'Micro F1': 0.7962857332360549, 'Patience Count': 1, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.8647723212759317, 'Macro ROC value': 0.8647723212759317}\n","Training Epoch Loss after 47 is 193.7223701439798\n","{'Validation Epoch Loss': 47.08369078487158, 'Epoch': 47, 'Micro F1': 0.7738111030045766, 'Patience Count': 2, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.8655435503877951, 'Macro ROC value': 0.8655435503877951}\n","Training Epoch Loss after 48 is 195.52748600393534\n","{'Validation Epoch Loss': 49.12909435480833, 'Epoch': 48, 'Micro F1': 0.7715692777077668, 'Patience Count': 3, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.874908747608453, 'Macro ROC value': 0.874908747608453}\n","Training Epoch Loss after 49 is 198.4438769966364\n","{'Validation Epoch Loss': 48.93558420240879, 'Epoch': 49, 'Micro F1': 0.7626285069974132, 'Patience Count': 4, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.8540029651287616, 'Macro ROC value': 0.8540029651287616}\n","Training Epoch Loss after 50 is 191.12060286849737\n","{'Validation Epoch Loss': 44.48152448236942, 'Epoch': 50, 'Micro F1': 0.794571201167341, 'Patience Count': 5, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.8709740810741844, 'Macro ROC value': 0.8709740810741844}\n","Training Epoch Loss after 51 is 192.47125205770135\n","{'Validation Epoch Loss': 47.40992671996355, 'Epoch': 51, 'Micro F1': 0.7769019035617165, 'Patience Count': 6, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.8777700434622759, 'Macro ROC value': 0.8777700434622759}\n","Training Epoch Loss after 52 is 180.57049054652452\n","{'Validation Epoch Loss': 45.73988801240921, 'Epoch': 52, 'Micro F1': 0.7836903893347483, 'Patience Count': 7, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 44.27635107189417, 'Micro ROC value': 0.8728235259873947, 'Macro ROC value': 0.8728235259873947}\n","Training Epoch Loss after 53 is 173.5665647648275\n","{'Validation Epoch Loss': 43.50262547656894, 'Epoch': 53, 'Micro F1': 0.8012635139616635, 'Patience Count': 0, 'Best Val F1': 0.8127379452145652, 'Best Val Loss': 43.50262547656894, 'Micro ROC value': 0.8918927750331892, 'Macro ROC value': 0.8918927750331892}\n","Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n","Training Epoch Loss after 54 is 153.18741323426366\n","{'Validation Epoch Loss': 42.58570792526007, 'Epoch': 54, 'Micro F1': 0.8144027326391192, 'Patience Count': 0, 'Best Val F1': 0.8144027326391192, 'Best Val Loss': 42.58570792526007, 'Micro ROC value': 0.9046127368466383, 'Macro ROC value': 0.9046127368466383}\n","Training Epoch Loss after 55 is 151.1393974274397\n","{'Validation Epoch Loss': 42.15801111608744, 'Epoch': 55, 'Micro F1': 0.8186078132254427, 'Patience Count': 0, 'Best Val F1': 0.8186078132254427, 'Best Val Loss': 42.15801111608744, 'Micro ROC value': 0.9064528169939112, 'Macro ROC value': 0.9064528169939112}\n","Training Epoch Loss after 56 is 150.48014396429062\n","{'Validation Epoch Loss': 41.76197139173746, 'Epoch': 56, 'Micro F1': 0.820100152550242, 'Patience Count': 0, 'Best Val F1': 0.820100152550242, 'Best Val Loss': 41.76197139173746, 'Micro ROC value': 0.9062994455532671, 'Macro ROC value': 0.9062994455532671}\n","Training Epoch Loss after 57 is 149.30039769783616\n","{'Validation Epoch Loss': 41.3519081287086, 'Epoch': 57, 'Micro F1': 0.82328049346687, 'Patience Count': 0, 'Best Val F1': 0.82328049346687, 'Best Val Loss': 41.3519081287086, 'Micro ROC value': 0.9091218399608686, 'Macro ROC value': 0.9091218399608686}\n","Training Epoch Loss after 58 is 148.0967652387917\n","{'Validation Epoch Loss': 41.22177663072944, 'Epoch': 58, 'Micro F1': 0.8276480732241162, 'Patience Count': 0, 'Best Val F1': 0.8276480732241162, 'Best Val Loss': 41.22177663072944, 'Micro ROC value': 0.9121810084573898, 'Macro ROC value': 0.9121810084573898}\n","Training Epoch Loss after 59 is 147.30698269233108\n","{'Validation Epoch Loss': 41.02239942550659, 'Epoch': 59, 'Micro F1': 0.8259534390130663, 'Patience Count': 0, 'Best Val F1': 0.8276480732241162, 'Best Val Loss': 41.02239942550659, 'Micro ROC value': 0.9145718681340151, 'Macro ROC value': 0.9145718681340151}\n","Training Epoch Loss after 60 is 145.4256978444755\n","{'Validation Epoch Loss': 40.658350102603436, 'Epoch': 60, 'Micro F1': 0.828918219805001, 'Patience Count': 0, 'Best Val F1': 0.828918219805001, 'Best Val Loss': 40.658350102603436, 'Micro ROC value': 0.9161048857433159, 'Macro ROC value': 0.9161048857433159}\n","Training Epoch Loss after 61 is 145.26922612264752\n","{'Validation Epoch Loss': 40.5071323402226, 'Epoch': 61, 'Micro F1': 0.8278238376334814, 'Patience Count': 0, 'Best Val F1': 0.828918219805001, 'Best Val Loss': 40.5071323402226, 'Micro ROC value': 0.9150860535998533, 'Macro ROC value': 0.9150860535998533}\n","Training Epoch Loss after 62 is 144.61128288507462\n","{'Validation Epoch Loss': 40.276751693338156, 'Epoch': 62, 'Micro F1': 0.8299363268554752, 'Patience Count': 0, 'Best Val F1': 0.8299363268554752, 'Best Val Loss': 40.276751693338156, 'Micro ROC value': 0.9189439544498451, 'Macro ROC value': 0.9189439544498451}\n","Training Epoch Loss after 63 is 143.928097050637\n","{'Validation Epoch Loss': 40.26770503073931, 'Epoch': 63, 'Micro F1': 0.827996285733236, 'Patience Count': 0, 'Best Val F1': 0.8299363268554752, 'Best Val Loss': 40.26770503073931, 'Micro ROC value': 0.9203504337692479, 'Macro ROC value': 0.9203504337692479}\n","Training Epoch Loss after 64 is 143.39278188720345\n","{'Validation Epoch Loss': 40.1798934340477, 'Epoch': 64, 'Micro F1': 0.830098826026398, 'Patience Count': 0, 'Best Val F1': 0.830098826026398, 'Best Val Loss': 40.1798934340477, 'Micro ROC value': 0.9217513229355725, 'Macro ROC value': 0.9217513229355725}\n","Training Epoch Loss after 65 is 142.5991371870041\n","{'Validation Epoch Loss': 40.096924398094416, 'Epoch': 65, 'Micro F1': 0.8310074948597201, 'Patience Count': 0, 'Best Val F1': 0.8310074948597201, 'Best Val Loss': 40.096924398094416, 'Micro ROC value': 0.9232854423835624, 'Macro ROC value': 0.9232854423835624}\n","Training Epoch Loss after 66 is 141.88704085722566\n","{'Validation Epoch Loss': 39.929123401641846, 'Epoch': 66, 'Micro F1': 0.8308151489023016, 'Patience Count': 0, 'Best Val F1': 0.8310074948597201, 'Best Val Loss': 39.929123401641846, 'Micro ROC value': 0.9222786231316614, 'Macro ROC value': 0.9222786231316614}\n","Training Epoch Loss after 67 is 141.3505853973329\n","{'Validation Epoch Loss': 39.93838315829635, 'Epoch': 67, 'Micro F1': 0.835169463421105, 'Patience Count': 0, 'Best Val F1': 0.835169463421105, 'Best Val Loss': 39.929123401641846, 'Micro ROC value': 0.9231724677416462, 'Macro ROC value': 0.9231724677416462}\n","Training Epoch Loss after 68 is 141.15058720111847\n","{'Validation Epoch Loss': 40.0983631759882, 'Epoch': 68, 'Micro F1': 0.8344199774490947, 'Patience Count': 1, 'Best Val F1': 0.835169463421105, 'Best Val Loss': 39.929123401641846, 'Micro ROC value': 0.9228864498624131, 'Macro ROC value': 0.9228864498624131}\n","Training Epoch Loss after 69 is 140.51058785244823\n","{'Validation Epoch Loss': 39.79591105878353, 'Epoch': 69, 'Micro F1': 0.8356901240299794, 'Patience Count': 0, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.79591105878353, 'Micro ROC value': 0.9229956127858935, 'Macro ROC value': 0.9229956127858935}\n","Training Epoch Loss after 70 is 140.2161772735417\n","{'Validation Epoch Loss': 39.936861988157034, 'Epoch': 70, 'Micro F1': 0.8339291636267162, 'Patience Count': 1, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.79591105878353, 'Micro ROC value': 0.9221556035655424, 'Macro ROC value': 0.9221556035655424}\n","Training Epoch Loss after 71 is 139.49895457178354\n","{'Validation Epoch Loss': 40.22760447487235, 'Epoch': 71, 'Micro F1': 0.8288319957551237, 'Patience Count': 2, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.79591105878353, 'Micro ROC value': 0.9127413760056695, 'Macro ROC value': 0.9127413760056695}\n","Training Epoch Loss after 72 is 139.2305950410664\n","{'Validation Epoch Loss': 40.33033937215805, 'Epoch': 72, 'Micro F1': 0.8291039331431983, 'Patience Count': 3, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.79591105878353, 'Micro ROC value': 0.9094646284423311, 'Macro ROC value': 0.9094646284423311}\n","Training Epoch Loss after 73 is 138.75666092708707\n","{'Validation Epoch Loss': 39.98613070324063, 'Epoch': 73, 'Micro F1': 0.8307057106851495, 'Patience Count': 4, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.79591105878353, 'Micro ROC value': 0.9070752507097574, 'Macro ROC value': 0.9070752507097574}\n","Training Epoch Loss after 74 is 137.75987177714705\n","{'Validation Epoch Loss': 39.82872161269188, 'Epoch': 74, 'Micro F1': 0.8288419446839558, 'Patience Count': 5, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.79591105878353, 'Micro ROC value': 0.9060766058140723, 'Macro ROC value': 0.9060766058140723}\n","Training Epoch Loss after 75 is 137.52590474113822\n","{'Validation Epoch Loss': 39.4871785081923, 'Epoch': 75, 'Micro F1': 0.8306261192544936, 'Patience Count': 0, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.4871785081923, 'Micro ROC value': 0.9114610554682085, 'Macro ROC value': 0.9114610554682085}\n","Training Epoch Loss after 76 is 137.13168766349554\n","{'Validation Epoch Loss': 39.65806411579251, 'Epoch': 76, 'Micro F1': 0.8305896398487763, 'Patience Count': 1, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.4871785081923, 'Micro ROC value': 0.9096629924407419, 'Macro ROC value': 0.9096629924407419}\n","Training Epoch Loss after 77 is 137.24048751592636\n","{'Validation Epoch Loss': 39.31595088914037, 'Epoch': 77, 'Micro F1': 0.8318962658353783, 'Patience Count': 0, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.31595088914037, 'Micro ROC value': 0.9129152380437927, 'Macro ROC value': 0.9129152380437927}\n","Training Epoch Loss after 78 is 137.01236621662974\n","{'Validation Epoch Loss': 39.25757314637303, 'Epoch': 78, 'Micro F1': 0.8331465145585991, 'Patience Count': 0, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.25757314637303, 'Micro ROC value': 0.9125988200328716, 'Macro ROC value': 0.9125988200328716}\n","Training Epoch Loss after 79 is 136.51129291579127\n","{'Validation Epoch Loss': 39.321274887770414, 'Epoch': 79, 'Micro F1': 0.8334980433773297, 'Patience Count': 1, 'Best Val F1': 0.8356901240299794, 'Best Val Loss': 39.25757314637303, 'Micro ROC value': 0.911096806643774, 'Macro ROC value': 0.911096806643774}\n","Training Epoch Loss after 80 is 135.9755375534296\n","{'Validation Epoch Loss': 38.80853336304426, 'Epoch': 80, 'Micro F1': 0.8368773628705974, 'Patience Count': 0, 'Best Val F1': 0.8368773628705974, 'Best Val Loss': 38.80853336304426, 'Micro ROC value': 0.9140681523483406, 'Macro ROC value': 0.9140681523483406}\n","Training Epoch Loss after 81 is 135.90303932130337\n","{'Validation Epoch Loss': 38.933130890131, 'Epoch': 81, 'Micro F1': 0.8356072162897129, 'Patience Count': 1, 'Best Val F1': 0.8368773628705974, 'Best Val Loss': 38.80853336304426, 'Micro ROC value': 0.9143480586714535, 'Macro ROC value': 0.9143480586714535}\n","Training Epoch Loss after 82 is 137.62766231037676\n","{'Validation Epoch Loss': 37.762864381074905, 'Epoch': 82, 'Micro F1': 0.8315613185647013, 'Patience Count': 0, 'Best Val F1': 0.8368773628705974, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9179099405499388, 'Macro ROC value': 0.9179099405499388}\n","Training Epoch Loss after 83 is 133.55180415697396\n","{'Validation Epoch Loss': 38.249177208170295, 'Epoch': 83, 'Micro F1': 0.8389633216157061, 'Patience Count': 0, 'Best Val F1': 0.8389633216157061, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9200917610401838, 'Macro ROC value': 0.9200917610401838}\n","Training Epoch Loss after 84 is 132.59062484651804\n","{'Validation Epoch Loss': 38.7387335319072, 'Epoch': 84, 'Micro F1': 0.8291868408834648, 'Patience Count': 1, 'Best Val F1': 0.8389633216157061, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9180571595674386, 'Macro ROC value': 0.9180571595674386}\n","Training Epoch Loss after 85 is 133.0936985593289\n","{'Validation Epoch Loss': 38.33545961417258, 'Epoch': 85, 'Micro F1': 0.8348776281753665, 'Patience Count': 2, 'Best Val F1': 0.8389633216157061, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9189433901884239, 'Macro ROC value': 0.9189433901884239}\n","Training Epoch Loss after 86 is 132.36586541868746\n","{'Validation Epoch Loss': 38.41361581720412, 'Epoch': 86, 'Micro F1': 0.838260263978245, 'Patience Count': 3, 'Best Val F1': 0.8389633216157061, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9197350178971784, 'Macro ROC value': 0.9197350178971784}\n","Training Epoch Loss after 87 is 131.66174420528114\n","{'Validation Epoch Loss': 38.42574215494096, 'Epoch': 87, 'Micro F1': 0.8384227631491676, 'Patience Count': 4, 'Best Val F1': 0.8389633216157061, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9188056605514144, 'Macro ROC value': 0.9188056605514144}\n","Training Epoch Loss after 88 is 131.29961639083922\n","{'Validation Epoch Loss': 38.387933012098074, 'Epoch': 88, 'Micro F1': 0.8390064336406446, 'Patience Count': 0, 'Best Val F1': 0.8390064336406446, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9191707784915506, 'Macro ROC value': 0.9191707784915506}\n","Training Epoch Loss after 89 is 130.77881963551044\n","{'Validation Epoch Loss': 38.44811348058283, 'Epoch': 89, 'Micro F1': 0.8403296411753002, 'Patience Count': 0, 'Best Val F1': 0.8403296411753002, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9195444962297743, 'Macro ROC value': 0.9195444962297743}\n","Training Epoch Loss after 90 is 131.52385655976832\n","{'Validation Epoch Loss': 38.511440170928836, 'Epoch': 90, 'Micro F1': 0.8408735159514492, 'Patience Count': 0, 'Best Val F1': 0.8408735159514492, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9183687948311132, 'Macro ROC value': 0.9183687948311132}\n","Training Epoch Loss after 91 is 134.94709451310337\n","{'Validation Epoch Loss': 37.946945982053876, 'Epoch': 91, 'Micro F1': 0.8445446706904557, 'Patience Count': 0, 'Best Val F1': 0.8445446706904557, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9214009107074725, 'Macro ROC value': 0.9214009107074725}\n","Training Epoch Loss after 92 is 131.65385125763714\n","{'Validation Epoch Loss': 48.16646218299866, 'Epoch': 92, 'Micro F1': 0.7277409298932147, 'Patience Count': 1, 'Best Val F1': 0.8445446706904557, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.8182441364729945, 'Macro ROC value': 0.8182441364729945}\n","Training Epoch Loss after 93 is 135.70423350855708\n","{'Validation Epoch Loss': 38.3960010483861, 'Epoch': 93, 'Micro F1': 0.838893679113882, 'Patience Count': 2, 'Best Val F1': 0.8445446706904557, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9272577586427316, 'Macro ROC value': 0.9272577586427316}\n","Training Epoch Loss after 94 is 133.79784426093102\n","{'Validation Epoch Loss': 38.14189611002803, 'Epoch': 94, 'Micro F1': 0.8455495125024872, 'Patience Count': 0, 'Best Val F1': 0.8455495125024872, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9295466130770067, 'Macro ROC value': 0.9295466130770067}\n","Training Epoch Loss after 95 is 133.19132364541292\n","{'Validation Epoch Loss': 38.05820721387863, 'Epoch': 95, 'Micro F1': 0.8457584400079592, 'Patience Count': 0, 'Best Val F1': 0.8457584400079592, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9302724619143405, 'Macro ROC value': 0.9302724619143405}\n","Training Epoch Loss after 96 is 132.57526891306043\n","{'Validation Epoch Loss': 37.77717014402151, 'Epoch': 96, 'Micro F1': 0.8488956688996485, 'Patience Count': 0, 'Best Val F1': 0.8488956688996485, 'Best Val Loss': 37.762864381074905, 'Micro ROC value': 0.9311286802310318, 'Macro ROC value': 0.9311286802310318}\n","Training Epoch Loss after 97 is 132.092870015651\n","{'Validation Epoch Loss': 37.73280946910381, 'Epoch': 97, 'Micro F1': 0.8508920872852689, 'Patience Count': 0, 'Best Val F1': 0.8508920872852689, 'Best Val Loss': 37.73280946910381, 'Micro ROC value': 0.9332716937537735, 'Macro ROC value': 0.9332716937537735}\n","Training Epoch Loss after 98 is 131.5057597644627\n","{'Validation Epoch Loss': 37.645429994910955, 'Epoch': 98, 'Micro F1': 0.8481097035219209, 'Patience Count': 0, 'Best Val F1': 0.8508920872852689, 'Best Val Loss': 37.645429994910955, 'Micro ROC value': 0.9226669616174533, 'Macro ROC value': 0.9226669616174533}\n","Training Epoch Loss after 99 is 131.33841631934047\n","{'Validation Epoch Loss': 37.28276160731912, 'Epoch': 99, 'Micro F1': 0.8500630098826026, 'Patience Count': 0, 'Best Val F1': 0.8508920872852689, 'Best Val Loss': 37.28276160731912, 'Micro ROC value': 0.9328190016755079, 'Macro ROC value': 0.9328190016755079}\n","Training Epoch Loss after 100 is 130.53371724113822\n","{'Validation Epoch Loss': 37.80848185904324, 'Epoch': 100, 'Micro F1': 0.8442528354447172, 'Patience Count': 1, 'Best Val F1': 0.8508920872852689, 'Best Val Loss': 37.28276160731912, 'Micro ROC value': 0.9309985937674315, 'Macro ROC value': 0.9309985937674315}\n","Training Epoch Loss after 101 is 129.5316101294011\n","{'Validation Epoch Loss': 36.97682616300881, 'Epoch': 101, 'Micro F1': 0.8527193738807455, 'Patience Count': 0, 'Best Val F1': 0.8527193738807455, 'Best Val Loss': 36.97682616300881, 'Micro ROC value': 0.934519989789381, 'Macro ROC value': 0.934519989789381}\n","Training Epoch Loss after 102 is 128.6882654055953\n","{'Validation Epoch Loss': 36.81917664967477, 'Epoch': 102, 'Micro F1': 0.8526596803077535, 'Patience Count': 0, 'Best Val F1': 0.8527193738807455, 'Best Val Loss': 36.81917664967477, 'Micro ROC value': 0.934461871084263, 'Macro ROC value': 0.934461871084263}\n","Training Epoch Loss after 103 is 128.47433711774647\n","{'Validation Epoch Loss': 36.83231641165912, 'Epoch': 103, 'Micro F1': 0.8515022882536314, 'Patience Count': 1, 'Best Val F1': 0.8527193738807455, 'Best Val Loss': 36.81917664967477, 'Micro ROC value': 0.9327993100095401, 'Macro ROC value': 0.9327993100095401}\n","Training Epoch Loss after 104 is 128.2106573637575\n","{'Validation Epoch Loss': 36.695774137973785, 'Epoch': 104, 'Micro F1': 0.8512568813424422, 'Patience Count': 0, 'Best Val F1': 0.8527193738807455, 'Best Val Loss': 36.695774137973785, 'Micro ROC value': 0.932404857445245, 'Macro ROC value': 0.932404857445245}\n","Training Epoch Loss after 105 is 128.2624487997964\n","{'Validation Epoch Loss': 36.65899579459801, 'Epoch': 105, 'Micro F1': 0.8507196391855144, 'Patience Count': 0, 'Best Val F1': 0.8527193738807455, 'Best Val Loss': 36.65899579459801, 'Micro ROC value': 0.9342892348577232, 'Macro ROC value': 0.9342892348577232}\n","Training Epoch Loss after 106 is 127.1488972529769\n","{'Validation Epoch Loss': 36.60414825659245, 'Epoch': 106, 'Micro F1': 0.8524772832791669, 'Patience Count': 0, 'Best Val F1': 0.8527193738807455, 'Best Val Loss': 36.60414825659245, 'Micro ROC value': 0.935206253349285, 'Macro ROC value': 0.935206253349285}\n","Training Epoch Loss after 107 is 126.86896936688572\n","{'Validation Epoch Loss': 36.52737949974835, 'Epoch': 107, 'Micro F1': 0.8521091729123831, 'Patience Count': 0, 'Best Val F1': 0.8527193738807455, 'Best Val Loss': 36.52737949974835, 'Micro ROC value': 0.9348673663521034, 'Macro ROC value': 0.9348673663521034}\n","Training Epoch Loss after 108 is 126.28960717562586\n","{'Validation Epoch Loss': 36.32966142008081, 'Epoch': 108, 'Micro F1': 0.8593221463155801, 'Patience Count': 0, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 36.32966142008081, 'Micro ROC value': 0.9381684940490733, 'Macro ROC value': 0.9381684940490733}\n","Training Epoch Loss after 109 is 125.85197472665459\n","{'Validation Epoch Loss': 36.50646010786295, 'Epoch': 109, 'Micro F1': 0.8519533063606818, 'Patience Count': 1, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 36.32966142008081, 'Micro ROC value': 0.9247409613572948, 'Macro ROC value': 0.9247409613572948}\n","Training Epoch Loss after 110 is 125.0245792074129\n","{'Validation Epoch Loss': 36.31555461231619, 'Epoch': 110, 'Micro F1': 0.8549446176295019, 'Patience Count': 0, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 36.31555461231619, 'Micro ROC value': 0.9300565230600224, 'Macro ROC value': 0.9300565230600224}\n","Training Epoch Loss after 111 is 125.90721163339913\n","{'Validation Epoch Loss': 36.05820295820013, 'Epoch': 111, 'Micro F1': 0.8566624660078265, 'Patience Count': 0, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 36.05820295820013, 'Micro ROC value': 0.932370137821796, 'Macro ROC value': 0.932370137821796}\n","Training Epoch Loss after 112 is 124.98505419678986\n","{'Validation Epoch Loss': 36.12525914888829, 'Epoch': 112, 'Micro F1': 0.8563971612389732, 'Patience Count': 1, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 36.05820295820013, 'Micro ROC value': 0.9328750048317567, 'Macro ROC value': 0.9328750048317567}\n","Training Epoch Loss after 113 is 124.51785686053336\n","{'Validation Epoch Loss': 35.99655353883281, 'Epoch': 113, 'Micro F1': 0.8568249651787492, 'Patience Count': 0, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 35.99655353883281, 'Micro ROC value': 0.9332603795622023, 'Macro ROC value': 0.9332603795622023}\n","Training Epoch Loss after 114 is 123.69899601396173\n","{'Validation Epoch Loss': 35.9563538399525, 'Epoch': 114, 'Micro F1': 0.8569708828016184, 'Patience Count': 0, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 35.9563538399525, 'Micro ROC value': 0.9331561530521735, 'Macro ROC value': 0.9331561530521735}\n","Training Epoch Loss after 115 is 123.49954203795642\n","{'Validation Epoch Loss': 35.813149275723845, 'Epoch': 115, 'Micro F1': 0.8569310870862904, 'Patience Count': 0, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 35.813149275723845, 'Micro ROC value': 0.9333342738899917, 'Macro ROC value': 0.9333342738899917}\n","Training Epoch Loss after 116 is 123.41620086878538\n","{'Validation Epoch Loss': 35.82624990493059, 'Epoch': 116, 'Micro F1': 0.8587915367778736, 'Patience Count': 1, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 35.813149275723845, 'Micro ROC value': 0.9368686420390682, 'Macro ROC value': 0.9368686420390682}\n","Training Epoch Loss after 117 is 123.08274055086076\n","{'Validation Epoch Loss': 35.84375654999167, 'Epoch': 117, 'Micro F1': 0.8588445977316442, 'Patience Count': 2, 'Best Val F1': 0.8593221463155801, 'Best Val Loss': 35.813149275723845, 'Micro ROC value': 0.9352585623655307, 'Macro ROC value': 0.9352585623655307}\n","Training Epoch Loss after 118 is 122.85693733114749\n","{'Validation Epoch Loss': 35.78840648056939, 'Epoch': 118, 'Micro F1': 0.8596106652517079, 'Patience Count': 0, 'Best Val F1': 0.8596106652517079, 'Best Val Loss': 35.78840648056939, 'Micro ROC value': 0.9347816240169227, 'Macro ROC value': 0.9347816240169227}\n","Training Epoch Loss after 119 is 122.13710164371878\n","{'Validation Epoch Loss': 35.60984446713701, 'Epoch': 119, 'Micro F1': 0.8609073423094781, 'Patience Count': 0, 'Best Val F1': 0.8609073423094781, 'Best Val Loss': 35.60984446713701, 'Micro ROC value': 0.9347658392118935, 'Macro ROC value': 0.9347658392118935}\n","Training Epoch Loss after 120 is 121.8753281570971\n","{'Validation Epoch Loss': 35.61056901421398, 'Epoch': 120, 'Micro F1': 0.8602905087218943, 'Patience Count': 1, 'Best Val F1': 0.8609073423094781, 'Best Val Loss': 35.60984446713701, 'Micro ROC value': 0.9352957144066361, 'Macro ROC value': 0.9352957144066361}\n","Training Epoch Loss after 121 is 121.78132267063484\n","{'Validation Epoch Loss': 35.86516361217946, 'Epoch': 121, 'Micro F1': 0.8572328712608609, 'Patience Count': 2, 'Best Val F1': 0.8609073423094781, 'Best Val Loss': 35.60984446713701, 'Micro ROC value': 0.9344732584913092, 'Macro ROC value': 0.9344732584913092}\n","Training Epoch Loss after 122 is 120.96484426781535\n","{'Validation Epoch Loss': 35.50260739214718, 'Epoch': 122, 'Micro F1': 0.8605060688465875, 'Patience Count': 0, 'Best Val F1': 0.8609073423094781, 'Best Val Loss': 35.50260739214718, 'Micro ROC value': 0.9374102148496691, 'Macro ROC value': 0.9374102148496691}\n","Training Epoch Loss after 123 is 120.63599604833871\n","{'Validation Epoch Loss': 35.602505209855735, 'Epoch': 123, 'Micro F1': 0.8588346488028122, 'Patience Count': 1, 'Best Val F1': 0.8609073423094781, 'Best Val Loss': 35.50260739214718, 'Micro ROC value': 0.9358392307573115, 'Macro ROC value': 0.9358392307573115}\n","Training Epoch Loss after 124 is 120.53744621621445\n","{'Validation Epoch Loss': 35.423059922643006, 'Epoch': 124, 'Micro F1': 0.8607415268289448, 'Patience Count': 0, 'Best Val F1': 0.8609073423094781, 'Best Val Loss': 35.423059922643006, 'Micro ROC value': 0.9383751649836716, 'Macro ROC value': 0.9383751649836716}\n","Training Epoch Loss after 125 is 120.43834852799773\n","{'Validation Epoch Loss': 35.50477006426081, 'Epoch': 125, 'Micro F1': 0.8629767195065331, 'Patience Count': 0, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.423059922643006, 'Micro ROC value': 0.9378532654300706, 'Macro ROC value': 0.9378532654300706}\n","Training Epoch Loss after 126 is 122.19089921051636\n","{'Validation Epoch Loss': 35.45528589235619, 'Epoch': 126, 'Micro F1': 0.8606354049214034, 'Patience Count': 1, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.423059922643006, 'Micro ROC value': 0.9350303519647998, 'Macro ROC value': 0.9350303519647998}\n","Training Epoch Loss after 127 is 120.96815632097423\n","{'Validation Epoch Loss': 35.30456402897835, 'Epoch': 127, 'Micro F1': 0.8623698348477814, 'Patience Count': 0, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.9379970629904061, 'Macro ROC value': 0.9379970629904061}\n","Training Epoch Loss after 128 is 120.33315543085337\n","{'Validation Epoch Loss': 35.45620777644217, 'Epoch': 128, 'Micro F1': 0.8597267360880811, 'Patience Count': 1, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.9382841154226654, 'Macro ROC value': 0.9382841154226654}\n","Training Epoch Loss after 129 is 121.41302311234176\n","{'Validation Epoch Loss': 35.556312277913094, 'Epoch': 129, 'Micro F1': 0.8558765006300988, 'Patience Count': 2, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.9395003635911906, 'Macro ROC value': 0.9395003635911906}\n","Training Epoch Loss after 130 is 120.5654230043292\n","{'Validation Epoch Loss': 35.975343000143766, 'Epoch': 130, 'Micro F1': 0.8534423293758705, 'Patience Count': 3, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.9386557456679951, 'Macro ROC value': 0.9386557456679951}\n","Training Epoch Loss after 131 is 119.86714160814881\n","{'Validation Epoch Loss': 36.06247950159013, 'Epoch': 131, 'Micro F1': 0.8525004974464416, 'Patience Count': 4, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.937919873789234, 'Macro ROC value': 0.937919873789234}\n","Training Epoch Loss after 132 is 119.46852451190352\n","{'Validation Epoch Loss': 36.20403624884784, 'Epoch': 132, 'Micro F1': 0.8514624925383034, 'Patience Count': 5, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.9327133137323811, 'Macro ROC value': 0.9327133137323811}\n","Training Epoch Loss after 133 is 119.3281649556011\n","{'Validation Epoch Loss': 36.27603270113468, 'Epoch': 133, 'Micro F1': 0.8528553425747828, 'Patience Count': 6, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.937779993909531, 'Macro ROC value': 0.937779993909531}\n","Training Epoch Loss after 134 is 119.28003205731511\n","{'Validation Epoch Loss': 36.00722757168114, 'Epoch': 134, 'Micro F1': 0.8514989719440207, 'Patience Count': 7, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.934697490098944, 'Macro ROC value': 0.934697490098944}\n","Training Epoch Loss after 135 is 119.06869383528829\n","{'Validation Epoch Loss': 35.67350680427626, 'Epoch': 135, 'Micro F1': 0.8547025270279234, 'Patience Count': 8, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.9365086909342502, 'Macro ROC value': 0.9365086909342502}\n","Training Epoch Loss after 136 is 118.35706203058362\n","{'Validation Epoch Loss': 36.38517997227609, 'Epoch': 136, 'Micro F1': 0.8524109570869537, 'Patience Count': 9, 'Best Val F1': 0.8629767195065331, 'Best Val Loss': 35.30456402897835, 'Micro ROC value': 0.9368510638863625, 'Macro ROC value': 0.9368510638863625}\n","Epoch   137: reducing learning rate of group 0 to 1.0000e-04.\n","Training Epoch Loss after 137 is 115.33912231959403\n","{'Validation Epoch Loss': 35.177438739687204, 'Epoch': 137, 'Micro F1': 0.8659481329176892, 'Patience Count': 0, 'Best Val F1': 0.8659481329176892, 'Best Val Loss': 35.177438739687204, 'Micro ROC value': 0.939906768642621, 'Macro ROC value': 0.939906768642621}\n","Training Epoch Loss after 138 is 114.79941892437637\n","{'Validation Epoch Loss': 35.1201661080122, 'Epoch': 138, 'Micro F1': 0.8670657292564834, 'Patience Count': 0, 'Best Val F1': 0.8670657292564834, 'Best Val Loss': 35.1201661080122, 'Micro ROC value': 0.9403313501160917, 'Macro ROC value': 0.9403313501160917}\n","Training Epoch Loss after 139 is 114.6520258653909\n","{'Validation Epoch Loss': 35.098819149658084, 'Epoch': 139, 'Micro F1': 0.8672613915235127, 'Patience Count': 0, 'Best Val F1': 0.8672613915235127, 'Best Val Loss': 35.098819149658084, 'Micro ROC value': 0.940473463322232, 'Macro ROC value': 0.940473463322232}\n","Training Epoch Loss after 140 is 114.55963189527392\n","{'Validation Epoch Loss': 35.08670130930841, 'Epoch': 140, 'Micro F1': 0.8674537374809312, 'Patience Count': 0, 'Best Val F1': 0.8674537374809312, 'Best Val Loss': 35.08670130930841, 'Micro ROC value': 0.9405325931266426, 'Macro ROC value': 0.9405325931266426}\n","Training Epoch Loss after 141 is 114.48752530291677\n","{'Validation Epoch Loss': 35.07745245099068, 'Epoch': 141, 'Micro F1': 0.8674736353385953, 'Patience Count': 0, 'Best Val F1': 0.8674736353385953, 'Best Val Loss': 35.07745245099068, 'Micro ROC value': 0.9405672265244327, 'Macro ROC value': 0.9405672265244327}\n","Training Epoch Loss after 142 is 114.4212930817157\n","{'Validation Epoch Loss': 35.070601342245936, 'Epoch': 142, 'Micro F1': 0.8675664920076939, 'Patience Count': 0, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.070601342245936, 'Micro ROC value': 0.9405732107666083, 'Macro ROC value': 0.9405732107666083}\n","Training Epoch Loss after 143 is 114.36414647474885\n","{'Validation Epoch Loss': 35.06364269182086, 'Epoch': 143, 'Micro F1': 0.8674272070040459, 'Patience Count': 0, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.06364269182086, 'Micro ROC value': 0.9405798458056307, 'Macro ROC value': 0.9405798458056307}\n","Training Epoch Loss after 144 is 114.28681773133576\n","{'Validation Epoch Loss': 35.058329693973064, 'Epoch': 144, 'Micro F1': 0.8674139417656033, 'Patience Count': 0, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.058329693973064, 'Micro ROC value': 0.9405816036186887, 'Macro ROC value': 0.9405816036186887}\n","Training Epoch Loss after 145 is 114.23849822953343\n","{'Validation Epoch Loss': 35.05449138954282, 'Epoch': 145, 'Micro F1': 0.8673608808118326, 'Patience Count': 0, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.05449138954282, 'Micro ROC value': 0.9405944792314906, 'Macro ROC value': 0.9405944792314906}\n","Training Epoch Loss after 146 is 114.2122375741601\n","{'Validation Epoch Loss': 35.04718199186027, 'Epoch': 146, 'Micro F1': 0.8675565430788619, 'Patience Count': 0, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.04718199186027, 'Micro ROC value': 0.9406265098180393, 'Macro ROC value': 0.9406265098180393}\n","Training Epoch Loss after 147 is 114.1303493231535\n","{'Validation Epoch Loss': 35.04878180101514, 'Epoch': 147, 'Micro F1': 0.8674769516482059, 'Patience Count': 1, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.04718199186027, 'Micro ROC value': 0.940612435852223, 'Macro ROC value': 0.940612435852223}\n","Training Epoch Loss after 148 is 114.07193990796804\n","{'Validation Epoch Loss': 35.06858410872519, 'Epoch': 148, 'Micro F1': 0.8673343503349473, 'Patience Count': 2, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.04718199186027, 'Micro ROC value': 0.9405648995158191, 'Macro ROC value': 0.9405648995158191}\n","Training Epoch Loss after 149 is 114.02033315040171\n","{'Validation Epoch Loss': 35.04916353709996, 'Epoch': 149, 'Micro F1': 0.867277973071566, 'Patience Count': 3, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 35.04718199186027, 'Micro ROC value': 0.9405589554547561, 'Macro ROC value': 0.9405589554547561}\n","Training Epoch Loss after 150 is 113.96923258900642\n","{'Validation Epoch Loss': 34.99236425291747, 'Epoch': 150, 'Micro F1': 0.8672912383100086, 'Patience Count': 0, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 34.99236425291747, 'Micro ROC value': 0.9406305858556239, 'Macro ROC value': 0.9406305858556239}\n","Training Epoch Loss after 151 is 113.90817957557738\n","{'Validation Epoch Loss': 34.97159737814218, 'Epoch': 151, 'Micro F1': 0.8673111361676726, 'Patience Count': 0, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 34.97159737814218, 'Micro ROC value': 0.9405878952375276, 'Macro ROC value': 0.9405878952375276}\n","Training Epoch Loss after 152 is 113.93207882530987\n","{'Validation Epoch Loss': 34.97298969887197, 'Epoch': 152, 'Micro F1': 0.867287922000398, 'Patience Count': 1, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 34.97159737814218, 'Micro ROC value': 0.9405418790570597, 'Macro ROC value': 0.9405418790570597}\n","Training Epoch Loss after 153 is 113.88468524813652\n","{'Validation Epoch Loss': 34.97208206914365, 'Epoch': 153, 'Micro F1': 0.8673210850965046, 'Patience Count': 2, 'Best Val F1': 0.8675664920076939, 'Best Val Loss': 34.97159737814218, 'Micro ROC value': 0.9405545303769425, 'Macro ROC value': 0.9405545303769425}\n","Epoch   154: reducing learning rate of group 0 to 1.0000e-05.\n","Training Epoch Loss after 154 is 113.4623565543443\n","{'Validation Epoch Loss': 34.916754831094295, 'Epoch': 154, 'Micro F1': 0.8678417457053791, 'Patience Count': 0, 'Best Val F1': 0.8678417457053791, 'Best Val Loss': 34.916754831094295, 'Micro ROC value': 0.9405845368620556, 'Macro ROC value': 0.9405845368620556}\n","Training Epoch Loss after 155 is 113.3962809368968\n","{'Validation Epoch Loss': 34.90256986580789, 'Epoch': 155, 'Micro F1': 0.8681070504742323, 'Patience Count': 0, 'Best Val F1': 0.8681070504742323, 'Best Val Loss': 34.90256986580789, 'Micro ROC value': 0.9405860632133173, 'Macro ROC value': 0.9405860632133173}\n","Training Epoch Loss after 156 is 113.38138071075082\n","{'Validation Epoch Loss': 34.89699338702485, 'Epoch': 156, 'Micro F1': 0.8681999071433311, 'Patience Count': 0, 'Best Val F1': 0.8681999071433311, 'Best Val Loss': 34.89699338702485, 'Micro ROC value': 0.9405948806443487, 'Macro ROC value': 0.9405948806443487}\n","Training Epoch Loss after 157 is 113.37329300306737\n","{'Validation Epoch Loss': 34.894302655011415, 'Epoch': 157, 'Micro F1': 0.8683159779797042, 'Patience Count': 0, 'Best Val F1': 0.8683159779797042, 'Best Val Loss': 34.894302655011415, 'Micro ROC value': 0.9406069439393108, 'Macro ROC value': 0.9406069439393108}\n","Training Epoch Loss after 158 is 113.36671454645693\n","{'Validation Epoch Loss': 34.89271415909752, 'Epoch': 158, 'Micro F1': 0.8683657226238641, 'Patience Count': 0, 'Best Val F1': 0.8683657226238641, 'Best Val Loss': 34.89271415909752, 'Micro ROC value': 0.940618586881419, 'Macro ROC value': 0.940618586881419}\n","Training Epoch Loss after 159 is 113.36142103746533\n","{'Validation Epoch Loss': 34.89153543347493, 'Epoch': 159, 'Micro F1': 0.8683922531007495, 'Patience Count': 0, 'Best Val F1': 0.8683922531007495, 'Best Val Loss': 34.89153543347493, 'Micro ROC value': 0.9406292601665387, 'Macro ROC value': 0.9406292601665387}\n","Training Epoch Loss after 160 is 113.35584645159543\n","{'Validation Epoch Loss': 34.890556695405394, 'Epoch': 160, 'Micro F1': 0.8684055183391921, 'Patience Count': 0, 'Best Val F1': 0.8684055183391921, 'Best Val Loss': 34.890556695405394, 'Micro ROC value': 0.9406395371720706, 'Macro ROC value': 0.9406395371720706}\n","Training Epoch Loss after 161 is 113.35071460343897\n","{'Validation Epoch Loss': 34.88976116850972, 'Epoch': 161, 'Micro F1': 0.8684453140545201, 'Patience Count': 0, 'Best Val F1': 0.8684453140545201, 'Best Val Loss': 34.88976116850972, 'Micro ROC value': 0.9406489245066947, 'Macro ROC value': 0.9406489245066947}\n","Training Epoch Loss after 162 is 113.34603037498891\n","{'Validation Epoch Loss': 34.889037140179425, 'Epoch': 162, 'Micro F1': 0.8684652119121842, 'Patience Count': 0, 'Best Val F1': 0.8684652119121842, 'Best Val Loss': 34.889037140179425, 'Micro ROC value': 0.9406581060679985, 'Macro ROC value': 0.9406581060679985}\n","Training Epoch Loss after 163 is 113.34132691845298\n","{'Validation Epoch Loss': 34.88828702876344, 'Epoch': 163, 'Micro F1': 0.868514956556344, 'Patience Count': 0, 'Best Val F1': 0.868514956556344, 'Best Val Loss': 34.88828702876344, 'Micro ROC value': 0.9406683482248228, 'Macro ROC value': 0.9406683482248228}\n","Training Epoch Loss after 164 is 113.33660732582211\n","{'Validation Epoch Loss': 34.88770550908521, 'Epoch': 164, 'Micro F1': 0.8685547522716721, 'Patience Count': 0, 'Best Val F1': 0.8685547522716721, 'Best Val Loss': 34.88770550908521, 'Micro ROC value': 0.94067610185204, 'Macro ROC value': 0.94067610185204}\n","Training Epoch Loss after 165 is 113.33198532089591\n","{'Validation Epoch Loss': 34.88702556164935, 'Epoch': 165, 'Micro F1': 0.8685779664389467, 'Patience Count': 0, 'Best Val F1': 0.8685779664389467, 'Best Val Loss': 34.88702556164935, 'Micro ROC value': 0.9406846310455397, 'Macro ROC value': 0.9406846310455397}\n","Training Epoch Loss after 166 is 113.3275441005826\n","{'Validation Epoch Loss': 34.88645410025492, 'Epoch': 166, 'Micro F1': 0.8686044969158321, 'Patience Count': 0, 'Best Val F1': 0.8686044969158321, 'Best Val Loss': 34.88645410025492, 'Micro ROC value': 0.9406906439189712, 'Macro ROC value': 0.9406906439189712}\n","Training Epoch Loss after 167 is 113.32304408214986\n","{'Validation Epoch Loss': 34.885850249323994, 'Epoch': 167, 'Micro F1': 0.8686243947734961, 'Patience Count': 0, 'Best Val F1': 0.8686243947734961, 'Best Val Loss': 34.885850249323994, 'Micro ROC value': 0.9406984618448195, 'Macro ROC value': 0.9406984618448195}\n","Training Epoch Loss after 168 is 113.31861746683717\n","{'Validation Epoch Loss': 34.88529619621113, 'Epoch': 168, 'Micro F1': 0.8686907209657093, 'Patience Count': 0, 'Best Val F1': 0.8686907209657093, 'Best Val Loss': 34.88529619621113, 'Micro ROC value': 0.9407061566385679, 'Macro ROC value': 0.9407061566385679}\n","Training Epoch Loss after 169 is 113.31378881447017\n","{'Validation Epoch Loss': 34.884799694642425, 'Epoch': 169, 'Micro F1': 0.8686774557272667, 'Patience Count': 0, 'Best Val F1': 0.8686907209657093, 'Best Val Loss': 34.884799694642425, 'Micro ROC value': 0.9407116239914386, 'Macro ROC value': 0.9407116239914386}\n","Training Epoch Loss after 170 is 113.30971084348857\n","{'Validation Epoch Loss': 34.88430066220462, 'Epoch': 170, 'Micro F1': 0.8686807720368773, 'Patience Count': 0, 'Best Val F1': 0.8686907209657093, 'Best Val Loss': 34.88430066220462, 'Micro ROC value': 0.9407170638414881, 'Macro ROC value': 0.9407170638414881}\n","Training Epoch Loss after 171 is 113.30524832010269\n","{'Validation Epoch Loss': 34.883778906427324, 'Epoch': 171, 'Micro F1': 0.8687006698945413, 'Patience Count': 0, 'Best Val F1': 0.8687006698945413, 'Best Val Loss': 34.883778906427324, 'Micro ROC value': 0.9407233415208439, 'Macro ROC value': 0.9407233415208439}\n","Training Epoch Loss after 172 is 113.30083411745727\n","{'Validation Epoch Loss': 34.88323110854253, 'Epoch': 172, 'Micro F1': 0.868723884061816, 'Patience Count': 0, 'Best Val F1': 0.868723884061816, 'Best Val Loss': 34.88323110854253, 'Micro ROC value': 0.9407294255298908, 'Macro ROC value': 0.9407294255298908}\n","Training Epoch Loss after 173 is 113.29691618680954\n","{'Validation Epoch Loss': 34.88276513852179, 'Epoch': 173, 'Micro F1': 0.8687272003714267, 'Patience Count': 0, 'Best Val F1': 0.8687272003714267, 'Best Val Loss': 34.88276513852179, 'Micro ROC value': 0.9407337405521674, 'Macro ROC value': 0.9407337405521674}\n","Training Epoch Loss after 174 is 113.29235833510756\n","{'Validation Epoch Loss': 34.88233069796115, 'Epoch': 174, 'Micro F1': 0.8687504145387014, 'Patience Count': 0, 'Best Val F1': 0.8687504145387014, 'Best Val Loss': 34.88233069796115, 'Micro ROC value': 0.940739343914565, 'Macro ROC value': 0.940739343914565}\n","Training Epoch Loss after 175 is 113.28794272430241\n","{'Validation Epoch Loss': 34.88184070913121, 'Epoch': 175, 'Micro F1': 0.8687603634675334, 'Patience Count': 0, 'Best Val F1': 0.8687603634675334, 'Best Val Loss': 34.88184070913121, 'Micro ROC value': 0.9407448516919363, 'Macro ROC value': 0.9407448516919363}\n","Training Epoch Loss after 176 is 113.28366438671947\n","{'Validation Epoch Loss': 34.881379486992955, 'Epoch': 176, 'Micro F1': 0.8687769450155867, 'Patience Count': 0, 'Best Val F1': 0.8687769450155867, 'Best Val Loss': 34.881379486992955, 'Micro ROC value': 0.9407484212837649, 'Macro ROC value': 0.9407484212837649}\n","Training Epoch Loss after 177 is 113.27950040437281\n","{'Validation Epoch Loss': 34.88097031926736, 'Epoch': 177, 'Micro F1': 0.8687968428732507, 'Patience Count': 0, 'Best Val F1': 0.8687968428732507, 'Best Val Loss': 34.88097031926736, 'Micro ROC value': 0.9407528069770076, 'Macro ROC value': 0.9407528069770076}\n","Training Epoch Loss after 178 is 113.2756931297481\n","{'Validation Epoch Loss': 34.88052314100787, 'Epoch': 178, 'Micro F1': 0.86879352656364, 'Patience Count': 0, 'Best Val F1': 0.8687968428732507, 'Best Val Loss': 34.88052314100787, 'Micro ROC value': 0.940756422701887, 'Macro ROC value': 0.940756422701887}\n","Training Epoch Loss after 179 is 113.27107786387205\n","{'Validation Epoch Loss': 34.88011335581541, 'Epoch': 179, 'Micro F1': 0.8688067918020826, 'Patience Count': 0, 'Best Val F1': 0.8688067918020826, 'Best Val Loss': 34.88011335581541, 'Micro ROC value': 0.9407596253091681, 'Macro ROC value': 0.9407596253091681}\n","Training Epoch Loss after 180 is 113.2674693968147\n","{'Validation Epoch Loss': 34.87962712207809, 'Epoch': 180, 'Micro F1': 0.8688067918020826, 'Patience Count': 0, 'Best Val F1': 0.8688067918020826, 'Best Val Loss': 34.87962712207809, 'Micro ROC value': 0.9407642682411874, 'Macro ROC value': 0.9407642682411874}\n","Training Epoch Loss after 181 is 113.26317325234413\n","{'Validation Epoch Loss': 34.87913428945467, 'Epoch': 181, 'Micro F1': 0.8688101081116933, 'Patience Count': 0, 'Best Val F1': 0.8688101081116933, 'Best Val Loss': 34.87913428945467, 'Micro ROC value': 0.9407674497622347, 'Macro ROC value': 0.9407674497622347}\n","Training Epoch Loss after 182 is 113.25882054679096\n","{'Validation Epoch Loss': 34.87864608084783, 'Epoch': 182, 'Micro F1': 0.8688266896597466, 'Patience Count': 0, 'Best Val F1': 0.8688266896597466, 'Best Val Loss': 34.87864608084783, 'Micro ROC value': 0.9407708774368508, 'Macro ROC value': 0.9407708774368508}\n","Training Epoch Loss after 183 is 113.25442349538207\n","{'Validation Epoch Loss': 34.87831876287237, 'Epoch': 183, 'Micro F1': 0.8688233733501359, 'Patience Count': 0, 'Best Val F1': 0.8688266896597466, 'Best Val Loss': 34.87831876287237, 'Micro ROC value': 0.9407690893552012, 'Macro ROC value': 0.9407690893552012}\n","Training Epoch Loss after 184 is 113.25123459473252\n","{'Validation Epoch Loss': 34.87797649903223, 'Epoch': 184, 'Micro F1': 0.8688399548981893, 'Patience Count': 0, 'Best Val F1': 0.8688399548981893, 'Best Val Loss': 34.87797649903223, 'Micro ROC value': 0.9407735832896356, 'Macro ROC value': 0.9407735832896356}\n","Training Epoch Loss after 185 is 113.24689539335668\n","{'Validation Epoch Loss': 34.87747821910307, 'Epoch': 185, 'Micro F1': 0.8688499038270212, 'Patience Count': 0, 'Best Val F1': 0.8688499038270212, 'Best Val Loss': 34.87747821910307, 'Micro ROC value': 0.9407779738948865, 'Macro ROC value': 0.9407779738948865}\n","Training Epoch Loss after 186 is 113.24258864857256\n","{'Validation Epoch Loss': 34.876908659003675, 'Epoch': 186, 'Micro F1': 0.8688830669231279, 'Patience Count': 0, 'Best Val F1': 0.8688830669231279, 'Best Val Loss': 34.876908659003675, 'Micro ROC value': 0.940780869877794, 'Macro ROC value': 0.940780869877794}\n","Training Epoch Loss after 187 is 113.23805575072765\n","{'Validation Epoch Loss': 34.87670719856396, 'Epoch': 187, 'Micro F1': 0.8689162300192346, 'Patience Count': 0, 'Best Val F1': 0.8689162300192346, 'Best Val Loss': 34.87670719856396, 'Micro ROC value': 0.9407738526314235, 'Macro ROC value': 0.9407738526314235}\n","Training Epoch Loss after 188 is 113.23610816709697\n","{'Validation Epoch Loss': 34.87647737422958, 'Epoch': 188, 'Micro F1': 0.8689261789480665, 'Patience Count': 0, 'Best Val F1': 0.8689261789480665, 'Best Val Loss': 34.87647737422958, 'Micro ROC value': 0.9407791745490217, 'Macro ROC value': 0.9407791745490217}\n","Training Epoch Loss after 189 is 113.23192557133734\n","{'Validation Epoch Loss': 34.875923089217395, 'Epoch': 189, 'Micro F1': 0.8689162300192346, 'Patience Count': 0, 'Best Val F1': 0.8689261789480665, 'Best Val Loss': 34.875923089217395, 'Micro ROC value': 0.9407830109602557, 'Macro ROC value': 0.9407830109602557}\n","Training Epoch Loss after 190 is 113.22772999480367\n","{'Validation Epoch Loss': 34.87531624827534, 'Epoch': 190, 'Micro F1': 0.8689394441865094, 'Patience Count': 0, 'Best Val F1': 0.8689394441865094, 'Best Val Loss': 34.87531624827534, 'Micro ROC value': 0.940786985571507, 'Macro ROC value': 0.940786985571507}\n","Training Epoch Loss after 191 is 113.22315527126193\n","{'Validation Epoch Loss': 34.874661698471755, 'Epoch': 191, 'Micro F1': 0.868922862638456, 'Patience Count': 0, 'Best Val F1': 0.8689394441865094, 'Best Val Loss': 34.874661698471755, 'Micro ROC value': 0.9407898107728176, 'Macro ROC value': 0.9407898107728176}\n","Training Epoch Loss after 192 is 113.21955772861838\n","{'Validation Epoch Loss': 34.874057011678815, 'Epoch': 192, 'Micro F1': 0.8689394441865094, 'Patience Count': 0, 'Best Val F1': 0.8689394441865094, 'Best Val Loss': 34.874057011678815, 'Micro ROC value': 0.9407919303486485, 'Macro ROC value': 0.9407919303486485}\n","Training Epoch Loss after 193 is 113.21546725556254\n","{'Validation Epoch Loss': 34.87350626010448, 'Epoch': 193, 'Micro F1': 0.868952709424952, 'Patience Count': 0, 'Best Val F1': 0.868952709424952, 'Best Val Loss': 34.87350626010448, 'Micro ROC value': 0.9407938609227908, 'Macro ROC value': 0.9407938609227908}\n","Training Epoch Loss after 194 is 113.21104698255658\n","{'Validation Epoch Loss': 34.872866766527295, 'Epoch': 194, 'Micro F1': 0.8689692909730052, 'Patience Count': 0, 'Best Val F1': 0.8689692909730052, 'Best Val Loss': 34.872866766527295, 'Micro ROC value': 0.940796052519284, 'Macro ROC value': 0.940796052519284}\n","Training Epoch Loss after 195 is 113.20591044984758\n","{'Validation Epoch Loss': 34.87255428591743, 'Epoch': 195, 'Micro F1': 0.8689726072826159, 'Patience Count': 0, 'Best Val F1': 0.8689726072826159, 'Best Val Loss': 34.87255428591743, 'Micro ROC value': 0.9407892639689395, 'Macro ROC value': 0.9407892639689395}\n","Training Epoch Loss after 196 is 113.20460877008736\n","{'Validation Epoch Loss': 34.87228302843869, 'Epoch': 196, 'Micro F1': 0.8689825562114479, 'Patience Count': 0, 'Best Val F1': 0.8689825562114479, 'Best Val Loss': 34.87228302843869, 'Micro ROC value': 0.9407932925680296, 'Macro ROC value': 0.9407932925680296}\n","Training Epoch Loss after 197 is 113.20012893341482\n","{'Validation Epoch Loss': 34.87167614744976, 'Epoch': 197, 'Micro F1': 0.8689958214498905, 'Patience Count': 0, 'Best Val F1': 0.8689958214498905, 'Best Val Loss': 34.87167614744976, 'Micro ROC value': 0.9407969317023901, 'Macro ROC value': 0.9407969317023901}\n","Training Epoch Loss after 198 is 113.19631340354681\n","{'Validation Epoch Loss': 34.870992538519204, 'Epoch': 198, 'Micro F1': 0.8689991377595012, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.870992538519204, 'Micro ROC value': 0.9407994173998481, 'Macro ROC value': 0.9407994173998481}\n","Epoch   199: reducing learning rate of group 0 to 1.0000e-06.\n","Training Epoch Loss after 199 is 113.14141483791173\n","{'Validation Epoch Loss': 34.86981201823801, 'Epoch': 199, 'Micro F1': 0.8689825562114479, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.86981201823801, 'Micro ROC value': 0.9407978155762428, 'Macro ROC value': 0.9407978155762428}\n","Training Epoch Loss after 200 is 113.14090804941952\n","{'Validation Epoch Loss': 34.86876475904137, 'Epoch': 200, 'Micro F1': 0.8689925051402799, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.86876475904137, 'Micro ROC value': 0.9407964486218627, 'Macro ROC value': 0.9407964486218627}\n","Training Epoch Loss after 201 is 113.13993791677058\n","{'Validation Epoch Loss': 34.867759129963815, 'Epoch': 201, 'Micro F1': 0.8689593420441732, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.867759129963815, 'Micro ROC value': 0.9407949828962889, 'Macro ROC value': 0.9407949828962889}\n","Training Epoch Loss after 202 is 113.13926438614726\n","{'Validation Epoch Loss': 34.86696053901687, 'Epoch': 202, 'Micro F1': 0.8689560257345625, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.86696053901687, 'Micro ROC value': 0.9407935434565973, 'Macro ROC value': 0.9407935434565973}\n","Training Epoch Loss after 203 is 113.13824371807277\n","{'Validation Epoch Loss': 34.866111517418176, 'Epoch': 203, 'Micro F1': 0.868962658353784, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.866111517418176, 'Micro ROC value': 0.9407921761039464, 'Macro ROC value': 0.9407921761039464}\n","Training Epoch Loss after 204 is 113.13776818849146\n","{'Validation Epoch Loss': 34.86541146878153, 'Epoch': 204, 'Micro F1': 0.8689759235922264, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.86541146878153, 'Micro ROC value': 0.9407918674439657, 'Macro ROC value': 0.9407918674439657}\n","Training Epoch Loss after 205 is 113.13718380406499\n","{'Validation Epoch Loss': 34.86478931643069, 'Epoch': 205, 'Micro F1': 0.8689925051402799, 'Patience Count': 0, 'Best Val F1': 0.8689991377595012, 'Best Val Loss': 34.86478931643069, 'Micro ROC value': 0.9407907447181783, 'Macro ROC value': 0.9407907447181783}\n","Training Epoch Loss after 206 is 113.1365712210536\n","{'Validation Epoch Loss': 34.86418431531638, 'Epoch': 206, 'Micro F1': 0.8690190356171652, 'Patience Count': 0, 'Best Val F1': 0.8690190356171652, 'Best Val Loss': 34.86418431531638, 'Micro ROC value': 0.9407898288941455, 'Macro ROC value': 0.9407898288941455}\n","Training Epoch Loss after 207 is 113.13622806593776\n","{'Validation Epoch Loss': 34.8636507159099, 'Epoch': 207, 'Micro F1': 0.8690223519267759, 'Patience Count': 0, 'Best Val F1': 0.8690223519267759, 'Best Val Loss': 34.8636507159099, 'Micro ROC value': 0.9407899897292278, 'Macro ROC value': 0.9407899897292278}\n","Training Epoch Loss after 208 is 113.13560853525996\n","{'Validation Epoch Loss': 34.863185905851424, 'Epoch': 208, 'Micro F1': 0.8690256682363865, 'Patience Count': 0, 'Best Val F1': 0.8690256682363865, 'Best Val Loss': 34.863185905851424, 'Micro ROC value': 0.9407898329211073, 'Macro ROC value': 0.9407898329211073}\n","Training Epoch Loss after 209 is 113.1350882127881\n","{'Validation Epoch Loss': 34.8627195362933, 'Epoch': 209, 'Micro F1': 0.8690289845459972, 'Patience Count': 0, 'Best Val F1': 0.8690289845459972, 'Best Val Loss': 34.8627195362933, 'Micro ROC value': 0.9407891596219524, 'Macro ROC value': 0.9407891596219524}\n","Training Epoch Loss after 210 is 113.13466096483171\n","{'Validation Epoch Loss': 34.86228945758194, 'Epoch': 210, 'Micro F1': 0.8690323008556078, 'Patience Count': 0, 'Best Val F1': 0.8690323008556078, 'Best Val Loss': 34.86228945758194, 'Micro ROC value': 0.9407890558723718, 'Macro ROC value': 0.9407890558723718}\n","Training Epoch Loss after 211 is 113.1343773342669\n","{'Validation Epoch Loss': 34.86193478200585, 'Epoch': 211, 'Micro F1': 0.8690190356171652, 'Patience Count': 0, 'Best Val F1': 0.8690323008556078, 'Best Val Loss': 34.86193478200585, 'Micro ROC value': 0.940788312189891, 'Macro ROC value': 0.940788312189891}\n","Training Epoch Loss after 212 is 113.13375220261514\n","{'Validation Epoch Loss': 34.861606729216874, 'Epoch': 212, 'Micro F1': 0.8690190356171652, 'Patience Count': 0, 'Best Val F1': 0.8690323008556078, 'Best Val Loss': 34.861606729216874, 'Micro ROC value': 0.9407886317801963, 'Macro ROC value': 0.9407886317801963}\n","Training Epoch Loss after 213 is 113.13341880589724\n","{'Validation Epoch Loss': 34.861232423223555, 'Epoch': 213, 'Micro F1': 0.8690124029979439, 'Patience Count': 0, 'Best Val F1': 0.8690323008556078, 'Best Val Loss': 34.861232423223555, 'Micro ROC value': 0.940788972102717, 'Macro ROC value': 0.940788972102717}\n","Training Epoch Loss after 214 is 113.13258348964155\n","{'Validation Epoch Loss': 34.86096885567531, 'Epoch': 214, 'Micro F1': 0.8690124029979439, 'Patience Count': 0, 'Best Val F1': 0.8690323008556078, 'Best Val Loss': 34.86096885567531, 'Micro ROC value': 0.9407879358238501, 'Macro ROC value': 0.9407879358238501}\n","Training Epoch Loss after 215 is 113.13266164809465\n","{'Validation Epoch Loss': 34.860718661919236, 'Epoch': 215, 'Micro F1': 0.8690157193075545, 'Patience Count': 0, 'Best Val F1': 0.8690323008556078, 'Best Val Loss': 34.860718661919236, 'Micro ROC value': 0.9407886088353647, 'Macro ROC value': 0.9407886088353647}\n","Training Epoch Loss after 216 is 113.13213575445116\n","{'Validation Epoch Loss': 34.860462352633476, 'Epoch': 216, 'Micro F1': 0.8690223519267759, 'Patience Count': 0, 'Best Val F1': 0.8690323008556078, 'Best Val Loss': 34.860462352633476, 'Micro ROC value': 0.9407899247668119, 'Macro ROC value': 0.9407899247668119}\n","Training Epoch Loss after 217 is 113.13159203529358\n","{'Validation Epoch Loss': 34.860228694044054, 'Epoch': 217, 'Micro F1': 0.8690422497844399, 'Patience Count': 0, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407886051402956, 'Macro ROC value': 0.9407886051402956}\n","Epoch   218: reducing learning rate of group 0 to 1.0000e-07.\n","Training Epoch Loss after 218 is 113.12598043307662\n","{'Validation Epoch Loss': 34.86026218859479, 'Epoch': 218, 'Micro F1': 0.8690422497844399, 'Patience Count': 1, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.940788740950687, 'Macro ROC value': 0.940788740950687}\n","Training Epoch Loss after 219 is 113.12600544840097\n","{'Validation Epoch Loss': 34.860316737089306, 'Epoch': 219, 'Micro F1': 0.8690356171652186, 'Patience Count': 2, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407883812677734, 'Macro ROC value': 0.9407883812677734}\n","Training Epoch Loss after 220 is 113.12596812099218\n","{'Validation Epoch Loss': 34.86034243134782, 'Epoch': 220, 'Micro F1': 0.8690323008556078, 'Patience Count': 3, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407882429792516, 'Macro ROC value': 0.9407882429792516}\n","Training Epoch Loss after 221 is 113.12588470056653\n","{'Validation Epoch Loss': 34.86037511518225, 'Epoch': 221, 'Micro F1': 0.8690289845459972, 'Patience Count': 4, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407882947544741, 'Macro ROC value': 0.9407882947544741}\n","Training Epoch Loss after 222 is 113.12559384293854\n","{'Validation Epoch Loss': 34.86045118421316, 'Epoch': 222, 'Micro F1': 0.8690356171652186, 'Patience Count': 5, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407881955850095, 'Macro ROC value': 0.9407881955850095}\n","Training Epoch Loss after 223 is 113.1255974136293\n","{'Validation Epoch Loss': 34.86053545586765, 'Epoch': 223, 'Micro F1': 0.8690389334748292, 'Patience Count': 6, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407879652295215, 'Macro ROC value': 0.9407879652295215}\n","Training Epoch Loss after 224 is 113.1255273129791\n","{'Validation Epoch Loss': 34.860565337818116, 'Epoch': 224, 'Micro F1': 0.8690389334748292, 'Patience Count': 7, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407870839001775, 'Macro ROC value': 0.9407870839001775}\n","Training Epoch Loss after 225 is 113.1256469860673\n","{'Validation Epoch Loss': 34.86060822894797, 'Epoch': 225, 'Micro F1': 0.8690422497844399, 'Patience Count': 8, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407870365059354, 'Macro ROC value': 0.9407870365059354}\n","Training Epoch Loss after 226 is 113.12547029182315\n","{'Validation Epoch Loss': 34.86063516465947, 'Epoch': 226, 'Micro F1': 0.8690422497844399, 'Patience Count': 9, 'Best Val F1': 0.8690422497844399, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407873510072231, 'Macro ROC value': 0.9407873510072231}\n","Training Epoch Loss after 227 is 113.12572402320802\n","{'Validation Epoch Loss': 34.86067422106862, 'Epoch': 227, 'Micro F1': 0.8690488824036613, 'Patience Count': 0, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407865165853458, 'Macro ROC value': 0.9407865165853458}\n","Training Epoch Loss after 228 is 113.12562147900462\n","{'Validation Epoch Loss': 34.86073427507654, 'Epoch': 228, 'Micro F1': 0.8690422497844399, 'Patience Count': 1, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407864887506321, 'Macro ROC value': 0.9407864887506321}\n","Epoch   229: reducing learning rate of group 0 to 1.0000e-08.\n","Training Epoch Loss after 229 is 113.12540021724999\n","{'Validation Epoch Loss': 34.86073092278093, 'Epoch': 229, 'Micro F1': 0.8690422497844399, 'Patience Count': 2, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407864743243735, 'Macro ROC value': 0.9407864743243735}\n","Training Epoch Loss after 230 is 113.12540193088353\n","{'Validation Epoch Loss': 34.86073231184855, 'Epoch': 230, 'Micro F1': 0.8690422497844399, 'Patience Count': 3, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407864719126218, 'Macro ROC value': 0.9407864719126218}\n","Training Epoch Loss after 231 is 113.12541355378926\n","{'Validation Epoch Loss': 34.86073600128293, 'Epoch': 231, 'Micro F1': 0.8690389334748292, 'Patience Count': 4, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407864117294571, 'Macro ROC value': 0.9407864117294571}\n","Training Epoch Loss after 232 is 113.12541734799743\n","{'Validation Epoch Loss': 34.8607365465723, 'Epoch': 232, 'Micro F1': 0.8690389334748292, 'Patience Count': 5, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407866190073566, 'Macro ROC value': 0.9407866190073566}\n","Training Epoch Loss after 233 is 113.12540816515684\n","{'Validation Epoch Loss': 34.86073787789792, 'Epoch': 233, 'Micro F1': 0.8690389334748292, 'Patience Count': 6, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407866015055613, 'Macro ROC value': 0.9407866015055613}\n","Training Epoch Loss after 234 is 113.12540435045958\n","{'Validation Epoch Loss': 34.86073703691363, 'Epoch': 234, 'Micro F1': 0.8690389334748292, 'Patience Count': 7, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407866011072903, 'Macro ROC value': 0.9407866011072903}\n","Training Epoch Loss after 235 is 113.12541997432709\n","{'Validation Epoch Loss': 34.86073885532096, 'Epoch': 235, 'Micro F1': 0.8690389334748292, 'Patience Count': 8, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407865910177597, 'Macro ROC value': 0.9407865910177597}\n","Training Epoch Loss after 236 is 113.12541393004358\n","{'Validation Epoch Loss': 34.860732750501484, 'Epoch': 236, 'Micro F1': 0.8690422497844399, 'Patience Count': 9, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407866482360185, 'Macro ROC value': 0.9407866482360185}\n","Training Epoch Loss after 237 is 113.12541840784252\n","{'Validation Epoch Loss': 34.86074299644679, 'Epoch': 237, 'Micro F1': 0.8690422497844399, 'Patience Count': 10, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407865896459376, 'Macro ROC value': 0.9407865896459376}\n","Training Epoch Loss after 238 is 113.12541654519737\n","{'Validation Epoch Loss': 34.86074208188802, 'Epoch': 238, 'Micro F1': 0.8690422497844399, 'Patience Count': 11, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407865957748849, 'Macro ROC value': 0.9407865957748849}\n","Training Epoch Loss after 239 is 113.12541589140892\n","{'Validation Epoch Loss': 34.860744749195874, 'Epoch': 239, 'Micro F1': 0.8690422497844399, 'Patience Count': 12, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.940786033571197, 'Macro ROC value': 0.940786033571197}\n","Training Epoch Loss after 240 is 113.125422867015\n","{'Validation Epoch Loss': 34.860745635814965, 'Epoch': 240, 'Micro F1': 0.8690422497844399, 'Patience Count': 13, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407860324206365, 'Macro ROC value': 0.9407860324206365}\n","Training Epoch Loss after 241 is 113.12540982104838\n","{'Validation Epoch Loss': 34.86074438132346, 'Epoch': 241, 'Micro F1': 0.8690422497844399, 'Patience Count': 14, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407860227072506, 'Macro ROC value': 0.9407860227072506}\n","Training Epoch Loss after 242 is 113.12542354129255\n","{'Validation Epoch Loss': 34.860741974785924, 'Epoch': 242, 'Micro F1': 0.8690422497844399, 'Patience Count': 15, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407861865072389, 'Macro ROC value': 0.9407861865072389}\n","Training Epoch Loss after 243 is 113.12541600689292\n","{'Validation Epoch Loss': 34.86073735309765, 'Epoch': 243, 'Micro F1': 0.8690422497844399, 'Patience Count': 16, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407862104920002, 'Macro ROC value': 0.9407862104920002}\n","Training Epoch Loss after 244 is 113.12541116029024\n","{'Validation Epoch Loss': 34.860737584065646, 'Epoch': 244, 'Micro F1': 0.8690422497844399, 'Patience Count': 17, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407863088427968, 'Macro ROC value': 0.9407863088427968}\n","Training Epoch Loss after 245 is 113.12541642971337\n","{'Validation Epoch Loss': 34.86074029747397, 'Epoch': 245, 'Micro F1': 0.8690422497844399, 'Patience Count': 18, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407862922703004, 'Macro ROC value': 0.9407862922703004}\n","Training Epoch Loss after 246 is 113.12542715854943\n","{'Validation Epoch Loss': 34.86073992494494, 'Epoch': 246, 'Micro F1': 0.8690422497844399, 'Patience Count': 19, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407862958547388, 'Macro ROC value': 0.9407862958547388}\n","Training Epoch Loss after 247 is 113.12540565989912\n","{'Validation Epoch Loss': 34.860741985961795, 'Epoch': 247, 'Micro F1': 0.8690455660940506, 'Patience Count': 20, 'Best Val F1': 0.8690488824036613, 'Best Val Loss': 34.860228694044054, 'Micro ROC value': 0.9407862789724761, 'Macro ROC value': 0.9407862789724761}\n","Testing stats.\n","\n","\n","\n","{'Micro F1': 0.8807742777781479, 'Micro Recall': 0.8807742777781479, 'Micro Precision': 0.8807742777781479, 'Micro ROC_AUC_Score': 0.9475180388661505, 'Macro ROC_AUC_Score': 0.9475180388661505}\n","\n","\n","\n","\n","Training Epoch Loss after 0 is 340.2901024520397\n","{'Validation Epoch Loss': 77.4749048948288, 'Epoch': 0, 'Micro F1': 0.5687321806763095, 'Patience Count': 0, 'Best Val F1': 0.5687321806763095, 'Best Val Loss': 77.4749048948288, 'Micro ROC value': 0.5764070082586343, 'Macro ROC value': 0.5764070082586343}\n","Training Epoch Loss after 1 is 330.9831433147192\n","{'Validation Epoch Loss': 78.32162091135979, 'Epoch': 1, 'Micro F1': 0.5627536301364068, 'Patience Count': 1, 'Best Val F1': 0.5687321806763095, 'Best Val Loss': 77.4749048948288, 'Micro ROC value': 0.5730202893818588, 'Macro ROC value': 0.5730202893818588}\n","Training Epoch Loss after 2 is 338.9779455065727\n","{'Validation Epoch Loss': 78.78112807869911, 'Epoch': 2, 'Micro F1': 0.5510052143112963, 'Patience Count': 2, 'Best Val F1': 0.5687321806763095, 'Best Val Loss': 77.4749048948288, 'Micro ROC value': 0.5840763452681745, 'Macro ROC value': 0.5840763452681745}\n","Training Epoch Loss after 3 is 328.8257623165846\n","{'Validation Epoch Loss': 79.10511475801468, 'Epoch': 3, 'Micro F1': 0.5699137904292431, 'Patience Count': 0, 'Best Val F1': 0.5699137904292431, 'Best Val Loss': 77.4749048948288, 'Micro ROC value': 0.5896541948383817, 'Macro ROC value': 0.5896541948383817}\n","Training Epoch Loss after 4 is 322.6163309812546\n","{'Validation Epoch Loss': 77.2316162288189, 'Epoch': 4, 'Micro F1': 0.5629848759591767, 'Patience Count': 0, 'Best Val F1': 0.5699137904292431, 'Best Val Loss': 77.2316162288189, 'Micro ROC value': 0.5695511028791512, 'Macro ROC value': 0.5695511028791512}\n","Training Epoch Loss after 5 is 333.55658443272114\n","{'Validation Epoch Loss': 78.14478576183319, 'Epoch': 5, 'Micro F1': 0.5659515906610528, 'Patience Count': 1, 'Best Val F1': 0.5699137904292431, 'Best Val Loss': 77.2316162288189, 'Micro ROC value': 0.57027212066588, 'Macro ROC value': 0.57027212066588}\n","Training Epoch Loss after 6 is 319.7961160391569\n","{'Validation Epoch Loss': 80.56142631173134, 'Epoch': 6, 'Micro F1': 0.5382274725677593, 'Patience Count': 2, 'Best Val F1': 0.5699137904292431, 'Best Val Loss': 77.2316162288189, 'Micro ROC value': 0.5846828644040641, 'Macro ROC value': 0.5846828644040641}\n","Training Epoch Loss after 7 is 312.4353451579809\n","{'Validation Epoch Loss': 76.76464873552322, 'Epoch': 7, 'Micro F1': 0.5766170992185583, 'Patience Count': 0, 'Best Val F1': 0.5766170992185583, 'Best Val Loss': 76.76464873552322, 'Micro ROC value': 0.5899641291209601, 'Macro ROC value': 0.5899641291209601}\n","Training Epoch Loss after 8 is 311.1946111321449\n","{'Validation Epoch Loss': 76.74724066257477, 'Epoch': 8, 'Micro F1': 0.578134297421609, 'Patience Count': 0, 'Best Val F1': 0.578134297421609, 'Best Val Loss': 76.74724066257477, 'Micro ROC value': 0.5960920314691641, 'Macro ROC value': 0.5960920314691641}\n","Training Epoch Loss after 9 is 307.9907470345497\n","{'Validation Epoch Loss': 76.73993590474129, 'Epoch': 9, 'Micro F1': 0.5752493647790051, 'Patience Count': 0, 'Best Val F1': 0.578134297421609, 'Best Val Loss': 76.73993590474129, 'Micro ROC value': 0.5982812988876289, 'Macro ROC value': 0.5982812988876289}\n","Training Epoch Loss after 10 is 306.76248137652874\n","{'Validation Epoch Loss': 76.85046476125717, 'Epoch': 10, 'Micro F1': 0.5769075665325253, 'Patience Count': 1, 'Best Val F1': 0.578134297421609, 'Best Val Loss': 76.73993590474129, 'Micro ROC value': 0.5976424797239471, 'Macro ROC value': 0.5976424797239471}\n","Training Epoch Loss after 11 is 306.54606303572655\n","{'Validation Epoch Loss': 76.4416860640049, 'Epoch': 11, 'Micro F1': 0.5786080693511862, 'Patience Count': 0, 'Best Val F1': 0.5786080693511862, 'Best Val Loss': 76.4416860640049, 'Micro ROC value': 0.5979894629129535, 'Macro ROC value': 0.5979894629129535}\n","Training Epoch Loss after 12 is 304.6363522410393\n","{'Validation Epoch Loss': 75.78610321879387, 'Epoch': 12, 'Micro F1': 0.5811771540407388, 'Patience Count': 0, 'Best Val F1': 0.5811771540407388, 'Best Val Loss': 75.78610321879387, 'Micro ROC value': 0.5989402682082734, 'Macro ROC value': 0.5989402682082734}\n","Training Epoch Loss after 13 is 300.56062310934067\n","{'Validation Epoch Loss': 73.32629349827766, 'Epoch': 13, 'Micro F1': 0.5815691439110436, 'Patience Count': 0, 'Best Val F1': 0.5815691439110436, 'Best Val Loss': 73.32629349827766, 'Micro ROC value': 0.6142501646624303, 'Macro ROC value': 0.6142501646624303}\n","Training Epoch Loss after 14 is 288.35791248083115\n","{'Validation Epoch Loss': 69.86684942245483, 'Epoch': 14, 'Micro F1': 0.6244257630407134, 'Patience Count': 0, 'Best Val F1': 0.6244257630407134, 'Best Val Loss': 69.86684942245483, 'Micro ROC value': 0.6442184101967374, 'Macro ROC value': 0.6442184101967374}\n","Training Epoch Loss after 15 is 274.30664061009884\n","{'Validation Epoch Loss': 64.79763892292976, 'Epoch': 15, 'Micro F1': 0.6319327920677043, 'Patience Count': 0, 'Best Val F1': 0.6319327920677043, 'Best Val Loss': 64.79763892292976, 'Micro ROC value': 0.6729975345794417, 'Macro ROC value': 0.6729975345794417}\n","Training Epoch Loss after 16 is 260.0287157446146\n","{'Validation Epoch Loss': 61.634190022945404, 'Epoch': 16, 'Micro F1': 0.658582463106421, 'Patience Count': 0, 'Best Val F1': 0.658582463106421, 'Best Val Loss': 61.634190022945404, 'Micro ROC value': 0.6954284556455511, 'Macro ROC value': 0.6954284556455511}\n","Training Epoch Loss after 17 is 270.5182485729456\n","{'Validation Epoch Loss': 60.50962062180042, 'Epoch': 17, 'Micro F1': 0.6446005510418752, 'Patience Count': 0, 'Best Val F1': 0.658582463106421, 'Best Val Loss': 60.50962062180042, 'Micro ROC value': 0.6855963644454736, 'Macro ROC value': 0.6855963644454736}\n","Training Epoch Loss after 18 is 245.4739501029253\n","{'Validation Epoch Loss': 54.705061703920364, 'Epoch': 18, 'Micro F1': 0.6991181637953644, 'Patience Count': 0, 'Best Val F1': 0.6991181637953644, 'Best Val Loss': 54.705061703920364, 'Micro ROC value': 0.7337333229720303, 'Macro ROC value': 0.7337333229720303}\n","Training Epoch Loss after 19 is 243.30934298038483\n","{'Validation Epoch Loss': 51.497420862317085, 'Epoch': 19, 'Micro F1': 0.689295856469666, 'Patience Count': 0, 'Best Val F1': 0.6991181637953644, 'Best Val Loss': 51.497420862317085, 'Micro ROC value': 0.7310759025630924, 'Macro ROC value': 0.7310759025630924}\n","Training Epoch Loss after 20 is 233.45998410880566\n","{'Validation Epoch Loss': 49.731085792183876, 'Epoch': 20, 'Micro F1': 0.6924402356451336, 'Patience Count': 0, 'Best Val F1': 0.6991181637953644, 'Best Val Loss': 49.731085792183876, 'Micro ROC value': 0.7419989590444027, 'Macro ROC value': 0.7419989590444027}\n","Training Epoch Loss after 21 is 220.9189771786332\n","{'Validation Epoch Loss': 54.820963606238365, 'Epoch': 21, 'Micro F1': 0.6831481016692, 'Patience Count': 1, 'Best Val F1': 0.6991181637953644, 'Best Val Loss': 49.731085792183876, 'Micro ROC value': 0.7269475829545803, 'Macro ROC value': 0.7269475829545803}\n","Training Epoch Loss after 22 is 223.40673277527094\n","{'Validation Epoch Loss': 48.23919415473938, 'Epoch': 22, 'Micro F1': 0.6742056564984307, 'Patience Count': 0, 'Best Val F1': 0.6991181637953644, 'Best Val Loss': 48.23919415473938, 'Micro ROC value': 0.7281742527371402, 'Macro ROC value': 0.7281742527371402}\n","Training Epoch Loss after 23 is 220.57233672589064\n","{'Validation Epoch Loss': 56.99413211643696, 'Epoch': 23, 'Micro F1': 0.6320230343400047, 'Patience Count': 1, 'Best Val F1': 0.6991181637953644, 'Best Val Loss': 48.23919415473938, 'Micro ROC value': 0.6867041948726884, 'Macro ROC value': 0.6867041948726884}\n","Training Epoch Loss after 24 is 224.6167812421918\n","{'Validation Epoch Loss': 50.880405977368355, 'Epoch': 24, 'Micro F1': 0.6842028082267112, 'Patience Count': 2, 'Best Val F1': 0.6991181637953644, 'Best Val Loss': 48.23919415473938, 'Micro ROC value': 0.7228979795217585, 'Macro ROC value': 0.7228979795217585}\n","Training Epoch Loss after 25 is 214.77529135346413\n","{'Validation Epoch Loss': 45.853790268301964, 'Epoch': 25, 'Micro F1': 0.7025107092196582, 'Patience Count': 0, 'Best Val F1': 0.7025107092196582, 'Best Val Loss': 45.853790268301964, 'Micro ROC value': 0.7633420669855797, 'Macro ROC value': 0.7633420669855797}\n","Training Epoch Loss after 26 is 208.0510996170342\n","{'Validation Epoch Loss': 58.56221853196621, 'Epoch': 26, 'Micro F1': 0.6652068099074735, 'Patience Count': 1, 'Best Val F1': 0.7025107092196582, 'Best Val Loss': 45.853790268301964, 'Micro ROC value': 0.7124260699953344, 'Macro ROC value': 0.7124260699953344}\n","Training Epoch Loss after 27 is 204.93394775688648\n","{'Validation Epoch Loss': 44.46871717274189, 'Epoch': 27, 'Micro F1': 0.7333087047131847, 'Patience Count': 0, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 44.46871717274189, 'Micro ROC value': 0.7749671176566175, 'Macro ROC value': 0.7749671176566175}\n","Training Epoch Loss after 28 is 197.83953032642603\n","{'Validation Epoch Loss': 44.6326060295105, 'Epoch': 28, 'Micro F1': 0.7053533407971213, 'Patience Count': 1, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 44.46871717274189, 'Micro ROC value': 0.7766213637620771, 'Macro ROC value': 0.7766213637620771}\n","Training Epoch Loss after 29 is 205.55694099515676\n","{'Validation Epoch Loss': 46.22260234504938, 'Epoch': 29, 'Micro F1': 0.7192675711574418, 'Patience Count': 2, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 44.46871717274189, 'Micro ROC value': 0.7793687400118176, 'Macro ROC value': 0.7793687400118176}\n","Training Epoch Loss after 30 is 209.77673323452473\n","{'Validation Epoch Loss': 51.02361024916172, 'Epoch': 30, 'Micro F1': 0.68273355123082, 'Patience Count': 3, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 44.46871717274189, 'Micro ROC value': 0.7278902402643644, 'Macro ROC value': 0.7278902402643644}\n","Training Epoch Loss after 31 is 211.1311644911766\n","{'Validation Epoch Loss': 46.21115888655186, 'Epoch': 31, 'Micro F1': 0.7150064438622563, 'Patience Count': 4, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 44.46871717274189, 'Micro ROC value': 0.7556282600617076, 'Macro ROC value': 0.7556282600617076}\n","Training Epoch Loss after 32 is 188.82174307852983\n","{'Validation Epoch Loss': 40.41456551849842, 'Epoch': 32, 'Micro F1': 0.7330548983223396, 'Patience Count': 0, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7924390782525079, 'Macro ROC value': 0.7924390782525079}\n","Training Epoch Loss after 33 is 185.62739815935493\n","{'Validation Epoch Loss': 42.102426782250404, 'Epoch': 33, 'Micro F1': 0.729008096423868, 'Patience Count': 1, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7878973678756729, 'Macro ROC value': 0.7878973678756729}\n","Training Epoch Loss after 34 is 186.2128871642053\n","{'Validation Epoch Loss': 55.656359776854515, 'Epoch': 34, 'Micro F1': 0.6896681058429052, 'Patience Count': 2, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7301757689022526, 'Macro ROC value': 0.7301757689022526}\n","Training Epoch Loss after 35 is 213.73303461819887\n","{'Validation Epoch Loss': 45.74047815054655, 'Epoch': 35, 'Micro F1': 0.709036353535382, 'Patience Count': 3, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7549534055216615, 'Macro ROC value': 0.7549534055216615}\n","Training Epoch Loss after 36 is 208.7632026821375\n","{'Validation Epoch Loss': 48.67813837528229, 'Epoch': 36, 'Micro F1': 0.690866636021895, 'Patience Count': 4, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.730450116586805, 'Macro ROC value': 0.730450116586805}\n","Training Epoch Loss after 37 is 204.51488856226206\n","{'Validation Epoch Loss': 47.21134854853153, 'Epoch': 37, 'Micro F1': 0.7186725361744609, 'Patience Count': 5, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7731394696534528, 'Macro ROC value': 0.7731394696534528}\n","Training Epoch Loss after 38 is 209.42462322860956\n","{'Validation Epoch Loss': 52.80200484395027, 'Epoch': 38, 'Micro F1': 0.6713066235007797, 'Patience Count': 6, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7133155496813204, 'Macro ROC value': 0.7133155496813204}\n","Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n","Training Epoch Loss after 39 is 213.0130789577961\n","{'Validation Epoch Loss': 48.63386479020119, 'Epoch': 39, 'Micro F1': 0.7068479784320969, 'Patience Count': 7, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7400100122686067, 'Macro ROC value': 0.7400100122686067}\n","Training Epoch Loss after 40 is 204.00174690783024\n","{'Validation Epoch Loss': 47.5248448997736, 'Epoch': 40, 'Micro F1': 0.7128547296820934, 'Patience Count': 8, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7419374916544627, 'Macro ROC value': 0.7419374916544627}\n","Training Epoch Loss after 41 is 198.19889697432518\n","{'Validation Epoch Loss': 46.23235768079758, 'Epoch': 41, 'Micro F1': 0.7165574829174198, 'Patience Count': 9, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7526539886531993, 'Macro ROC value': 0.7526539886531993}\n","Training Epoch Loss after 42 is 194.0343633443117\n","{'Validation Epoch Loss': 45.596234023571014, 'Epoch': 42, 'Micro F1': 0.7198372255013381, 'Patience Count': 10, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.756307124203756, 'Macro ROC value': 0.756307124203756}\n","Training Epoch Loss after 43 is 190.66821637004614\n","{'Validation Epoch Loss': 45.01748774200678, 'Epoch': 43, 'Micro F1': 0.7235033178135425, 'Patience Count': 11, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.75856959984968, 'Macro ROC value': 0.75856959984968}\n","Training Epoch Loss after 44 is 188.03972871601582\n","{'Validation Epoch Loss': 44.782150372862816, 'Epoch': 44, 'Micro F1': 0.7246990279215231, 'Patience Count': 12, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7582449846634496, 'Macro ROC value': 0.7582449846634496}\n","Training Epoch Loss after 45 is 185.65552034974098\n","{'Validation Epoch Loss': 44.1534972935915, 'Epoch': 45, 'Micro F1': 0.7284046012278589, 'Patience Count': 13, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7612589850789344, 'Macro ROC value': 0.7612589850789344}\n","Training Epoch Loss after 46 is 183.09895354509354\n","{'Validation Epoch Loss': 43.65018128603697, 'Epoch': 46, 'Micro F1': 0.7321045343921759, 'Patience Count': 14, 'Best Val F1': 0.7333087047131847, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7686087185308443, 'Macro ROC value': 0.7686087185308443}\n","Training Epoch Loss after 47 is 180.69136542081833\n","{'Validation Epoch Loss': 43.07223814725876, 'Epoch': 47, 'Micro F1': 0.7376685344936986, 'Patience Count': 0, 'Best Val F1': 0.7376685344936986, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7746865663426282, 'Macro ROC value': 0.7746865663426282}\n","Training Epoch Loss after 48 is 178.15218295156956\n","{'Validation Epoch Loss': 42.61834205687046, 'Epoch': 48, 'Micro F1': 0.74328329587339, 'Patience Count': 0, 'Best Val F1': 0.74328329587339, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7782234046445385, 'Macro ROC value': 0.7782234046445385}\n","Training Epoch Loss after 49 is 176.7572456896305\n","{'Validation Epoch Loss': 42.31661964207888, 'Epoch': 49, 'Micro F1': 0.7453927089884124, 'Patience Count': 0, 'Best Val F1': 0.7453927089884124, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7789239283477433, 'Macro ROC value': 0.7789239283477433}\n","Training Epoch Loss after 50 is 174.52030202001333\n","{'Validation Epoch Loss': 42.01422284543514, 'Epoch': 50, 'Micro F1': 0.742578278121043, 'Patience Count': 1, 'Best Val F1': 0.7453927089884124, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7779722818834091, 'Macro ROC value': 0.7779722818834091}\n","Training Epoch Loss after 51 is 172.7660680115223\n","{'Validation Epoch Loss': 41.56544775515795, 'Epoch': 51, 'Micro F1': 0.747127052659186, 'Patience Count': 0, 'Best Val F1': 0.747127052659186, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7837399920256223, 'Macro ROC value': 0.7837399920256223}\n","Training Epoch Loss after 52 is 171.95625852793455\n","{'Validation Epoch Loss': 41.418873339891434, 'Epoch': 52, 'Micro F1': 0.749177244283011, 'Patience Count': 0, 'Best Val F1': 0.749177244283011, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7796636327101734, 'Macro ROC value': 0.7796636327101734}\n","Training Epoch Loss after 53 is 170.44401651620865\n","{'Validation Epoch Loss': 41.198437944054604, 'Epoch': 53, 'Micro F1': 0.7491462235019077, 'Patience Count': 1, 'Best Val F1': 0.749177244283011, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7829145372537822, 'Macro ROC value': 0.7829145372537822}\n","Training Epoch Loss after 54 is 168.40709295868874\n","{'Validation Epoch Loss': 40.697472400963306, 'Epoch': 54, 'Micro F1': 0.74867527164334, 'Patience Count': 2, 'Best Val F1': 0.749177244283011, 'Best Val Loss': 40.41456551849842, 'Micro ROC value': 0.7843429414596557, 'Macro ROC value': 0.7843429414596557}\n","Training Epoch Loss after 55 is 166.98965075612068\n","{'Validation Epoch Loss': 40.248232930898666, 'Epoch': 55, 'Micro F1': 0.7489318981051942, 'Patience Count': 0, 'Best Val F1': 0.749177244283011, 'Best Val Loss': 40.248232930898666, 'Micro ROC value': 0.7876726565773765, 'Macro ROC value': 0.7876726565773765}\n","Training Epoch Loss after 56 is 165.56876453757286\n","{'Validation Epoch Loss': 39.92077035456896, 'Epoch': 56, 'Micro F1': 0.7538895829396984, 'Patience Count': 0, 'Best Val F1': 0.7538895829396984, 'Best Val Loss': 39.92077035456896, 'Micro ROC value': 0.7935242366227011, 'Macro ROC value': 0.7935242366227011}\n","Training Epoch Loss after 57 is 164.8516191765666\n","{'Validation Epoch Loss': 39.7348161265254, 'Epoch': 57, 'Micro F1': 0.7575838759619968, 'Patience Count': 0, 'Best Val F1': 0.7575838759619968, 'Best Val Loss': 39.7348161265254, 'Micro ROC value': 0.7949502143770465, 'Macro ROC value': 0.7949502143770465}\n","Training Epoch Loss after 58 is 163.51443907618523\n","{'Validation Epoch Loss': 39.24058149009943, 'Epoch': 58, 'Micro F1': 0.7582776134303061, 'Patience Count': 0, 'Best Val F1': 0.7582776134303061, 'Best Val Loss': 39.24058149009943, 'Micro ROC value': 0.7965825642649997, 'Macro ROC value': 0.7965825642649997}\n","Training Epoch Loss after 59 is 162.18002446740866\n","{'Validation Epoch Loss': 39.24756257236004, 'Epoch': 59, 'Micro F1': 0.759766610923263, 'Patience Count': 0, 'Best Val F1': 0.759766610923263, 'Best Val Loss': 39.24058149009943, 'Micro ROC value': 0.7985827023054365, 'Macro ROC value': 0.7985827023054365}\n","Training Epoch Loss after 60 is 161.28133350610733\n","{'Validation Epoch Loss': 38.45265594869852, 'Epoch': 60, 'Micro F1': 0.7613120098364076, 'Patience Count': 0, 'Best Val F1': 0.7613120098364076, 'Best Val Loss': 38.45265594869852, 'Micro ROC value': 0.8057269153097523, 'Macro ROC value': 0.8057269153097523}\n","Training Epoch Loss after 61 is 160.17864403128624\n","{'Validation Epoch Loss': 38.35658831894398, 'Epoch': 61, 'Micro F1': 0.7611851066409853, 'Patience Count': 0, 'Best Val F1': 0.7613120098364076, 'Best Val Loss': 38.35658831894398, 'Micro ROC value': 0.8048367109691026, 'Macro ROC value': 0.8048367109691026}\n","Training Epoch Loss after 62 is 159.09134005755186\n","{'Validation Epoch Loss': 38.006337374448776, 'Epoch': 62, 'Micro F1': 0.7617970620500224, 'Patience Count': 0, 'Best Val F1': 0.7617970620500224, 'Best Val Loss': 38.006337374448776, 'Micro ROC value': 0.8103321498260955, 'Macro ROC value': 0.8103321498260955}\n","Training Epoch Loss after 63 is 158.10607490688562\n","{'Validation Epoch Loss': 38.02595688402653, 'Epoch': 63, 'Micro F1': 0.7615742764402808, 'Patience Count': 1, 'Best Val F1': 0.7617970620500224, 'Best Val Loss': 38.006337374448776, 'Micro ROC value': 0.805408471438245, 'Macro ROC value': 0.805408471438245}\n","Training Epoch Loss after 64 is 158.1036446094513\n","{'Validation Epoch Loss': 37.182288229465485, 'Epoch': 64, 'Micro F1': 0.763748551188519, 'Patience Count': 0, 'Best Val F1': 0.763748551188519, 'Best Val Loss': 37.182288229465485, 'Micro ROC value': 0.818652956040176, 'Macro ROC value': 0.818652956040176}\n","Training Epoch Loss after 65 is 156.57035951316357\n","{'Validation Epoch Loss': 37.14297056943178, 'Epoch': 65, 'Micro F1': 0.7664388989314751, 'Patience Count': 0, 'Best Val F1': 0.7664388989314751, 'Best Val Loss': 37.14297056943178, 'Micro ROC value': 0.8220454060451357, 'Macro ROC value': 0.8220454060451357}\n","Training Epoch Loss after 66 is 155.2932589314878\n","{'Validation Epoch Loss': 37.07987058907747, 'Epoch': 66, 'Micro F1': 0.7670818751216155, 'Patience Count': 0, 'Best Val F1': 0.7670818751216155, 'Best Val Loss': 37.07987058907747, 'Micro ROC value': 0.8244303481701227, 'Macro ROC value': 0.8244303481701227}\n","Training Epoch Loss after 67 is 154.4083312675357\n","{'Validation Epoch Loss': 36.82868578284979, 'Epoch': 67, 'Micro F1': 0.7673385015834697, 'Patience Count': 0, 'Best Val F1': 0.7673385015834697, 'Best Val Loss': 36.82868578284979, 'Micro ROC value': 0.8266897763365061, 'Macro ROC value': 0.8266897763365061}\n","Training Epoch Loss after 68 is 153.4012104794383\n","{'Validation Epoch Loss': 36.32912257313728, 'Epoch': 68, 'Micro F1': 0.7656492790488465, 'Patience Count': 0, 'Best Val F1': 0.7673385015834697, 'Best Val Loss': 36.32912257313728, 'Micro ROC value': 0.8279454528941128, 'Macro ROC value': 0.8279454528941128}\n","Training Epoch Loss after 69 is 153.189718849957\n","{'Validation Epoch Loss': 36.59423182159662, 'Epoch': 69, 'Micro F1': 0.7644733094379318, 'Patience Count': 1, 'Best Val F1': 0.7673385015834697, 'Best Val Loss': 36.32912257313728, 'Micro ROC value': 0.8289246195771239, 'Macro ROC value': 0.8289246195771239}\n","Training Epoch Loss after 70 is 151.8162349537015\n","{'Validation Epoch Loss': 35.90631181746721, 'Epoch': 70, 'Micro F1': 0.769120786461403, 'Patience Count': 0, 'Best Val F1': 0.769120786461403, 'Best Val Loss': 35.90631181746721, 'Micro ROC value': 0.833110238216208, 'Macro ROC value': 0.833110238216208}\n","Training Epoch Loss after 71 is 150.9403255879879\n","{'Validation Epoch Loss': 36.159118831157684, 'Epoch': 71, 'Micro F1': 0.7695099562606986, 'Patience Count': 0, 'Best Val F1': 0.7695099562606986, 'Best Val Loss': 35.90631181746721, 'Micro ROC value': 0.8230012187845311, 'Macro ROC value': 0.8230012187845311}\n","Training Epoch Loss after 72 is 149.92712058126926\n","{'Validation Epoch Loss': 35.74539013952017, 'Epoch': 72, 'Micro F1': 0.7727953389866357, 'Patience Count': 0, 'Best Val F1': 0.7727953389866357, 'Best Val Loss': 35.74539013952017, 'Micro ROC value': 0.82739409183959, 'Macro ROC value': 0.82739409183959}\n","Training Epoch Loss after 73 is 149.57572146505117\n","{'Validation Epoch Loss': 35.59498334676027, 'Epoch': 73, 'Micro F1': 0.7723864286902744, 'Patience Count': 0, 'Best Val F1': 0.7727953389866357, 'Best Val Loss': 35.59498334676027, 'Micro ROC value': 0.8290461973936128, 'Macro ROC value': 0.8290461973936128}\n","Training Epoch Loss after 74 is 148.2556431852281\n","{'Validation Epoch Loss': 35.29149929434061, 'Epoch': 74, 'Micro F1': 0.776794199677948, 'Patience Count': 0, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 35.29149929434061, 'Micro ROC value': 0.8306238900862124, 'Macro ROC value': 0.8306238900862124}\n","Training Epoch Loss after 75 is 147.15566289052367\n","{'Validation Epoch Loss': 35.126012451946735, 'Epoch': 75, 'Micro F1': 0.7719803384649226, 'Patience Count': 0, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 35.126012451946735, 'Micro ROC value': 0.8402045200559833, 'Macro ROC value': 0.8402045200559833}\n","Training Epoch Loss after 76 is 146.46125266700983\n","{'Validation Epoch Loss': 35.054883413016796, 'Epoch': 76, 'Micro F1': 0.7704405796937966, 'Patience Count': 0, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 35.054883413016796, 'Micro ROC value': 0.8410055211020218, 'Macro ROC value': 0.8410055211020218}\n","Training Epoch Loss after 77 is 145.92447175830603\n","{'Validation Epoch Loss': 34.81899954006076, 'Epoch': 77, 'Micro F1': 0.7698878457759566, 'Patience Count': 0, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 34.81899954006076, 'Micro ROC value': 0.8418522611348542, 'Macro ROC value': 0.8418522611348542}\n","Training Epoch Loss after 78 is 145.11319797858596\n","{'Validation Epoch Loss': 34.897930666804314, 'Epoch': 78, 'Micro F1': 0.7726853562172695, 'Patience Count': 1, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 34.81899954006076, 'Micro ROC value': 0.8431243502415262, 'Macro ROC value': 0.8431243502415262}\n","Training Epoch Loss after 79 is 144.7979711405933\n","{'Validation Epoch Loss': 34.88040105625987, 'Epoch': 79, 'Micro F1': 0.7711681580142188, 'Patience Count': 2, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 34.81899954006076, 'Micro ROC value': 0.8434390871492211, 'Macro ROC value': 0.8434390871492211}\n","Training Epoch Loss after 80 is 144.79615489020944\n","{'Validation Epoch Loss': 34.96270168200135, 'Epoch': 80, 'Micro F1': 0.7767236979027132, 'Patience Count': 3, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 34.81899954006076, 'Micro ROC value': 0.84469858565756, 'Macro ROC value': 0.84469858565756}\n","Training Epoch Loss after 81 is 143.42173114046454\n","{'Validation Epoch Loss': 34.82640788704157, 'Epoch': 81, 'Micro F1': 0.7760412407184413, 'Patience Count': 4, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 34.81899954006076, 'Micro ROC value': 0.8454721642723311, 'Macro ROC value': 0.8454721642723311}\n","Training Epoch Loss after 82 is 142.8349135555327\n","{'Validation Epoch Loss': 34.738831859081984, 'Epoch': 82, 'Micro F1': 0.7756013096409766, 'Patience Count': 0, 'Best Val F1': 0.776794199677948, 'Best Val Loss': 34.738831859081984, 'Micro ROC value': 0.8454812338874945, 'Macro ROC value': 0.8454812338874945}\n","Training Epoch Loss after 83 is 142.24632904678583\n","{'Validation Epoch Loss': 34.54374509677291, 'Epoch': 83, 'Micro F1': 0.7770310856427364, 'Patience Count': 0, 'Best Val F1': 0.7770310856427364, 'Best Val Loss': 34.54374509677291, 'Micro ROC value': 0.8476987980801344, 'Macro ROC value': 0.8476987980801344}\n","Training Epoch Loss after 84 is 142.07566579803824\n","{'Validation Epoch Loss': 34.69264401495457, 'Epoch': 84, 'Micro F1': 0.7755420881497797, 'Patience Count': 1, 'Best Val F1': 0.7770310856427364, 'Best Val Loss': 34.54374509677291, 'Micro ROC value': 0.8473038808108798, 'Macro ROC value': 0.8473038808108798}\n","Training Epoch Loss after 85 is 141.027382645756\n","{'Validation Epoch Loss': 34.52440423890948, 'Epoch': 85, 'Micro F1': 0.7781929548986043, 'Patience Count': 0, 'Best Val F1': 0.7781929548986043, 'Best Val Loss': 34.52440423890948, 'Micro ROC value': 0.8492917719090614, 'Macro ROC value': 0.8492917719090614}\n","Training Epoch Loss after 86 is 141.38047497719526\n","{'Validation Epoch Loss': 34.768482469022274, 'Epoch': 86, 'Micro F1': 0.7770395458557646, 'Patience Count': 1, 'Best Val F1': 0.7781929548986043, 'Best Val Loss': 34.52440423890948, 'Micro ROC value': 0.8468897696042392, 'Macro ROC value': 0.8468897696042392}\n","Training Epoch Loss after 87 is 140.12128108739853\n","{'Validation Epoch Loss': 34.408042907714844, 'Epoch': 87, 'Micro F1': 0.781235811517734, 'Patience Count': 0, 'Best Val F1': 0.781235811517734, 'Best Val Loss': 34.408042907714844, 'Micro ROC value': 0.8412020456170903, 'Macro ROC value': 0.8412020456170903}\n","Training Epoch Loss after 88 is 139.75873025134206\n","{'Validation Epoch Loss': 34.6108846925199, 'Epoch': 88, 'Micro F1': 0.7815516594707855, 'Patience Count': 0, 'Best Val F1': 0.7815516594707855, 'Best Val Loss': 34.408042907714844, 'Micro ROC value': 0.8398552986554167, 'Macro ROC value': 0.8398552986554167}\n","Training Epoch Loss after 89 is 139.11636995524168\n","{'Validation Epoch Loss': 34.600188329815865, 'Epoch': 89, 'Micro F1': 0.7825697051051745, 'Patience Count': 0, 'Best Val F1': 0.7825697051051745, 'Best Val Loss': 34.408042907714844, 'Micro ROC value': 0.8404042402432269, 'Macro ROC value': 0.8404042402432269}\n","Training Epoch Loss after 90 is 138.7169129922986\n","{'Validation Epoch Loss': 34.47572226449847, 'Epoch': 90, 'Micro F1': 0.7830039960406203, 'Patience Count': 0, 'Best Val F1': 0.7830039960406203, 'Best Val Loss': 34.408042907714844, 'Micro ROC value': 0.842546552935237, 'Macro ROC value': 0.842546552935237}\n","Training Epoch Loss after 91 is 138.37118835374713\n","{'Validation Epoch Loss': 34.55749274417758, 'Epoch': 91, 'Micro F1': 0.7843548100541171, 'Patience Count': 0, 'Best Val F1': 0.7843548100541171, 'Best Val Loss': 34.408042907714844, 'Micro ROC value': 0.8417075562778161, 'Macro ROC value': 0.8417075562778161}\n","Training Epoch Loss after 92 is 137.59374532848597\n","{'Validation Epoch Loss': 34.383632354438305, 'Epoch': 92, 'Micro F1': 0.7846621977941405, 'Patience Count': 0, 'Best Val F1': 0.7846621977941405, 'Best Val Loss': 34.383632354438305, 'Micro ROC value': 0.8429600708144636, 'Macro ROC value': 0.8429600708144636}\n","Training Epoch Loss after 93 is 137.37240276113153\n","{'Validation Epoch Loss': 34.19802273064852, 'Epoch': 93, 'Micro F1': 0.7847693604924972, 'Patience Count': 0, 'Best Val F1': 0.7847693604924972, 'Best Val Loss': 34.19802273064852, 'Micro ROC value': 0.8533316302362435, 'Macro ROC value': 0.8533316302362435}\n","Training Epoch Loss after 94 is 137.5048347003758\n","{'Validation Epoch Loss': 34.16763837635517, 'Epoch': 94, 'Micro F1': 0.784005121248953, 'Patience Count': 0, 'Best Val F1': 0.7847693604924972, 'Best Val Loss': 34.16763837635517, 'Micro ROC value': 0.8509518265802779, 'Macro ROC value': 0.8509518265802779}\n","Training Epoch Loss after 95 is 136.6826311275363\n","{'Validation Epoch Loss': 34.05550096184015, 'Epoch': 95, 'Micro F1': 0.7826796878745407, 'Patience Count': 0, 'Best Val F1': 0.7847693604924972, 'Best Val Loss': 34.05550096184015, 'Micro ROC value': 0.8499364239342001, 'Macro ROC value': 0.8499364239342001}\n","Training Epoch Loss after 96 is 136.1922509893775\n","{'Validation Epoch Loss': 33.88708397373557, 'Epoch': 96, 'Micro F1': 0.7848962636879196, 'Patience Count': 0, 'Best Val F1': 0.7848962636879196, 'Best Val Loss': 33.88708397373557, 'Micro ROC value': 0.8524097200703065, 'Macro ROC value': 0.8524097200703065}\n","Training Epoch Loss after 97 is 136.02831650525331\n","{'Validation Epoch Loss': 33.828480772674084, 'Epoch': 97, 'Micro F1': 0.7883621309584574, 'Patience Count': 0, 'Best Val F1': 0.7883621309584574, 'Best Val Loss': 33.828480772674084, 'Micro ROC value': 0.8542422905541941, 'Macro ROC value': 0.8542422905541941}\n","Training Epoch Loss after 98 is 135.66837962716818\n","{'Validation Epoch Loss': 33.77420883253217, 'Epoch': 98, 'Micro F1': 0.7878347776797021, 'Patience Count': 0, 'Best Val F1': 0.7883621309584574, 'Best Val Loss': 33.77420883253217, 'Micro ROC value': 0.8542276076616993, 'Macro ROC value': 0.8542276076616993}\n","Training Epoch Loss after 99 is 135.64214112609625\n","{'Validation Epoch Loss': 33.353526171296835, 'Epoch': 99, 'Micro F1': 0.7895155400012972, 'Patience Count': 0, 'Best Val F1': 0.7895155400012972, 'Best Val Loss': 33.353526171296835, 'Micro ROC value': 0.8594026813934807, 'Macro ROC value': 0.8594026813934807}\n","Training Epoch Loss after 100 is 134.24452160298824\n","{'Validation Epoch Loss': 33.13913632556796, 'Epoch': 100, 'Micro F1': 0.7892419931133866, 'Patience Count': 0, 'Best Val F1': 0.7895155400012972, 'Best Val Loss': 33.13913632556796, 'Micro ROC value': 0.8595056876530093, 'Macro ROC value': 0.8595056876530093}\n","Training Epoch Loss after 101 is 133.52876441553235\n","{'Validation Epoch Loss': 33.00524070113897, 'Epoch': 101, 'Micro F1': 0.7917828770928452, 'Patience Count': 0, 'Best Val F1': 0.7917828770928452, 'Best Val Loss': 33.00524070113897, 'Micro ROC value': 0.8622673743566373, 'Macro ROC value': 0.8622673743566373}\n","Training Epoch Loss after 102 is 134.4102575033903\n","{'Validation Epoch Loss': 33.22621804103255, 'Epoch': 102, 'Micro F1': 0.788009622082284, 'Patience Count': 1, 'Best Val F1': 0.7917828770928452, 'Best Val Loss': 33.00524070113897, 'Micro ROC value': 0.859433306370363, 'Macro ROC value': 0.859433306370363}\n","Training Epoch Loss after 103 is 133.86208187788725\n","{'Validation Epoch Loss': 32.92629907280207, 'Epoch': 103, 'Micro F1': 0.7914501087137373, 'Patience Count': 0, 'Best Val F1': 0.7917828770928452, 'Best Val Loss': 32.92629907280207, 'Micro ROC value': 0.8623315400171913, 'Macro ROC value': 0.8623315400171913}\n","Training Epoch Loss after 104 is 132.85959390550852\n","{'Validation Epoch Loss': 32.76834074035287, 'Epoch': 104, 'Micro F1': 0.7925753170464832, 'Patience Count': 0, 'Best Val F1': 0.7925753170464832, 'Best Val Loss': 32.76834074035287, 'Micro ROC value': 0.8624596080314594, 'Macro ROC value': 0.8624596080314594}\n","Training Epoch Loss after 105 is 132.54682758450508\n","{'Validation Epoch Loss': 32.609450086951256, 'Epoch': 105, 'Micro F1': 0.7934297985623278, 'Patience Count': 0, 'Best Val F1': 0.7934297985623278, 'Best Val Loss': 32.609450086951256, 'Micro ROC value': 0.8637796287681256, 'Macro ROC value': 0.8637796287681256}\n","Training Epoch Loss after 106 is 132.67215129174292\n","{'Validation Epoch Loss': 32.50325194746256, 'Epoch': 106, 'Micro F1': 0.7893970970189029, 'Patience Count': 0, 'Best Val F1': 0.7934297985623278, 'Best Val Loss': 32.50325194746256, 'Micro ROC value': 0.8611948892410729, 'Macro ROC value': 0.8611948892410729}\n","Training Epoch Loss after 107 is 131.56242211908102\n","{'Validation Epoch Loss': 32.232066839933395, 'Epoch': 107, 'Micro F1': 0.7932013728105674, 'Patience Count': 0, 'Best Val F1': 0.7934297985623278, 'Best Val Loss': 32.232066839933395, 'Micro ROC value': 0.8613961109566932, 'Macro ROC value': 0.8613961109566932}\n","Training Epoch Loss after 108 is 131.24716374278069\n","{'Validation Epoch Loss': 31.973004203289747, 'Epoch': 108, 'Micro F1': 0.7954997306832186, 'Patience Count': 0, 'Best Val F1': 0.7954997306832186, 'Best Val Loss': 31.973004203289747, 'Micro ROC value': 0.867342843990652, 'Macro ROC value': 0.867342843990652}\n","Training Epoch Loss after 109 is 130.50020833313465\n","{'Validation Epoch Loss': 31.72305081039667, 'Epoch': 109, 'Micro F1': 0.7967941432765278, 'Patience Count': 0, 'Best Val F1': 0.7967941432765278, 'Best Val Loss': 31.72305081039667, 'Micro ROC value': 0.8680175411098343, 'Macro ROC value': 0.8680175411098343}\n","Training Epoch Loss after 110 is 129.9603184349835\n","{'Validation Epoch Loss': 31.62556729093194, 'Epoch': 110, 'Micro F1': 0.7975386420230062, 'Patience Count': 0, 'Best Val F1': 0.7975386420230062, 'Best Val Loss': 31.62556729093194, 'Micro ROC value': 0.8690135161056629, 'Macro ROC value': 0.8690135161056629}\n","Training Epoch Loss after 111 is 129.6555930748582\n","{'Validation Epoch Loss': 31.753308068960905, 'Epoch': 111, 'Micro F1': 0.7972481747090392, 'Patience Count': 1, 'Best Val F1': 0.7975386420230062, 'Best Val Loss': 31.62556729093194, 'Micro ROC value': 0.8696283439096539, 'Macro ROC value': 0.8696283439096539}\n","Training Epoch Loss after 112 is 128.94939785823226\n","{'Validation Epoch Loss': 31.56049297004938, 'Epoch': 112, 'Micro F1': 0.7993293871139675, 'Patience Count': 0, 'Best Val F1': 0.7993293871139675, 'Best Val Loss': 31.56049297004938, 'Micro ROC value': 0.871110834449432, 'Macro ROC value': 0.871110834449432}\n","Training Epoch Loss after 113 is 128.51605922542512\n","{'Validation Epoch Loss': 31.46896853670478, 'Epoch': 113, 'Micro F1': 0.801055270571713, 'Patience Count': 0, 'Best Val F1': 0.801055270571713, 'Best Val Loss': 31.46896853670478, 'Micro ROC value': 0.8713958796565346, 'Macro ROC value': 0.8713958796565346}\n","Training Epoch Loss after 114 is 128.00980687700212\n","{'Validation Epoch Loss': 31.438513591885567, 'Epoch': 114, 'Micro F1': 0.8003530728903754, 'Patience Count': 0, 'Best Val F1': 0.801055270571713, 'Best Val Loss': 31.438513591885567, 'Micro ROC value': 0.8704348046148267, 'Macro ROC value': 0.8704348046148267}\n","Training Epoch Loss after 115 is 127.73890880681574\n","{'Validation Epoch Loss': 31.10495688021183, 'Epoch': 115, 'Micro F1': 0.8024878666444821, 'Patience Count': 0, 'Best Val F1': 0.8024878666444821, 'Best Val Loss': 31.10495688021183, 'Micro ROC value': 0.8726844095379249, 'Macro ROC value': 0.8726844095379249}\n","Training Epoch Loss after 116 is 127.35258673876524\n","{'Validation Epoch Loss': 31.126108534634113, 'Epoch': 116, 'Micro F1': 0.8024596659343883, 'Patience Count': 1, 'Best Val F1': 0.8024878666444821, 'Best Val Loss': 31.10495688021183, 'Micro ROC value': 0.871965299989915, 'Macro ROC value': 0.871965299989915}\n","Training Epoch Loss after 117 is 127.0924609452486\n","{'Validation Epoch Loss': 30.891542308032513, 'Epoch': 117, 'Micro F1': 0.8041968296761712, 'Patience Count': 0, 'Best Val F1': 0.8041968296761712, 'Best Val Loss': 30.891542308032513, 'Micro ROC value': 0.8728548009326498, 'Macro ROC value': 0.8728548009326498}\n","Training Epoch Loss after 118 is 126.95844409428537\n","{'Validation Epoch Loss': 30.64985452964902, 'Epoch': 118, 'Micro F1': 0.8056660866720624, 'Patience Count': 0, 'Best Val F1': 0.8056660866720624, 'Best Val Loss': 30.64985452964902, 'Micro ROC value': 0.8751861318025245, 'Macro ROC value': 0.8751861318025245}\n","Training Epoch Loss after 119 is 126.36967872083187\n","{'Validation Epoch Loss': 30.23486478254199, 'Epoch': 119, 'Micro F1': 0.8068956376321555, 'Patience Count': 0, 'Best Val F1': 0.8068956376321555, 'Best Val Loss': 30.23486478254199, 'Micro ROC value': 0.8764436526535849, 'Macro ROC value': 0.8764436526535849}\n","Training Epoch Loss after 120 is 126.29295140877366\n","{'Validation Epoch Loss': 30.423075530678034, 'Epoch': 120, 'Micro F1': 0.8061031976785176, 'Patience Count': 1, 'Best Val F1': 0.8068956376321555, 'Best Val Loss': 30.23486478254199, 'Micro ROC value': 0.8761220683997251, 'Macro ROC value': 0.8761220683997251}\n","Training Epoch Loss after 121 is 126.93195035681129\n","{'Validation Epoch Loss': 30.63772625476122, 'Epoch': 121, 'Micro F1': 0.807262246863376, 'Patience Count': 0, 'Best Val F1': 0.807262246863376, 'Best Val Loss': 30.23486478254199, 'Micro ROC value': 0.8790949647702414, 'Macro ROC value': 0.8790949647702414}\n","Training Epoch Loss after 122 is 126.5303296521306\n","{'Validation Epoch Loss': 30.40179193019867, 'Epoch': 122, 'Micro F1': 0.8071409838099723, 'Patience Count': 1, 'Best Val F1': 0.807262246863376, 'Best Val Loss': 30.23486478254199, 'Micro ROC value': 0.8773377823965994, 'Macro ROC value': 0.8773377823965994}\n","Training Epoch Loss after 123 is 125.76360264606774\n","{'Validation Epoch Loss': 30.311336301267147, 'Epoch': 123, 'Micro F1': 0.7969154063299314, 'Patience Count': 2, 'Best Val F1': 0.807262246863376, 'Best Val Loss': 30.23486478254199, 'Micro ROC value': 0.878004856823335, 'Macro ROC value': 0.878004856823335}\n","Training Epoch Loss after 124 is 126.72239480540156\n","{'Validation Epoch Loss': 30.26745969429612, 'Epoch': 124, 'Micro F1': 0.8072904475734699, 'Patience Count': 0, 'Best Val F1': 0.8072904475734699, 'Best Val Loss': 30.23486478254199, 'Micro ROC value': 0.8741462023844365, 'Macro ROC value': 0.8741462023844365}\n","Training Epoch Loss after 125 is 125.55547886528075\n","{'Validation Epoch Loss': 30.13206635788083, 'Epoch': 125, 'Micro F1': 0.8079982853968262, 'Patience Count': 0, 'Best Val F1': 0.8079982853968262, 'Best Val Loss': 30.13206635788083, 'Micro ROC value': 0.8746842376053205, 'Macro ROC value': 0.8746842376053205}\n","Training Epoch Loss after 126 is 125.2392238676548\n","{'Validation Epoch Loss': 29.94853411614895, 'Epoch': 126, 'Micro F1': 0.8096903280024591, 'Patience Count': 0, 'Best Val F1': 0.8096903280024591, 'Best Val Loss': 29.94853411614895, 'Micro ROC value': 0.876334959386355, 'Macro ROC value': 0.876334959386355}\n","Training Epoch Loss after 127 is 124.76903704740107\n","{'Validation Epoch Loss': 29.86811600998044, 'Epoch': 127, 'Micro F1': 0.809340639197295, 'Patience Count': 0, 'Best Val F1': 0.8096903280024591, 'Best Val Loss': 29.86811600998044, 'Micro ROC value': 0.8769604622469307, 'Macro ROC value': 0.8769604622469307}\n","Training Epoch Loss after 128 is 124.31598492898047\n","{'Validation Epoch Loss': 29.916710808873177, 'Epoch': 128, 'Micro F1': 0.8058014500805131, 'Patience Count': 1, 'Best Val F1': 0.8096903280024591, 'Best Val Loss': 29.86811600998044, 'Micro ROC value': 0.8735812428657407, 'Macro ROC value': 0.8735812428657407}\n","Training Epoch Loss after 129 is 123.52719922177494\n","{'Validation Epoch Loss': 29.679540935903788, 'Epoch': 129, 'Micro F1': 0.8085425591016382, 'Patience Count': 0, 'Best Val F1': 0.8096903280024591, 'Best Val Loss': 29.679540935903788, 'Micro ROC value': 0.8767112461334458, 'Macro ROC value': 0.8767112461334458}\n","Training Epoch Loss after 130 is 123.30125484988093\n","{'Validation Epoch Loss': 29.564405942335725, 'Epoch': 130, 'Micro F1': 0.8086243411609104, 'Patience Count': 0, 'Best Val F1': 0.8096903280024591, 'Best Val Loss': 29.564405942335725, 'Micro ROC value': 0.8773006055041771, 'Macro ROC value': 0.8773006055041771}\n","Training Epoch Loss after 131 is 123.06165004335344\n","{'Validation Epoch Loss': 29.53904834203422, 'Epoch': 131, 'Micro F1': 0.8097269889255811, 'Patience Count': 0, 'Best Val F1': 0.8097269889255811, 'Best Val Loss': 29.53904834203422, 'Micro ROC value': 0.8782545697337727, 'Macro ROC value': 0.8782545697337727}\n","Training Epoch Loss after 132 is 123.35566723719239\n","{'Validation Epoch Loss': 29.68378157913685, 'Epoch': 132, 'Micro F1': 0.8034889918528149, 'Patience Count': 1, 'Best Val F1': 0.8097269889255811, 'Best Val Loss': 29.53904834203422, 'Micro ROC value': 0.8720854636279909, 'Macro ROC value': 0.8720854636279909}\n","Training Epoch Loss after 133 is 122.98419420048594\n","{'Validation Epoch Loss': 29.546629974618554, 'Epoch': 133, 'Micro F1': 0.8076711571597373, 'Patience Count': 2, 'Best Val F1': 0.8097269889255811, 'Best Val Loss': 29.53904834203422, 'Micro ROC value': 0.8757861624589951, 'Macro ROC value': 0.8757861624589951}\n","Training Epoch Loss after 134 is 122.61909141764045\n","{'Validation Epoch Loss': 29.54843731224537, 'Epoch': 134, 'Micro F1': 0.8089260887589149, 'Patience Count': 3, 'Best Val F1': 0.8097269889255811, 'Best Val Loss': 29.53904834203422, 'Micro ROC value': 0.8775291084114236, 'Macro ROC value': 0.8775291084114236}\n","Training Epoch Loss after 135 is 122.29359855875373\n","{'Validation Epoch Loss': 29.245395734906197, 'Epoch': 135, 'Micro F1': 0.8114218516022234, 'Patience Count': 0, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 29.245395734906197, 'Micro ROC value': 0.8755019511815201, 'Macro ROC value': 0.8755019511815201}\n","Training Epoch Loss after 136 is 124.97873935848475\n","{'Validation Epoch Loss': 29.41943341586739, 'Epoch': 136, 'Micro F1': 0.8044731966350913, 'Patience Count': 1, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 29.245395734906197, 'Micro ROC value': 0.8669605084256267, 'Macro ROC value': 0.8669605084256267}\n","Training Epoch Loss after 137 is 124.80644020624459\n","{'Validation Epoch Loss': 29.493213897570968, 'Epoch': 137, 'Micro F1': 0.8041460683980023, 'Patience Count': 2, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 29.245395734906197, 'Micro ROC value': 0.870374630529406, 'Macro ROC value': 0.870374630529406}\n","Training Epoch Loss after 138 is 123.64189965464175\n","{'Validation Epoch Loss': 29.215744051150978, 'Epoch': 138, 'Micro F1': 0.8079418839766386, 'Patience Count': 0, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 29.215744051150978, 'Micro ROC value': 0.8721137840137045, 'Macro ROC value': 0.8721137840137045}\n","Training Epoch Loss after 139 is 126.70481339469552\n","{'Validation Epoch Loss': 29.336005602031946, 'Epoch': 139, 'Micro F1': 0.8036751165394345, 'Patience Count': 1, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 29.215744051150978, 'Micro ROC value': 0.8716494954715506, 'Macro ROC value': 0.8716494954715506}\n","Training Epoch Loss after 140 is 123.65836232714355\n","{'Validation Epoch Loss': 29.16129022371024, 'Epoch': 140, 'Micro F1': 0.8058634916427195, 'Patience Count': 0, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 29.16129022371024, 'Micro ROC value': 0.875129842801653, 'Macro ROC value': 0.875129842801653}\n","Training Epoch Loss after 141 is 122.98875488899648\n","{'Validation Epoch Loss': 28.94631319027394, 'Epoch': 141, 'Micro F1': 0.807814980781216, 'Patience Count': 0, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 28.94631319027394, 'Micro ROC value': 0.8769253789692613, 'Macro ROC value': 0.8769253789692613}\n","Training Epoch Loss after 142 is 121.92068248800933\n","{'Validation Epoch Loss': 28.620045386254787, 'Epoch': 142, 'Micro F1': 0.8077247385089156, 'Patience Count': 0, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 28.620045386254787, 'Micro ROC value': 0.8776922745321709, 'Macro ROC value': 0.8776922745321709}\n","Training Epoch Loss after 143 is 121.73333423025906\n","{'Validation Epoch Loss': 28.71940442174673, 'Epoch': 143, 'Micro F1': 0.810358684831684, 'Patience Count': 1, 'Best Val F1': 0.8114218516022234, 'Best Val Loss': 28.620045386254787, 'Micro ROC value': 0.876929342414206, 'Macro ROC value': 0.876929342414206}\n","Training Epoch Loss after 144 is 121.6520693525672\n","{'Validation Epoch Loss': 28.42472530528903, 'Epoch': 144, 'Micro F1': 0.8117715404073874, 'Patience Count': 0, 'Best Val F1': 0.8117715404073874, 'Best Val Loss': 28.42472530528903, 'Micro ROC value': 0.8785190450585849, 'Macro ROC value': 0.8785190450585849}\n","Training Epoch Loss after 145 is 121.03944729268551\n","{'Validation Epoch Loss': 28.2629367262125, 'Epoch': 145, 'Micro F1': 0.8131223544208843, 'Patience Count': 0, 'Best Val F1': 0.8131223544208843, 'Best Val Loss': 28.2629367262125, 'Micro ROC value': 0.8786973843931087, 'Macro ROC value': 0.8786973843931087}\n","Training Epoch Loss after 146 is 120.54626746661961\n","{'Validation Epoch Loss': 27.943093353882432, 'Epoch': 146, 'Micro F1': 0.8131872160541003, 'Patience Count': 0, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8815665738428291, 'Macro ROC value': 0.8815665738428291}\n","Training Epoch Loss after 147 is 119.59778272360563\n","{'Validation Epoch Loss': 28.055030069313943, 'Epoch': 147, 'Micro F1': 0.8129362297342647, 'Patience Count': 1, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8807122555403363, 'Macro ROC value': 0.8807122555403363}\n","Training Epoch Loss after 148 is 118.87190893478692\n","{'Validation Epoch Loss': 28.027933716773987, 'Epoch': 148, 'Micro F1': 0.8127783057577391, 'Patience Count': 2, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8808663353078214, 'Macro ROC value': 0.8808663353078214}\n","Training Epoch Loss after 149 is 118.44006609544158\n","{'Validation Epoch Loss': 28.00093999877572, 'Epoch': 149, 'Micro F1': 0.8126429423492884, 'Patience Count': 3, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8808063493669042, 'Macro ROC value': 0.8808063493669042}\n","Training Epoch Loss after 150 is 118.88364942371845\n","{'Validation Epoch Loss': 28.20872006006539, 'Epoch': 150, 'Micro F1': 0.8120817482184202, 'Patience Count': 4, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.880501214177258, 'Macro ROC value': 0.880501214177258}\n","Training Epoch Loss after 151 is 120.01966341584921\n","{'Validation Epoch Loss': 28.312949382700026, 'Epoch': 151, 'Micro F1': 0.8113090487618478, 'Patience Count': 5, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8794718950272208, 'Macro ROC value': 0.8794718950272208}\n","Training Epoch Loss after 152 is 118.77537625096738\n","{'Validation Epoch Loss': 28.103756410069764, 'Epoch': 152, 'Micro F1': 0.8116925784191246, 'Patience Count': 6, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8792286066509372, 'Macro ROC value': 0.8792286066509372}\n","Training Epoch Loss after 153 is 118.01697695069015\n","{'Validation Epoch Loss': 28.002353569492698, 'Epoch': 153, 'Micro F1': 0.8118984436028099, 'Patience Count': 7, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8801278558337277, 'Macro ROC value': 0.8801278558337277}\n","Training Epoch Loss after 154 is 117.5465812087059\n","{'Validation Epoch Loss': 27.984017113223672, 'Epoch': 154, 'Micro F1': 0.8114867132354393, 'Patience Count': 8, 'Best Val F1': 0.8131872160541003, 'Best Val Loss': 27.943093353882432, 'Micro ROC value': 0.8781620622239164, 'Macro ROC value': 0.8781620622239164}\n","Training Epoch Loss after 155 is 117.02931225299835\n","{'Validation Epoch Loss': 27.747466667555273, 'Epoch': 155, 'Micro F1': 0.8139711957947101, 'Patience Count': 0, 'Best Val F1': 0.8139711957947101, 'Best Val Loss': 27.747466667555273, 'Micro ROC value': 0.8811269930732661, 'Macro ROC value': 0.8811269930732661}\n","Training Epoch Loss after 156 is 117.48591480590403\n","{'Validation Epoch Loss': 27.99678351636976, 'Epoch': 156, 'Micro F1': 0.8126429423492884, 'Patience Count': 1, 'Best Val F1': 0.8139711957947101, 'Best Val Loss': 27.747466667555273, 'Micro ROC value': 0.8800522388315731, 'Macro ROC value': 0.8800522388315731}\n","Training Epoch Loss after 157 is 117.50535097531974\n","{'Validation Epoch Loss': 28.03795984853059, 'Epoch': 157, 'Micro F1': 0.8125498800059785, 'Patience Count': 2, 'Best Val F1': 0.8139711957947101, 'Best Val Loss': 27.747466667555273, 'Micro ROC value': 0.8799838929740602, 'Macro ROC value': 0.8799838929740602}\n","Training Epoch Loss after 158 is 118.62010023742914\n","{'Validation Epoch Loss': 27.892319015227258, 'Epoch': 158, 'Micro F1': 0.8130969737817998, 'Patience Count': 3, 'Best Val F1': 0.8139711957947101, 'Best Val Loss': 27.747466667555273, 'Micro ROC value': 0.882968624055463, 'Macro ROC value': 0.882968624055463}\n","Training Epoch Loss after 159 is 117.25159053690732\n","{'Validation Epoch Loss': 27.339489558711648, 'Epoch': 159, 'Micro F1': 0.814994881571118, 'Patience Count': 0, 'Best Val F1': 0.814994881571118, 'Best Val Loss': 27.339489558711648, 'Micro ROC value': 0.8845377343834078, 'Macro ROC value': 0.8845377343834078}\n","Training Epoch Loss after 160 is 117.07462155632675\n","{'Validation Epoch Loss': 27.197537388652563, 'Epoch': 160, 'Micro F1': 0.8166051421174785, 'Patience Count': 0, 'Best Val F1': 0.8166051421174785, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8863077499305285, 'Macro ROC value': 0.8863077499305285}\n","Training Epoch Loss after 161 is 117.93536909669638\n","{'Validation Epoch Loss': 27.754597570747137, 'Epoch': 161, 'Micro F1': 0.8176513884619615, 'Patience Count': 0, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8846877061886949, 'Macro ROC value': 0.8846877061886949}\n","Training Epoch Loss after 162 is 119.81785565428436\n","{'Validation Epoch Loss': 28.12934936210513, 'Epoch': 162, 'Micro F1': 0.8153417503052727, 'Patience Count': 1, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8869445921847365, 'Macro ROC value': 0.8869445921847365}\n","Training Epoch Loss after 163 is 118.51287284679711\n","{'Validation Epoch Loss': 27.872302763164043, 'Epoch': 163, 'Micro F1': 0.8155250549208829, 'Patience Count': 2, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8879533535605568, 'Macro ROC value': 0.8879533535605568}\n","Training Epoch Loss after 164 is 117.50172492861748\n","{'Validation Epoch Loss': 27.878632225096226, 'Epoch': 164, 'Micro F1': 0.813271818184382, 'Patience Count': 3, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8852011236122237, 'Macro ROC value': 0.8852011236122237}\n","Training Epoch Loss after 165 is 117.02057353965938\n","{'Validation Epoch Loss': 27.857911475002766, 'Epoch': 165, 'Micro F1': 0.8135143442911893, 'Patience Count': 4, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8854715847166175, 'Macro ROC value': 0.8854715847166175}\n","Training Epoch Loss after 166 is 117.11194095108658\n","{'Validation Epoch Loss': 27.861990933306515, 'Epoch': 166, 'Micro F1': 0.8135425450012831, 'Patience Count': 5, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8860530309125173, 'Macro ROC value': 0.8860530309125173}\n","Training Epoch Loss after 167 is 116.7367922142148\n","{'Validation Epoch Loss': 27.774184701032937, 'Epoch': 167, 'Micro F1': 0.8143631856650151, 'Patience Count': 6, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8861464336719939, 'Macro ROC value': 0.8861464336719939}\n","Training Epoch Loss after 168 is 115.95549068693072\n","{'Validation Epoch Loss': 27.774939159862697, 'Epoch': 168, 'Micro F1': 0.8141206595582076, 'Patience Count': 7, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8854523229517459, 'Macro ROC value': 0.8854523229517459}\n","Training Epoch Loss after 169 is 116.13947110529989\n","{'Validation Epoch Loss': 27.658795254305005, 'Epoch': 169, 'Micro F1': 0.8157845014537465, 'Patience Count': 8, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8861323713461002, 'Macro ROC value': 0.8861323713461002}\n","Training Epoch Loss after 170 is 115.65976442676038\n","{'Validation Epoch Loss': 27.642704776488245, 'Epoch': 170, 'Micro F1': 0.815003341784146, 'Patience Count': 9, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8854853783101087, 'Macro ROC value': 0.8854853783101087}\n","Training Epoch Loss after 171 is 116.03810648526996\n","{'Validation Epoch Loss': 27.75733930710703, 'Epoch': 171, 'Micro F1': 0.8138442925992877, 'Patience Count': 10, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8842858104528648, 'Macro ROC value': 0.8842858104528648}\n","Training Epoch Loss after 172 is 115.26523255743086\n","{'Validation Epoch Loss': 27.619135877117515, 'Epoch': 172, 'Micro F1': 0.8147213346832073, 'Patience Count': 11, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.884720152579386, 'Macro ROC value': 0.884720152579386}\n","Epoch   173: reducing learning rate of group 0 to 1.0000e-04.\n","Training Epoch Loss after 173 is 110.81829752866179\n","{'Validation Epoch Loss': 27.366586718708277, 'Epoch': 173, 'Micro F1': 0.8121635302776924, 'Patience Count': 12, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8861697033841507, 'Macro ROC value': 0.8861697033841507}\n","Training Epoch Loss after 174 is 110.44285560864955\n","{'Validation Epoch Loss': 27.301237912848592, 'Epoch': 174, 'Micro F1': 0.8118392221116127, 'Patience Count': 13, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8870713817710273, 'Macro ROC value': 0.8870713817710273}\n","Training Epoch Loss after 175 is 110.24988752789795\n","{'Validation Epoch Loss': 27.30321491882205, 'Epoch': 175, 'Micro F1': 0.8123073538991712, 'Patience Count': 14, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8868508927695083, 'Macro ROC value': 0.8868508927695083}\n","Training Epoch Loss after 176 is 110.16959719266742\n","{'Validation Epoch Loss': 27.2874884493649, 'Epoch': 176, 'Micro F1': 0.8126429423492884, 'Patience Count': 15, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8871413249236625, 'Macro ROC value': 0.8871413249236625}\n","Training Epoch Loss after 177 is 110.10613403655589\n","{'Validation Epoch Loss': 27.274550741538405, 'Epoch': 177, 'Micro F1': 0.812989811083443, 'Patience Count': 16, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8873481273950612, 'Macro ROC value': 0.8873481273950612}\n","Training Epoch Loss after 178 is 110.05325498059392\n","{'Validation Epoch Loss': 27.26318133994937, 'Epoch': 178, 'Micro F1': 0.8132689981133725, 'Patience Count': 17, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8875036897412315, 'Macro ROC value': 0.8875036897412315}\n","Training Epoch Loss after 179 is 110.00580845959485\n","{'Validation Epoch Loss': 27.25246679969132, 'Epoch': 179, 'Micro F1': 0.8133564203146635, 'Patience Count': 18, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8876210823011463, 'Macro ROC value': 0.8876210823011463}\n","Training Epoch Loss after 180 is 109.96261411346495\n","{'Validation Epoch Loss': 27.24237620085478, 'Epoch': 180, 'Micro F1': 0.8133846210247574, 'Patience Count': 19, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8877109054941076, 'Macro ROC value': 0.8877109054941076}\n","Training Epoch Loss after 181 is 109.92211166862398\n","{'Validation Epoch Loss': 27.2335998211056, 'Epoch': 181, 'Micro F1': 0.8134776833680673, 'Patience Count': 20, 'Best Val F1': 0.8176513884619615, 'Best Val Loss': 27.197537388652563, 'Micro ROC value': 0.8877989495958287, 'Macro ROC value': 0.8877989495958287}\n","Testing stats.\n","\n","\n","\n","{'Micro F1': 0.9085214097021074, 'Micro Recall': 0.9085214097021074, 'Micro Precision': 0.9085214097021074, 'Micro ROC_AUC_Score': 0.969959461226942, 'Macro ROC_AUC_Score': 0.969959461226942}\n","\n","\n","\n","\n","Training Epoch Loss after 0 is 338.29907685518265\n","{'Validation Epoch Loss': 88.2547960281372, 'Epoch': 0, 'Micro F1': 0.6247537514896515, 'Patience Count': 0, 'Best Val F1': 0.6247537514896515, 'Best Val Loss': 88.2547960281372, 'Micro ROC value': 0.6063133620908279, 'Macro ROC value': 0.6063133620908279}\n","Training Epoch Loss after 1 is 329.3248420059681\n","{'Validation Epoch Loss': 109.5658331811428, 'Epoch': 1, 'Micro F1': 0.5876922649303903, 'Patience Count': 1, 'Best Val F1': 0.6247537514896515, 'Best Val Loss': 88.2547960281372, 'Micro ROC value': 0.6805877807573909, 'Macro ROC value': 0.6805877807573909}\n","Training Epoch Loss after 2 is 340.4153326898813\n","{'Validation Epoch Loss': 85.918859988451, 'Epoch': 2, 'Micro F1': 0.628398403163099, 'Patience Count': 0, 'Best Val F1': 0.628398403163099, 'Best Val Loss': 85.918859988451, 'Micro ROC value': 0.6830136862455949, 'Macro ROC value': 0.6830136862455949}\n","Training Epoch Loss after 3 is 328.14616018533707\n","{'Validation Epoch Loss': 80.96092355251312, 'Epoch': 3, 'Micro F1': 0.64685444671825, 'Patience Count': 0, 'Best Val F1': 0.64685444671825, 'Best Val Loss': 80.96092355251312, 'Micro ROC value': 0.684626063024641, 'Macro ROC value': 0.684626063024641}\n","Training Epoch Loss after 4 is 312.6745839416981\n","{'Validation Epoch Loss': 80.36517861485481, 'Epoch': 4, 'Micro F1': 0.6533654831682412, 'Patience Count': 0, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 80.36517861485481, 'Micro ROC value': 0.6874416251655482, 'Macro ROC value': 0.6874416251655482}\n","Training Epoch Loss after 5 is 309.92882707715034\n","{'Validation Epoch Loss': 80.42348247766495, 'Epoch': 5, 'Micro F1': 0.652979824125579, 'Patience Count': 1, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 80.36517861485481, 'Micro ROC value': 0.6895880750931938, 'Macro ROC value': 0.6895880750931938}\n","Training Epoch Loss after 6 is 314.372910708189\n","{'Validation Epoch Loss': 79.89842596650124, 'Epoch': 6, 'Micro F1': 0.6528373734881991, 'Patience Count': 0, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 79.89842596650124, 'Micro ROC value': 0.6857340897323794, 'Macro ROC value': 0.6857340897323794}\n","Training Epoch Loss after 7 is 310.63495245575905\n","{'Validation Epoch Loss': 78.00960862636566, 'Epoch': 7, 'Micro F1': 0.6414343736862403, 'Patience Count': 0, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 78.00960862636566, 'Micro ROC value': 0.6833324862122754, 'Macro ROC value': 0.6833324862122754}\n","Training Epoch Loss after 8 is 306.9150867164135\n","{'Validation Epoch Loss': 77.69346669316292, 'Epoch': 8, 'Micro F1': 0.6463923507482133, 'Patience Count': 0, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.69346669316292, 'Micro ROC value': 0.6924184748010421, 'Macro ROC value': 0.6924184748010421}\n","Training Epoch Loss after 9 is 305.47807174921036\n","{'Validation Epoch Loss': 77.33270373940468, 'Epoch': 9, 'Micro F1': 0.6488765508878844, 'Patience Count': 0, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.33270373940468, 'Micro ROC value': 0.6943814811134463, 'Macro ROC value': 0.6943814811134463}\n","Training Epoch Loss after 10 is 307.43555334210396\n","{'Validation Epoch Loss': 77.21456462144852, 'Epoch': 10, 'Micro F1': 0.6495297391763574, 'Patience Count': 0, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.21456462144852, 'Micro ROC value': 0.6887582976279706, 'Macro ROC value': 0.6887582976279706}\n","Training Epoch Loss after 11 is 309.8350770175457\n","{'Validation Epoch Loss': 77.37797114253044, 'Epoch': 11, 'Micro F1': 0.6474277236735587, 'Patience Count': 1, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.21456462144852, 'Micro ROC value': 0.6754002647361605, 'Macro ROC value': 0.6754002647361605}\n","Training Epoch Loss after 12 is 308.58425906300545\n","{'Validation Epoch Loss': 80.42596107721329, 'Epoch': 12, 'Micro F1': 0.6419346881199642, 'Patience Count': 2, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.21456462144852, 'Micro ROC value': 0.6878743496922358, 'Macro ROC value': 0.6878743496922358}\n","Training Epoch Loss after 13 is 305.63276666402817\n","{'Validation Epoch Loss': 77.99674043059349, 'Epoch': 13, 'Micro F1': 0.6497104082774243, 'Patience Count': 3, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.21456462144852, 'Micro ROC value': 0.6954946215754249, 'Macro ROC value': 0.6954946215754249}\n","Training Epoch Loss after 14 is 302.81708016991615\n","{'Validation Epoch Loss': 78.57495185732841, 'Epoch': 14, 'Micro F1': 0.6478238059335902, 'Patience Count': 4, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.21456462144852, 'Micro ROC value': 0.6948496002971007, 'Macro ROC value': 0.6948496002971007}\n","Training Epoch Loss after 15 is 301.8859274685383\n","{'Validation Epoch Loss': 79.57475835084915, 'Epoch': 15, 'Micro F1': 0.6484422501641657, 'Patience Count': 5, 'Best Val F1': 0.6533654831682412, 'Best Val Loss': 77.21456462144852, 'Micro ROC value': 0.6950249663177975, 'Macro ROC value': 0.6950249663177975}\n","Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n","Training Epoch Loss after 16 is 297.00111132860184\n","{'Validation Epoch Loss': 74.41191780567169, 'Epoch': 16, 'Micro F1': 0.6734371254156258, 'Patience Count': 0, 'Best Val F1': 0.6734371254156258, 'Best Val Loss': 74.41191780567169, 'Micro ROC value': 0.7075117489311985, 'Macro ROC value': 0.7075117489311985}\n","Training Epoch Loss after 17 is 295.13775554299355\n","{'Validation Epoch Loss': 74.14809975028038, 'Epoch': 17, 'Micro F1': 0.6740208255883038, 'Patience Count': 0, 'Best Val F1': 0.6740208255883038, 'Best Val Loss': 74.14809975028038, 'Micro ROC value': 0.7079061654413523, 'Macro ROC value': 0.7079061654413523}\n","Training Epoch Loss after 18 is 294.2079172730446\n","{'Validation Epoch Loss': 73.88741558790207, 'Epoch': 18, 'Micro F1': 0.6750423008904902, 'Patience Count': 0, 'Best Val F1': 0.6750423008904902, 'Best Val Loss': 73.88741558790207, 'Micro ROC value': 0.7083026950379434, 'Macro ROC value': 0.7083026950379434}\n","Training Epoch Loss after 19 is 293.20072838664055\n","{'Validation Epoch Loss': 73.5886800289154, 'Epoch': 19, 'Micro F1': 0.6754696528026294, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 73.5886800289154, 'Micro ROC value': 0.7094971431725752, 'Macro ROC value': 0.7094971431725752}\n","Training Epoch Loss after 20 is 292.0543697476387\n","{'Validation Epoch Loss': 73.22480860352516, 'Epoch': 20, 'Micro F1': 0.6728951181124249, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 73.22480860352516, 'Micro ROC value': 0.7096990403607542, 'Macro ROC value': 0.7096990403607542}\n","Training Epoch Loss after 21 is 290.6613946557045\n","{'Validation Epoch Loss': 72.90289941430092, 'Epoch': 21, 'Micro F1': 0.66657517398087, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 72.90289941430092, 'Micro ROC value': 0.7104128557918956, 'Macro ROC value': 0.7104128557918956}\n","Training Epoch Loss after 22 is 289.2429713010788\n","{'Validation Epoch Loss': 72.44432646036148, 'Epoch': 22, 'Micro F1': 0.6627220579600374, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 72.44432646036148, 'Micro ROC value': 0.7122627745482601, 'Macro ROC value': 0.7122627745482601}\n","Training Epoch Loss after 23 is 287.42003324627876\n","{'Validation Epoch Loss': 72.01218861341476, 'Epoch': 23, 'Micro F1': 0.6622043714973647, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 72.01218861341476, 'Micro ROC value': 0.7149329994574922, 'Macro ROC value': 0.7149329994574922}\n","Training Epoch Loss after 24 is 285.4150587618351\n","{'Validation Epoch Loss': 71.6439882516861, 'Epoch': 24, 'Micro F1': 0.6607208002251415, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 71.6439882516861, 'Micro ROC value': 0.7180747014497442, 'Macro ROC value': 0.7180747014497442}\n","Training Epoch Loss after 25 is 283.15155282616615\n","{'Validation Epoch Loss': 71.19494622945786, 'Epoch': 25, 'Micro F1': 0.6573019849280277, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 71.19494622945786, 'Micro ROC value': 0.7213691921765855, 'Macro ROC value': 0.7213691921765855}\n","Training Epoch Loss after 26 is 280.7185075581074\n","{'Validation Epoch Loss': 70.80359449982643, 'Epoch': 26, 'Micro F1': 0.6545988972236023, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 70.80359449982643, 'Micro ROC value': 0.7263564021557015, 'Macro ROC value': 0.7263564021557015}\n","Training Epoch Loss after 27 is 278.092935949564\n","{'Validation Epoch Loss': 70.4526771903038, 'Epoch': 27, 'Micro F1': 0.6533064182698154, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 70.4526771903038, 'Micro ROC value': 0.732204297802649, 'Macro ROC value': 0.732204297802649}\n","Training Epoch Loss after 28 is 275.5243067741394\n","{'Validation Epoch Loss': 69.79700049757957, 'Epoch': 28, 'Micro F1': 0.6592789218223953, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 69.79700049757957, 'Micro ROC value': 0.7428624206953542, 'Macro ROC value': 0.7428624206953542}\n","Training Epoch Loss after 29 is 273.447819262743\n","{'Validation Epoch Loss': 69.30666026473045, 'Epoch': 29, 'Micro F1': 0.6617388011215382, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 69.30666026473045, 'Micro ROC value': 0.7492898360007817, 'Macro ROC value': 0.7492898360007817}\n","Training Epoch Loss after 30 is 271.3381176888943\n","{'Validation Epoch Loss': 68.51164254546165, 'Epoch': 30, 'Micro F1': 0.6654668385339397, 'Patience Count': 0, 'Best Val F1': 0.6754696528026294, 'Best Val Loss': 68.51164254546165, 'Micro ROC value': 0.7538863141044114, 'Macro ROC value': 0.7538863141044114}\n","Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n","Training Epoch Loss after 31 is 267.18920692801476\n","{'Validation Epoch Loss': 67.12024658918381, 'Epoch': 31, 'Micro F1': 0.6956316296005476, 'Patience Count': 0, 'Best Val F1': 0.6956316296005476, 'Best Val Loss': 67.12024658918381, 'Micro ROC value': 0.7588057346399505, 'Macro ROC value': 0.7588057346399505}\n","Training Epoch Loss after 32 is 266.66054314374924\n","{'Validation Epoch Loss': 67.04845753312111, 'Epoch': 32, 'Micro F1': 0.6960937255705842, 'Patience Count': 0, 'Best Val F1': 0.6960937255705842, 'Best Val Loss': 67.04845753312111, 'Micro ROC value': 0.7591823952939306, 'Macro ROC value': 0.7591823952939306}\n","Training Epoch Loss after 33 is 266.39429718255997\n","{'Validation Epoch Loss': 66.98276972770691, 'Epoch': 33, 'Micro F1': 0.6966044632216775, 'Patience Count': 0, 'Best Val F1': 0.6966044632216775, 'Best Val Loss': 66.98276972770691, 'Micro ROC value': 0.7597255924793129, 'Macro ROC value': 0.7597255924793129}\n","Training Epoch Loss after 34 is 266.14892664551735\n","{'Validation Epoch Loss': 66.91881021857262, 'Epoch': 34, 'Micro F1': 0.697361883683843, 'Patience Count': 0, 'Best Val F1': 0.697361883683843, 'Best Val Loss': 66.91881021857262, 'Micro ROC value': 0.7603162743252717, 'Macro ROC value': 0.7603162743252717}\n","Training Epoch Loss after 35 is 265.91512563824654\n","{'Validation Epoch Loss': 66.85846391320229, 'Epoch': 35, 'Micro F1': 0.6979490582623107, 'Patience Count': 0, 'Best Val F1': 0.6979490582623107, 'Best Val Loss': 66.85846391320229, 'Micro ROC value': 0.7609216412568642, 'Macro ROC value': 0.7609216412568642}\n","Training Epoch Loss after 36 is 265.6872403919697\n","{'Validation Epoch Loss': 66.81256574392319, 'Epoch': 36, 'Micro F1': 0.6986960555071069, 'Patience Count': 0, 'Best Val F1': 0.6986960555071069, 'Best Val Loss': 66.81256574392319, 'Micro ROC value': 0.761536060696766, 'Macro ROC value': 0.761536060696766}\n","Training Epoch Loss after 37 is 265.46464467048645\n","{'Validation Epoch Loss': 66.75812548398972, 'Epoch': 37, 'Micro F1': 0.6994951688387494, 'Patience Count': 0, 'Best Val F1': 0.6994951688387494, 'Best Val Loss': 66.75812548398972, 'Micro ROC value': 0.7621604469528596, 'Macro ROC value': 0.7621604469528596}\n","Training Epoch Loss after 38 is 265.23994666337967\n","{'Validation Epoch Loss': 66.69232001900673, 'Epoch': 38, 'Micro F1': 0.7000580225766888, 'Patience Count': 0, 'Best Val F1': 0.7000580225766888, 'Best Val Loss': 66.69232001900673, 'Micro ROC value': 0.7627810068947446, 'Macro ROC value': 0.7627810068947446}\n","Training Epoch Loss after 39 is 265.0084938406944\n","{'Validation Epoch Loss': 66.62608760595322, 'Epoch': 39, 'Micro F1': 0.7005548626046231, 'Patience Count': 0, 'Best Val F1': 0.7005548626046231, 'Best Val Loss': 66.62608760595322, 'Micro ROC value': 0.7633777132264019, 'Macro ROC value': 0.7633777132264019}\n","Training Epoch Loss after 40 is 264.78135776519775\n","{'Validation Epoch Loss': 66.70608165860176, 'Epoch': 40, 'Micro F1': 0.7010621258499266, 'Patience Count': 0, 'Best Val F1': 0.7010621258499266, 'Best Val Loss': 66.62608760595322, 'Micro ROC value': 0.7640039987809576, 'Macro ROC value': 0.7640039987809576}\n","Training Epoch Loss after 41 is 264.55249869823456\n","{'Validation Epoch Loss': 66.6763981282711, 'Epoch': 41, 'Micro F1': 0.7015207474141735, 'Patience Count': 0, 'Best Val F1': 0.7015207474141735, 'Best Val Loss': 66.62608760595322, 'Micro ROC value': 0.764589450179771, 'Macro ROC value': 0.764589450179771}\n","Training Epoch Loss after 42 is 264.32639917731285\n","{'Validation Epoch Loss': 66.62124371528625, 'Epoch': 42, 'Micro F1': 0.7020314850652667, 'Patience Count': 0, 'Best Val F1': 0.7020314850652667, 'Best Val Loss': 66.62124371528625, 'Micro ROC value': 0.7652343563359165, 'Macro ROC value': 0.7652343563359165}\n","Training Epoch Loss after 43 is 264.1002694964409\n","{'Validation Epoch Loss': 66.57127022743225, 'Epoch': 43, 'Micro F1': 0.7026395060784729, 'Patience Count': 0, 'Best Val F1': 0.7026395060784729, 'Best Val Loss': 66.57127022743225, 'Micro ROC value': 0.7658757462392882, 'Macro ROC value': 0.7658757462392882}\n","Training Epoch Loss after 44 is 263.87466594576836\n","{'Validation Epoch Loss': 66.52376130223274, 'Epoch': 44, 'Micro F1': 0.7031432949179867, 'Patience Count': 0, 'Best Val F1': 0.7031432949179867, 'Best Val Loss': 66.52376130223274, 'Micro ROC value': 0.7665376164845664, 'Macro ROC value': 0.7665376164845664}\n","Training Epoch Loss after 45 is 263.6524530351162\n","{'Validation Epoch Loss': 66.47777932882309, 'Epoch': 45, 'Micro F1': 0.7037061486559261, 'Patience Count': 0, 'Best Val F1': 0.7037061486559261, 'Best Val Loss': 66.47777932882309, 'Micro ROC value': 0.7671863407146469, 'Macro ROC value': 0.7671863407146469}\n","Training Epoch Loss after 46 is 263.437238574028\n","{'Validation Epoch Loss': 66.43314969539642, 'Epoch': 46, 'Micro F1': 0.70448441555283, 'Patience Count': 0, 'Best Val F1': 0.70448441555283, 'Best Val Loss': 66.43314969539642, 'Micro ROC value': 0.7678464782551443, 'Macro ROC value': 0.7678464782551443}\n","Training Epoch Loss after 47 is 263.2292801141739\n","{'Validation Epoch Loss': 66.39046701788902, 'Epoch': 47, 'Micro F1': 0.7050090508270823, 'Patience Count': 0, 'Best Val F1': 0.7050090508270823, 'Best Val Loss': 66.39046701788902, 'Micro ROC value': 0.7684883184495903, 'Macro ROC value': 0.7684883184495903}\n","Training Epoch Loss after 48 is 263.0458194613457\n","{'Validation Epoch Loss': 66.3498392701149, 'Epoch': 48, 'Micro F1': 0.706027051723479, 'Patience Count': 0, 'Best Val F1': 0.706027051723479, 'Best Val Loss': 66.3498392701149, 'Micro ROC value': 0.7691554426787481, 'Macro ROC value': 0.7691554426787481}\n","Training Epoch Loss after 49 is 262.8276787996292\n","{'Validation Epoch Loss': 66.30741354823112, 'Epoch': 49, 'Micro F1': 0.7066871888235314, 'Patience Count': 0, 'Best Val F1': 0.7066871888235314, 'Best Val Loss': 66.30741354823112, 'Micro ROC value': 0.7697887811824624, 'Macro ROC value': 0.7697887811824624}\n","Training Epoch Loss after 50 is 262.6505998671055\n","{'Validation Epoch Loss': 66.26787185668945, 'Epoch': 50, 'Micro F1': 0.7075314694304407, 'Patience Count': 0, 'Best Val F1': 0.7075314694304407, 'Best Val Loss': 66.26787185668945, 'Micro ROC value': 0.7704362541717182, 'Macro ROC value': 0.7704362541717182}\n","Training Epoch Loss after 51 is 262.4500221014023\n","{'Validation Epoch Loss': 66.22704857587814, 'Epoch': 51, 'Micro F1': 0.7086849721526376, 'Patience Count': 0, 'Best Val F1': 0.7086849721526376, 'Best Val Loss': 66.22704857587814, 'Micro ROC value': 0.7711290917755855, 'Macro ROC value': 0.7711290917755855}\n","Training Epoch Loss after 52 is 262.2550033926964\n","{'Validation Epoch Loss': 66.18736165761948, 'Epoch': 52, 'Micro F1': 0.7095570480058648, 'Patience Count': 0, 'Best Val F1': 0.7095570480058648, 'Best Val Loss': 66.18736165761948, 'Micro ROC value': 0.771779955939446, 'Macro ROC value': 0.771779955939446}\n","Training Epoch Loss after 53 is 262.078868240118\n","{'Validation Epoch Loss': 66.14684063196182, 'Epoch': 53, 'Micro F1': 0.7105020863806767, 'Patience Count': 0, 'Best Val F1': 0.7105020863806767, 'Best Val Loss': 66.14684063196182, 'Micro ROC value': 0.7724299213335356, 'Macro ROC value': 0.7724299213335356}\n","Training Epoch Loss after 54 is 261.896050542593\n","{'Validation Epoch Loss': 66.10424456000328, 'Epoch': 54, 'Micro F1': 0.7112768788717909, 'Patience Count': 0, 'Best Val F1': 0.7112768788717909, 'Best Val Loss': 66.10424456000328, 'Micro ROC value': 0.7730597175345792, 'Macro ROC value': 0.7730597175345792}\n","Training Epoch Loss after 55 is 261.71932631731033\n","{'Validation Epoch Loss': 66.05847007036209, 'Epoch': 55, 'Micro F1': 0.7119265927544742, 'Patience Count': 0, 'Best Val F1': 0.7119265927544742, 'Best Val Loss': 66.05847007036209, 'Micro ROC value': 0.773692855613577, 'Macro ROC value': 0.773692855613577}\n","Training Epoch Loss after 56 is 261.561507076025\n","{'Validation Epoch Loss': 66.02052375674248, 'Epoch': 56, 'Micro F1': 0.7130627234477225, 'Patience Count': 0, 'Best Val F1': 0.7130627234477225, 'Best Val Loss': 66.02052375674248, 'Micro ROC value': 0.7745146517335499, 'Macro ROC value': 0.7745146517335499}\n","Training Epoch Loss after 57 is 261.41065964102745\n","{'Validation Epoch Loss': 65.99178606271744, 'Epoch': 57, 'Micro F1': 0.7142162261699193, 'Patience Count': 0, 'Best Val F1': 0.7142162261699193, 'Best Val Loss': 65.99178606271744, 'Micro ROC value': 0.7748901000282304, 'Macro ROC value': 0.7748901000282304}\n","Training Epoch Loss after 58 is 261.22854310274124\n","{'Validation Epoch Loss': 65.94329339265823, 'Epoch': 58, 'Micro F1': 0.7142648678509756, 'Patience Count': 0, 'Best Val F1': 0.7142648678509756, 'Best Val Loss': 65.94329339265823, 'Micro ROC value': 0.7754448388886424, 'Macro ROC value': 0.7754448388886424}\n","Training Epoch Loss after 59 is 261.0500291585922\n","{'Validation Epoch Loss': 65.90416356921196, 'Epoch': 59, 'Micro F1': 0.7150014418784029, 'Patience Count': 0, 'Best Val F1': 0.7150014418784029, 'Best Val Loss': 65.90416356921196, 'Micro ROC value': 0.7759945376981402, 'Macro ROC value': 0.7759945376981402}\n","Training Epoch Loss after 60 is 260.89776065945625\n","{'Validation Epoch Loss': 65.87424963712692, 'Epoch': 60, 'Micro F1': 0.7157275926884605, 'Patience Count': 0, 'Best Val F1': 0.7157275926884605, 'Best Val Loss': 65.87424963712692, 'Micro ROC value': 0.7765332376998928, 'Macro ROC value': 0.7765332376998928}\n","Training Epoch Loss after 61 is 260.7326659858227\n","{'Validation Epoch Loss': 65.82299190759659, 'Epoch': 61, 'Micro F1': 0.7161688422237587, 'Patience Count': 0, 'Best Val F1': 0.7161688422237587, 'Best Val Loss': 65.82299190759659, 'Micro ROC value': 0.777118753860973, 'Macro ROC value': 0.777118753860973}\n","Training Epoch Loss after 62 is 260.57996648550034\n","{'Validation Epoch Loss': 65.79536643624306, 'Epoch': 62, 'Micro F1': 0.7174404747428071, 'Patience Count': 0, 'Best Val F1': 0.7174404747428071, 'Best Val Loss': 65.79536643624306, 'Micro ROC value': 0.7776167937193275, 'Macro ROC value': 0.7776167937193275}\n","Training Epoch Loss after 63 is 260.40830385684967\n","{'Validation Epoch Loss': 65.74414071440697, 'Epoch': 63, 'Micro F1': 0.717582925380187, 'Patience Count': 0, 'Best Val F1': 0.717582925380187, 'Best Val Loss': 65.74414071440697, 'Micro ROC value': 0.7782155177097392, 'Macro ROC value': 0.7782155177097392}\n","Training Epoch Loss after 64 is 260.23394215106964\n","{'Validation Epoch Loss': 65.69466656446457, 'Epoch': 64, 'Micro F1': 0.7184688988565731, 'Patience Count': 0, 'Best Val F1': 0.7184688988565731, 'Best Val Loss': 65.69466656446457, 'Micro ROC value': 0.7788379129127707, 'Macro ROC value': 0.7788379129127707}\n","Training Epoch Loss after 65 is 260.0647620856762\n","{'Validation Epoch Loss': 65.64083206653595, 'Epoch': 65, 'Micro F1': 0.7192992818403232, 'Patience Count': 0, 'Best Val F1': 0.7192992818403232, 'Best Val Loss': 65.64083206653595, 'Micro ROC value': 0.7796860844324752, 'Macro ROC value': 0.7796860844324752}\n","Training Epoch Loss after 66 is 260.0215457677841\n","{'Validation Epoch Loss': 65.6325227022171, 'Epoch': 66, 'Micro F1': 0.7196501968250879, 'Patience Count': 0, 'Best Val F1': 0.7196501968250879, 'Best Val Loss': 65.6325227022171, 'Micro ROC value': 0.7798201417930006, 'Macro ROC value': 0.7798201417930006}\n","Training Epoch Loss after 67 is 259.9071998298168\n","{'Validation Epoch Loss': 65.58200401067734, 'Epoch': 67, 'Micro F1': 0.7198795076072114, 'Patience Count': 0, 'Best Val F1': 0.7198795076072114, 'Best Val Loss': 65.58200401067734, 'Micro ROC value': 0.7803857943036098, 'Macro ROC value': 0.7803857943036098}\n","Training Epoch Loss after 68 is 259.6684862971306\n","{'Validation Epoch Loss': 65.55050849914551, 'Epoch': 68, 'Micro F1': 0.7203902452583048, 'Patience Count': 0, 'Best Val F1': 0.7203902452583048, 'Best Val Loss': 65.55050849914551, 'Micro ROC value': 0.7809117436299722, 'Macro ROC value': 0.7809117436299722}\n","Training Epoch Loss after 69 is 259.4886194765568\n","{'Validation Epoch Loss': 65.50859478116035, 'Epoch': 69, 'Micro F1': 0.7211407169088907, 'Patience Count': 0, 'Best Val F1': 0.7211407169088907, 'Best Val Loss': 65.50859478116035, 'Micro ROC value': 0.7814464427735417, 'Macro ROC value': 0.7814464427735417}\n","Training Epoch Loss after 70 is 259.32076331973076\n","{'Validation Epoch Loss': 65.46879544854164, 'Epoch': 70, 'Micro F1': 0.7212414746767934, 'Patience Count': 0, 'Best Val F1': 0.7212414746767934, 'Best Val Loss': 65.46879544854164, 'Micro ROC value': 0.7819122377892658, 'Macro ROC value': 0.7819122377892658}\n","Training Epoch Loss after 71 is 259.16907984018326\n","{'Validation Epoch Loss': 65.43104007840157, 'Epoch': 71, 'Micro F1': 0.7214603622415476, 'Patience Count': 0, 'Best Val F1': 0.7214603622415476, 'Best Val Loss': 65.43104007840157, 'Micro ROC value': 0.7823801470513487, 'Macro ROC value': 0.7823801470513487}\n","Training Epoch Loss after 72 is 259.03237345814705\n","{'Validation Epoch Loss': 65.39591348171234, 'Epoch': 72, 'Micro F1': 0.7224644655147854, 'Patience Count': 0, 'Best Val F1': 0.7224644655147854, 'Best Val Loss': 65.39591348171234, 'Micro ROC value': 0.7828836147851022, 'Macro ROC value': 0.7828836147851022}\n","Training Epoch Loss after 73 is 258.89795914292336\n","{'Validation Epoch Loss': 65.35380113124847, 'Epoch': 73, 'Micro F1': 0.722106601718441, 'Patience Count': 0, 'Best Val F1': 0.7224644655147854, 'Best Val Loss': 65.35380113124847, 'Micro ROC value': 0.7835060949523612, 'Macro ROC value': 0.7835060949523612}\n","Training Epoch Loss after 74 is 258.76138919591904\n","{'Validation Epoch Loss': 65.33257073163986, 'Epoch': 74, 'Micro F1': 0.7223671821526724, 'Patience Count': 0, 'Best Val F1': 0.7224644655147854, 'Best Val Loss': 65.33257073163986, 'Micro ROC value': 0.7837618852690609, 'Macro ROC value': 0.7837618852690609}\n","Training Epoch Loss after 75 is 258.61704456806183\n","{'Validation Epoch Loss': 65.29146918654442, 'Epoch': 75, 'Micro F1': 0.72309333296273, 'Patience Count': 0, 'Best Val F1': 0.72309333296273, 'Best Val Loss': 65.29146918654442, 'Micro ROC value': 0.7842840323495797, 'Macro ROC value': 0.7842840323495797}\n","Training Epoch Loss after 76 is 258.4590646624565\n","{'Validation Epoch Loss': 65.24641746282578, 'Epoch': 76, 'Micro F1': 0.7234824664111821, 'Patience Count': 0, 'Best Val F1': 0.7234824664111821, 'Best Val Loss': 65.24641746282578, 'Micro ROC value': 0.784863356198863, 'Macro ROC value': 0.784863356198863}\n","Training Epoch Loss after 77 is 258.2985156774521\n","{'Validation Epoch Loss': 65.19288149476051, 'Epoch': 77, 'Micro F1': 0.7234199271069666, 'Patience Count': 0, 'Best Val F1': 0.7234824664111821, 'Best Val Loss': 65.19288149476051, 'Micro ROC value': 0.785588196221831, 'Macro ROC value': 0.785588196221831}\n","Training Epoch Loss after 78 is 258.16485580801964\n","{'Validation Epoch Loss': 65.14201366901398, 'Epoch': 78, 'Micro F1': 0.7236110194254027, 'Patience Count': 0, 'Best Val F1': 0.7236110194254027, 'Best Val Loss': 65.14201366901398, 'Micro ROC value': 0.7859876517679677, 'Macro ROC value': 0.7859876517679677}\n","Training Epoch Loss after 79 is 258.00332540273666\n","{'Validation Epoch Loss': 65.09535783529282, 'Epoch': 79, 'Micro F1': 0.7238993951059519, 'Patience Count': 0, 'Best Val F1': 0.7238993951059519, 'Best Val Loss': 65.09535783529282, 'Micro ROC value': 0.7864304997243732, 'Macro ROC value': 0.7864304997243732}\n","Training Epoch Loss after 80 is 257.84190034866333\n","{'Validation Epoch Loss': 65.05066549777985, 'Epoch': 80, 'Micro F1': 0.7243093749891425, 'Patience Count': 0, 'Best Val F1': 0.7243093749891425, 'Best Val Loss': 65.05066549777985, 'Micro ROC value': 0.7868760957032459, 'Macro ROC value': 0.7868760957032459}\n","Training Epoch Loss after 81 is 257.68086045980453\n","{'Validation Epoch Loss': 65.00662696361542, 'Epoch': 81, 'Micro F1': 0.7247089316549636, 'Patience Count': 0, 'Best Val F1': 0.7247089316549636, 'Best Val Loss': 65.00662696361542, 'Micro ROC value': 0.7873269384406555, 'Macro ROC value': 0.7873269384406555}\n","Training Epoch Loss after 82 is 257.5211119353771\n","{'Validation Epoch Loss': 64.96426928043365, 'Epoch': 82, 'Micro F1': 0.7251918740597388, 'Patience Count': 0, 'Best Val F1': 0.7251918740597388, 'Best Val Loss': 64.96426928043365, 'Micro ROC value': 0.7877759977508973, 'Macro ROC value': 0.7877759977508973}\n","Training Epoch Loss after 83 is 257.3638729453087\n","{'Validation Epoch Loss': 64.92233234643936, 'Epoch': 83, 'Micro F1': 0.7256852396818835, 'Patience Count': 0, 'Best Val F1': 0.7256852396818835, 'Best Val Loss': 64.92233234643936, 'Micro ROC value': 0.7882220365055213, 'Macro ROC value': 0.7882220365055213}\n","Training Epoch Loss after 84 is 257.2083061635494\n","{'Validation Epoch Loss': 64.88195705413818, 'Epoch': 84, 'Micro F1': 0.7261751308982382, 'Patience Count': 0, 'Best Val F1': 0.7261751308982382, 'Best Val Loss': 64.88195705413818, 'Micro ROC value': 0.7886662371233608, 'Macro ROC value': 0.7886662371233608}\n","Training Epoch Loss after 85 is 257.0535391867161\n","{'Validation Epoch Loss': 64.84026736021042, 'Epoch': 85, 'Micro F1': 0.7264287625208897, 'Patience Count': 0, 'Best Val F1': 0.7264287625208897, 'Best Val Loss': 64.84026736021042, 'Micro ROC value': 0.7891048990933274, 'Macro ROC value': 0.7891048990933274}\n","Training Epoch Loss after 86 is 256.9001652896404\n","{'Validation Epoch Loss': 64.80144217610359, 'Epoch': 86, 'Micro F1': 0.726939500171983, 'Patience Count': 0, 'Best Val F1': 0.726939500171983, 'Best Val Loss': 64.80144217610359, 'Micro ROC value': 0.7895441250991403, 'Macro ROC value': 0.7895441250991403}\n","Training Epoch Loss after 87 is 256.7450307607651\n","{'Validation Epoch Loss': 64.75714302062988, 'Epoch': 87, 'Micro F1': 0.727217452635163, 'Patience Count': 0, 'Best Val F1': 0.727217452635163, 'Best Val Loss': 64.75714302062988, 'Micro ROC value': 0.7899827442970128, 'Macro ROC value': 0.7899827442970128}\n","Training Epoch Loss after 88 is 256.5845001041889\n","{'Validation Epoch Loss': 64.71647363901138, 'Epoch': 88, 'Micro F1': 0.7276691253878305, 'Patience Count': 0, 'Best Val F1': 0.7276691253878305, 'Best Val Loss': 64.71647363901138, 'Micro ROC value': 0.7904252432379637, 'Macro ROC value': 0.7904252432379637}\n","Training Epoch Loss after 89 is 256.423670232296\n","{'Validation Epoch Loss': 64.67065528035164, 'Epoch': 89, 'Micro F1': 0.7279713986915388, 'Patience Count': 0, 'Best Val F1': 0.7279713986915388, 'Best Val Loss': 64.67065528035164, 'Micro ROC value': 0.7908686509046761, 'Macro ROC value': 0.7908686509046761}\n","Training Epoch Loss after 90 is 256.2553009390831\n","{'Validation Epoch Loss': 64.62884810566902, 'Epoch': 90, 'Micro F1': 0.7283918017920985, 'Patience Count': 0, 'Best Val F1': 0.7283918017920985, 'Best Val Loss': 64.62884810566902, 'Micro ROC value': 0.7913174572312721, 'Macro ROC value': 0.7913174572312721}\n","Training Epoch Loss after 91 is 256.08647084236145\n","{'Validation Epoch Loss': 64.58337700366974, 'Epoch': 91, 'Micro F1': 0.7288886418200329, 'Patience Count': 0, 'Best Val F1': 0.7288886418200329, 'Best Val Loss': 64.58337700366974, 'Micro ROC value': 0.791754612560266, 'Macro ROC value': 0.791754612560266}\n","Training Epoch Loss after 92 is 255.9140361249447\n","{'Validation Epoch Loss': 64.54220905900002, 'Epoch': 92, 'Micro F1': 0.7293507377900693, 'Patience Count': 0, 'Best Val F1': 0.7293507377900693, 'Best Val Loss': 64.54220905900002, 'Micro ROC value': 0.7921954199978036, 'Macro ROC value': 0.7921954199978036}\n","Training Epoch Loss after 93 is 255.74550500512123\n","{'Validation Epoch Loss': 64.49873000383377, 'Epoch': 93, 'Micro F1': 0.7296286902532494, 'Patience Count': 0, 'Best Val F1': 0.7296286902532494, 'Best Val Loss': 64.49873000383377, 'Micro ROC value': 0.7926177049679176, 'Macro ROC value': 0.7926177049679176}\n","Training Epoch Loss after 94 is 255.57536694407463\n","{'Validation Epoch Loss': 64.46013662219048, 'Epoch': 94, 'Micro F1': 0.7301290046869734, 'Patience Count': 0, 'Best Val F1': 0.7301290046869734, 'Best Val Loss': 64.46013662219048, 'Micro ROC value': 0.7930518005456233, 'Macro ROC value': 0.7930518005456233}\n","Training Epoch Loss after 95 is 255.41069090366364\n","{'Validation Epoch Loss': 64.41834768652916, 'Epoch': 95, 'Micro F1': 0.7304000083385739, 'Patience Count': 0, 'Best Val F1': 0.7304000083385739, 'Best Val Loss': 64.41834768652916, 'Micro ROC value': 0.7934721230740648, 'Macro ROC value': 0.7934721230740648}\n","Training Epoch Loss after 96 is 255.24597698450089\n","{'Validation Epoch Loss': 64.3815493285656, 'Epoch': 96, 'Micro F1': 0.7308204114391338, 'Patience Count': 0, 'Best Val F1': 0.7308204114391338, 'Best Val Loss': 64.3815493285656, 'Micro ROC value': 0.7939032379684436, 'Macro ROC value': 0.7939032379684436}\n","Training Epoch Loss after 97 is 255.08529022336006\n","{'Validation Epoch Loss': 64.33932077884674, 'Epoch': 97, 'Micro F1': 0.7309767596996724, 'Patience Count': 0, 'Best Val F1': 0.7309767596996724, 'Best Val Loss': 64.33932077884674, 'Micro ROC value': 0.7943152207601506, 'Macro ROC value': 0.7943152207601506}\n","Training Epoch Loss after 98 is 254.92155346274376\n","{'Validation Epoch Loss': 64.30072408914566, 'Epoch': 98, 'Micro F1': 0.7313867395828628, 'Patience Count': 0, 'Best Val F1': 0.7313867395828628, 'Best Val Loss': 64.30072408914566, 'Micro ROC value': 0.794755457540625, 'Macro ROC value': 0.794755457540625}\n","Training Epoch Loss after 99 is 254.76033928990364\n","{'Validation Epoch Loss': 64.25704973936081, 'Epoch': 99, 'Micro F1': 0.73170291050973, 'Patience Count': 0, 'Best Val F1': 0.73170291050973, 'Best Val Loss': 64.25704973936081, 'Micro ROC value': 0.7951577036638375, 'Macro ROC value': 0.7951577036638375}\n","Training Epoch Loss after 100 is 254.59650847315788\n","{'Validation Epoch Loss': 64.21585947275162, 'Epoch': 100, 'Micro F1': 0.7321163647987103, 'Patience Count': 0, 'Best Val F1': 0.7321163647987103, 'Best Val Loss': 64.21585947275162, 'Micro ROC value': 0.7955902239477348, 'Macro ROC value': 0.7955902239477348}\n","Training Epoch Loss after 101 is 254.43379446864128\n","{'Validation Epoch Loss': 64.17123630642891, 'Epoch': 101, 'Micro F1': 0.7323456755808337, 'Patience Count': 0, 'Best Val F1': 0.7323456755808337, 'Best Val Loss': 64.17123630642891, 'Micro ROC value': 0.7959905912402611, 'Macro ROC value': 0.7959905912402611}\n","Training Epoch Loss after 102 is 254.2730651795864\n","{'Validation Epoch Loss': 64.12763583660126, 'Epoch': 102, 'Micro F1': 0.7325958327976957, 'Patience Count': 0, 'Best Val F1': 0.7325958327976957, 'Best Val Loss': 64.12763583660126, 'Micro ROC value': 0.7963844865108274, 'Macro ROC value': 0.7963844865108274}\n","Training Epoch Loss after 103 is 254.1059868633747\n","{'Validation Epoch Loss': 64.08484718203545, 'Epoch': 103, 'Micro F1': 0.7329988638693068, 'Patience Count': 0, 'Best Val F1': 0.7329988638693068, 'Best Val Loss': 64.08484718203545, 'Micro ROC value': 0.7967995922695278, 'Macro ROC value': 0.7967995922695278}\n","Training Epoch Loss after 104 is 253.94000512361526\n","{'Validation Epoch Loss': 64.04097807407379, 'Epoch': 104, 'Micro F1': 0.7334088437524973, 'Patience Count': 0, 'Best Val F1': 0.7334088437524973, 'Best Val Loss': 64.04097807407379, 'Micro ROC value': 0.797187825481439, 'Macro ROC value': 0.797187825481439}\n","Training Epoch Loss after 105 is 253.77223390340805\n","{'Validation Epoch Loss': 63.99807494878769, 'Epoch': 105, 'Micro F1': 0.7337562843314722, 'Patience Count': 0, 'Best Val F1': 0.7337562843314722, 'Best Val Loss': 63.99807494878769, 'Micro ROC value': 0.7975770758234135, 'Macro ROC value': 0.7975770758234135}\n","Training Epoch Loss after 106 is 253.60350328683853\n","{'Validation Epoch Loss': 63.95513904094696, 'Epoch': 106, 'Micro F1': 0.7340724552583393, 'Patience Count': 0, 'Best Val F1': 0.7340724552583393, 'Best Val Loss': 63.95513904094696, 'Micro ROC value': 0.7979458520338929, 'Macro ROC value': 0.7979458520338929}\n","Training Epoch Loss after 107 is 253.43311527371407\n","{'Validation Epoch Loss': 63.912730664014816, 'Epoch': 107, 'Micro F1': 0.7343712541562579, 'Patience Count': 0, 'Best Val F1': 0.7343712541562579, 'Best Val Loss': 63.912730664014816, 'Micro ROC value': 0.7983000171278797, 'Macro ROC value': 0.7983000171278797}\n","Training Epoch Loss after 108 is 253.26341067254543\n","{'Validation Epoch Loss': 63.865809977054596, 'Epoch': 108, 'Micro F1': 0.7346214113731199, 'Patience Count': 0, 'Best Val F1': 0.7346214113731199, 'Best Val Loss': 63.865809977054596, 'Micro ROC value': 0.7986040620995091, 'Macro ROC value': 0.7986040620995091}\n","Training Epoch Loss after 109 is 253.07695846259594\n","{'Validation Epoch Loss': 63.833748519420624, 'Epoch': 109, 'Micro F1': 0.7353892550526546, 'Patience Count': 0, 'Best Val F1': 0.7353892550526546, 'Best Val Loss': 63.833748519420624, 'Micro ROC value': 0.7990150102656747, 'Macro ROC value': 0.7990150102656747}\n","Training Epoch Loss after 110 is 252.89435920119286\n","{'Validation Epoch Loss': 63.81729942560196, 'Epoch': 110, 'Micro F1': 0.7362821773406203, 'Patience Count': 0, 'Best Val F1': 0.7362821773406203, 'Best Val Loss': 63.81729942560196, 'Micro ROC value': 0.7994095067862258, 'Macro ROC value': 0.7994095067862258}\n","Training Epoch Loss after 111 is 252.7306062579155\n","{'Validation Epoch Loss': 63.78477489948273, 'Epoch': 111, 'Micro F1': 0.7368797751364574, 'Patience Count': 0, 'Best Val F1': 0.7368797751364574, 'Best Val Loss': 63.78477489948273, 'Micro ROC value': 0.7998525671532002, 'Macro ROC value': 0.7998525671532002}\n","Training Epoch Loss after 112 is 252.57007613778114\n","{'Validation Epoch Loss': 63.72745567560196, 'Epoch': 112, 'Micro F1': 0.7367651197453955, 'Patience Count': 0, 'Best Val F1': 0.7368797751364574, 'Best Val Loss': 63.72745567560196, 'Micro ROC value': 0.8000307316771011, 'Macro ROC value': 0.8000307316771011}\n","Training Epoch Loss after 113 is 252.37880082428455\n","{'Validation Epoch Loss': 63.66958674788475, 'Epoch': 113, 'Micro F1': 0.7368207102380315, 'Patience Count': 0, 'Best Val F1': 0.7368797751364574, 'Best Val Loss': 63.66958674788475, 'Micro ROC value': 0.8003226572362857, 'Macro ROC value': 0.8003226572362857}\n","Training Epoch Loss after 114 is 252.20758217573166\n","{'Validation Epoch Loss': 63.63133639097214, 'Epoch': 114, 'Micro F1': 0.7372967038312273, 'Patience Count': 0, 'Best Val F1': 0.7372967038312273, 'Best Val Loss': 63.63133639097214, 'Micro ROC value': 0.8007791541062224, 'Macro ROC value': 0.8007791541062224}\n","Training Epoch Loss after 115 is 252.04351358115673\n","{'Validation Epoch Loss': 63.603119641542435, 'Epoch': 115, 'Micro F1': 0.7380471754818131, 'Patience Count': 0, 'Best Val F1': 0.7380471754818131, 'Best Val Loss': 63.603119641542435, 'Micro ROC value': 0.8012026912112666, 'Macro ROC value': 0.8012026912112666}\n","Training Epoch Loss after 116 is 251.88583399355412\n","{'Validation Epoch Loss': 63.56116884946823, 'Epoch': 116, 'Micro F1': 0.7382660630465675, 'Patience Count': 0, 'Best Val F1': 0.7382660630465675, 'Best Val Loss': 63.56116884946823, 'Micro ROC value': 0.8014433499210023, 'Macro ROC value': 0.8014433499210023}\n","Training Epoch Loss after 117 is 251.7214776277542\n","{'Validation Epoch Loss': 63.528037428855896, 'Epoch': 117, 'Micro F1': 0.7388671352481941, 'Patience Count': 0, 'Best Val F1': 0.7388671352481941, 'Best Val Loss': 63.528037428855896, 'Micro ROC value': 0.8018221329407895, 'Macro ROC value': 0.8018221329407895}\n","Training Epoch Loss after 118 is 251.56342297792435\n","{'Validation Epoch Loss': 63.48796999454498, 'Epoch': 118, 'Micro F1': 0.7391242412766357, 'Patience Count': 0, 'Best Val F1': 0.7391242412766357, 'Best Val Loss': 63.48796999454498, 'Micro ROC value': 0.8020993038673983, 'Macro ROC value': 0.8020993038673983}\n","Training Epoch Loss after 119 is 251.40156254172325\n","{'Validation Epoch Loss': 63.45252338051796, 'Epoch': 119, 'Micro F1': 0.7395620164061442, 'Patience Count': 0, 'Best Val F1': 0.7395620164061442, 'Best Val Loss': 63.45252338051796, 'Micro ROC value': 0.8024659088020601, 'Macro ROC value': 0.8024659088020601}\n","Training Epoch Loss after 120 is 251.24139355123043\n","{'Validation Epoch Loss': 63.41254726052284, 'Epoch': 120, 'Micro F1': 0.7398642897098524, 'Patience Count': 0, 'Best Val F1': 0.7398642897098524, 'Best Val Loss': 63.41254726052284, 'Micro ROC value': 0.8027567212718676, 'Macro ROC value': 0.8027567212718676}\n","Training Epoch Loss after 121 is 251.0820592045784\n","{'Validation Epoch Loss': 63.37603658437729, 'Epoch': 121, 'Micro F1': 0.7402429999409351, 'Patience Count': 0, 'Best Val F1': 0.7402429999409351, 'Best Val Loss': 63.37603658437729, 'Micro ROC value': 0.8031242163252217, 'Macro ROC value': 0.8031242163252217}\n","Training Epoch Loss after 122 is 250.918376237154\n","{'Validation Epoch Loss': 63.33496397733688, 'Epoch': 122, 'Micro F1': 0.740465361911479, 'Patience Count': 0, 'Best Val F1': 0.740465361911479, 'Best Val Loss': 63.33496397733688, 'Micro ROC value': 0.8034052370786082, 'Macro ROC value': 0.8034052370786082}\n","Training Epoch Loss after 123 is 250.7587559968233\n","{'Validation Epoch Loss': 63.298470199108124, 'Epoch': 123, 'Micro F1': 0.7410733829246853, 'Patience Count': 0, 'Best Val F1': 0.7410733829246853, 'Best Val Loss': 63.298470199108124, 'Micro ROC value': 0.8037782340973274, 'Macro ROC value': 0.8037782340973274}\n","Training Epoch Loss after 124 is 250.59489269554615\n","{'Validation Epoch Loss': 63.25809624791145, 'Epoch': 124, 'Micro F1': 0.7414069258805013, 'Patience Count': 0, 'Best Val F1': 0.7414069258805013, 'Best Val Loss': 63.25809624791145, 'Micro ROC value': 0.8040684136368026, 'Macro ROC value': 0.8040684136368026}\n","Training Epoch Loss after 125 is 250.43339638412\n","{'Validation Epoch Loss': 63.21968710422516, 'Epoch': 125, 'Micro F1': 0.741785636111584, 'Patience Count': 0, 'Best Val F1': 0.741785636111584, 'Best Val Loss': 63.21968710422516, 'Micro ROC value': 0.8044163503889405, 'Macro ROC value': 0.8044163503889405}\n","Training Epoch Loss after 126 is 250.27075181901455\n","{'Validation Epoch Loss': 63.17990383505821, 'Epoch': 126, 'Micro F1': 0.7421990904005642, 'Patience Count': 0, 'Best Val F1': 0.7421990904005642, 'Best Val Loss': 63.17990383505821, 'Micro ROC value': 0.8047359502662754, 'Macro ROC value': 0.8047359502662754}\n","Training Epoch Loss after 127 is 250.11015038192272\n","{'Validation Epoch Loss': 63.14015507698059, 'Epoch': 127, 'Micro F1': 0.7426021214721751, 'Patience Count': 0, 'Best Val F1': 0.7426021214721751, 'Best Val Loss': 63.14015507698059, 'Micro ROC value': 0.8050750859230232, 'Macro ROC value': 0.8050750859230232}\n","Training Epoch Loss after 128 is 249.94693879783154\n","{'Validation Epoch Loss': 63.0999156832695, 'Epoch': 128, 'Micro F1': 0.743022524572735, 'Patience Count': 0, 'Best Val F1': 0.743022524572735, 'Best Val Loss': 63.0999156832695, 'Micro ROC value': 0.8054024931332642, 'Macro ROC value': 0.8054024931332642}\n","Training Epoch Loss after 129 is 249.78560027480125\n","{'Validation Epoch Loss': 63.05950570106506, 'Epoch': 129, 'Micro F1': 0.7433491187169714, 'Patience Count': 0, 'Best Val F1': 0.7433491187169714, 'Best Val Loss': 63.05950570106506, 'Micro ROC value': 0.8057400035229321, 'Macro ROC value': 0.8057400035229321}\n","Training Epoch Loss after 130 is 249.6227381080389\n","{'Validation Epoch Loss': 63.0186602473259, 'Epoch': 130, 'Micro F1': 0.7437278289480542, 'Patience Count': 0, 'Best Val F1': 0.7437278289480542, 'Best Val Loss': 63.0186602473259, 'Micro ROC value': 0.8060729064639616, 'Macro ROC value': 0.8060729064639616}\n","Training Epoch Loss after 131 is 249.4605951011181\n","{'Validation Epoch Loss': 62.97731560468674, 'Epoch': 131, 'Micro F1': 0.7441829761065115, 'Patience Count': 0, 'Best Val F1': 0.7441829761065115, 'Best Val Loss': 62.97731560468674, 'Micro ROC value': 0.8064086634635874, 'Macro ROC value': 0.8064086634635874}\n","Training Epoch Loss after 132 is 249.29760651290417\n","{'Validation Epoch Loss': 62.93575993180275, 'Epoch': 132, 'Micro F1': 0.7446485464823378, 'Patience Count': 0, 'Best Val F1': 0.7446485464823378, 'Best Val Loss': 62.93575993180275, 'Micro ROC value': 0.8067378119813577, 'Macro ROC value': 0.8067378119813577}\n","Training Epoch Loss after 133 is 249.135328322649\n","{'Validation Epoch Loss': 62.89417678117752, 'Epoch': 133, 'Micro F1': 0.7450168334960512, 'Patience Count': 0, 'Best Val F1': 0.7450168334960512, 'Best Val Loss': 62.89417678117752, 'Micro ROC value': 0.8070661413047839, 'Macro ROC value': 0.8070661413047839}\n","Training Epoch Loss after 134 is 248.97297798097134\n","{'Validation Epoch Loss': 62.85290914773941, 'Epoch': 134, 'Micro F1': 0.7453607996692364, 'Patience Count': 0, 'Best Val F1': 0.7453607996692364, 'Best Val Loss': 62.85290914773941, 'Micro ROC value': 0.8073867701047142, 'Macro ROC value': 0.8073867701047142}\n","Training Epoch Loss after 135 is 248.81131075322628\n","{'Validation Epoch Loss': 62.81198036670685, 'Epoch': 135, 'Micro F1': 0.7458298444508528, 'Patience Count': 0, 'Best Val F1': 0.7458298444508528, 'Best Val Loss': 62.81198036670685, 'Micro ROC value': 0.8077017014925578, 'Macro ROC value': 0.8077017014925578}\n","Training Epoch Loss after 136 is 248.64983342587948\n","{'Validation Epoch Loss': 62.77189442515373, 'Epoch': 136, 'Micro F1': 0.7462398243340433, 'Patience Count': 0, 'Best Val F1': 0.7462398243340433, 'Best Val Loss': 62.77189442515373, 'Micro ROC value': 0.808005414195095, 'Macro ROC value': 0.808005414195095}\n","Training Epoch Loss after 137 is 248.4888351559639\n","{'Validation Epoch Loss': 62.75599664449692, 'Epoch': 137, 'Micro F1': 0.7465803161014387, 'Patience Count': 0, 'Best Val F1': 0.7465803161014387, 'Best Val Loss': 62.75599664449692, 'Micro ROC value': 0.8082738781974157, 'Macro ROC value': 0.8082738781974157}\n","Training Epoch Loss after 138 is 248.32796230912209\n","{'Validation Epoch Loss': 62.706124007701874, 'Epoch': 138, 'Micro F1': 0.746993770390419, 'Patience Count': 0, 'Best Val F1': 0.746993770390419, 'Best Val Loss': 62.706124007701874, 'Micro ROC value': 0.8085558600905025, 'Macro ROC value': 0.8085558600905025}\n","Training Epoch Loss after 139 is 248.16729152202606\n","{'Validation Epoch Loss': 62.711842745542526, 'Epoch': 139, 'Micro F1': 0.74725782523044, 'Patience Count': 0, 'Best Val F1': 0.74725782523044, 'Best Val Loss': 62.706124007701874, 'Micro ROC value': 0.8088100188088858, 'Macro ROC value': 0.8088100188088858}\n","Training Epoch Loss after 140 is 248.00677940249443\n","{'Validation Epoch Loss': 62.6744165122509, 'Epoch': 140, 'Micro F1': 0.747646958678892, 'Patience Count': 0, 'Best Val F1': 0.747646958678892, 'Best Val Loss': 62.6744165122509, 'Micro ROC value': 0.809073641130982, 'Macro ROC value': 0.809073641130982}\n","Training Epoch Loss after 141 is 247.84635040163994\n","{'Validation Epoch Loss': 62.63506519794464, 'Epoch': 141, 'Micro F1': 0.7479770272289182, 'Patience Count': 0, 'Best Val F1': 0.7479770272289182, 'Best Val Loss': 62.63506519794464, 'Micro ROC value': 0.8093261690243294, 'Macro ROC value': 0.8093261690243294}\n","Training Epoch Loss after 142 is 247.68598008155823\n","{'Validation Epoch Loss': 62.5954070687294, 'Epoch': 142, 'Micro F1': 0.748355737460001, 'Patience Count': 0, 'Best Val F1': 0.748355737460001, 'Best Val Loss': 62.5954070687294, 'Micro ROC value': 0.8095716560751959, 'Macro ROC value': 0.8095716560751959}\n","Training Epoch Loss after 143 is 247.52565635740757\n","{'Validation Epoch Loss': 62.55591267347336, 'Epoch': 143, 'Micro F1': 0.7487031780389759, 'Patience Count': 0, 'Best Val F1': 0.7487031780389759, 'Best Val Loss': 62.55591267347336, 'Micro ROC value': 0.8098112590149934, 'Macro ROC value': 0.8098112590149934}\n","Training Epoch Loss after 144 is 247.36549420654774\n","{'Validation Epoch Loss': 62.51549082994461, 'Epoch': 144, 'Micro F1': 0.7490228233716328, 'Patience Count': 0, 'Best Val F1': 0.7490228233716328, 'Best Val Loss': 62.51549082994461, 'Micro ROC value': 0.8100455025389075, 'Macro ROC value': 0.8100455025389075}\n","Training Epoch Loss after 145 is 247.20547150075436\n","{'Validation Epoch Loss': 62.47754293680191, 'Epoch': 145, 'Micro F1': 0.7493424687042899, 'Patience Count': 0, 'Best Val F1': 0.7493424687042899, 'Best Val Loss': 62.47754293680191, 'Micro ROC value': 0.8102756563981721, 'Macro ROC value': 0.8102756563981721}\n","Training Epoch Loss after 146 is 247.04537098109722\n","{'Validation Epoch Loss': 62.43807315826416, 'Epoch': 146, 'Micro F1': 0.7497593973990598, 'Patience Count': 0, 'Best Val F1': 0.7497593973990598, 'Best Val Loss': 62.43807315826416, 'Micro ROC value': 0.8105034553032646, 'Macro ROC value': 0.8105034553032646}\n","Training Epoch Loss after 147 is 246.88541226089\n","{'Validation Epoch Loss': 62.39851611852646, 'Epoch': 147, 'Micro F1': 0.7499748105580243, 'Patience Count': 0, 'Best Val F1': 0.7499748105580243, 'Best Val Loss': 62.39851611852646, 'Micro ROC value': 0.8107311091698778, 'Macro ROC value': 0.8107311091698778}\n","Training Epoch Loss after 148 is 246.7254207879305\n","{'Validation Epoch Loss': 62.35908657312393, 'Epoch': 148, 'Micro F1': 0.7503257255427891, 'Patience Count': 0, 'Best Val F1': 0.7503257255427891, 'Best Val Loss': 62.35908657312393, 'Micro ROC value': 0.8109523544718863, 'Macro ROC value': 0.8109523544718863}\n","Training Epoch Loss after 149 is 246.5660421848297\n","{'Validation Epoch Loss': 62.31952065229416, 'Epoch': 149, 'Micro F1': 0.7506557940928152, 'Patience Count': 0, 'Best Val F1': 0.7506557940928152, 'Best Val Loss': 62.31952065229416, 'Micro ROC value': 0.8111757759068827, 'Macro ROC value': 0.8111757759068827}\n","Training Epoch Loss after 150 is 246.40623454749584\n","{'Validation Epoch Loss': 62.28007158637047, 'Epoch': 150, 'Micro F1': 0.7509129001212568, 'Patience Count': 0, 'Best Val F1': 0.7509129001212568, 'Best Val Loss': 62.28007158637047, 'Micro ROC value': 0.8113954843616376, 'Macro ROC value': 0.8113954843616376}\n","Training Epoch Loss after 151 is 246.24718676507473\n","{'Validation Epoch Loss': 62.2404448390007, 'Epoch': 151, 'Micro F1': 0.7511839037728573, 'Patience Count': 0, 'Best Val F1': 0.7511839037728573, 'Best Val Loss': 62.2404448390007, 'Micro ROC value': 0.8116151762633502, 'Macro ROC value': 0.8116151762633502}\n","Training Epoch Loss after 152 is 246.08750270307064\n","{'Validation Epoch Loss': 62.201056495308876, 'Epoch': 152, 'Micro F1': 0.7514027913376115, 'Patience Count': 0, 'Best Val F1': 0.7514027913376115, 'Best Val Loss': 62.201056495308876, 'Micro ROC value': 0.8118322847064156, 'Macro ROC value': 0.8118322847064156}\n","Training Epoch Loss after 153 is 245.9292106628418\n","{'Validation Epoch Loss': 62.161604821681976, 'Epoch': 153, 'Micro F1': 0.7517953991918533, 'Patience Count': 0, 'Best Val F1': 0.7517953991918533, 'Best Val Loss': 62.161604821681976, 'Micro ROC value': 0.8120503200956712, 'Macro ROC value': 0.8120503200956712}\n","Training Epoch Loss after 154 is 245.77015866339207\n","{'Validation Epoch Loss': 62.12302578985691, 'Epoch': 154, 'Micro F1': 0.7521775838287257, 'Patience Count': 0, 'Best Val F1': 0.7521775838287257, 'Best Val Loss': 62.12302578985691, 'Micro ROC value': 0.8122578158851499, 'Macro ROC value': 0.8122578158851499}\n","Training Epoch Loss after 155 is 245.65215998888016\n","{'Validation Epoch Loss': 62.12764789164066, 'Epoch': 155, 'Micro F1': 0.7524173178282184, 'Patience Count': 0, 'Best Val F1': 0.7524173178282184, 'Best Val Loss': 62.12302578985691, 'Micro ROC value': 0.8120412979627982, 'Macro ROC value': 0.8120412979627982}\n","Training Epoch Loss after 156 is 245.48101338744164\n","{'Validation Epoch Loss': 62.07111673057079, 'Epoch': 156, 'Micro F1': 0.7524659595092749, 'Patience Count': 0, 'Best Val F1': 0.7524659595092749, 'Best Val Loss': 62.07111673057079, 'Micro ROC value': 0.8122924867754557, 'Macro ROC value': 0.8122924867754557}\n","Training Epoch Loss after 157 is 245.31447741389275\n","{'Validation Epoch Loss': 62.02434450387955, 'Epoch': 157, 'Micro F1': 0.7526257821756034, 'Patience Count': 0, 'Best Val F1': 0.7526257821756034, 'Best Val Loss': 62.02434450387955, 'Micro ROC value': 0.812619431684605, 'Macro ROC value': 0.812619431684605}\n","Training Epoch Loss after 158 is 245.15437383949757\n","{'Validation Epoch Loss': 61.98488526046276, 'Epoch': 158, 'Micro F1': 0.7528377209287782, 'Patience Count': 0, 'Best Val F1': 0.7528377209287782, 'Best Val Loss': 61.98488526046276, 'Micro ROC value': 0.812962100340489, 'Macro ROC value': 0.812962100340489}\n","Training Epoch Loss after 159 is 245.0804909169674\n","{'Validation Epoch Loss': 61.9965975433588, 'Epoch': 159, 'Micro F1': 0.7530496596819528, 'Patience Count': 0, 'Best Val F1': 0.7530496596819528, 'Best Val Loss': 61.98488526046276, 'Micro ROC value': 0.8120986288560917, 'Macro ROC value': 0.8120986288560917}\n","Training Epoch Loss after 160 is 244.898249194026\n","{'Validation Epoch Loss': 61.95273721218109, 'Epoch': 160, 'Micro F1': 0.7531365198266966, 'Patience Count': 0, 'Best Val F1': 0.7531365198266966, 'Best Val Loss': 61.95273721218109, 'Micro ROC value': 0.8130596515012322, 'Macro ROC value': 0.8130596515012322}\n","Training Epoch Loss after 161 is 244.72102931141853\n","{'Validation Epoch Loss': 61.90224201977253, 'Epoch': 161, 'Micro F1': 0.7534109978840867, 'Patience Count': 0, 'Best Val F1': 0.7534109978840867, 'Best Val Loss': 61.90224201977253, 'Micro ROC value': 0.8134357771415608, 'Macro ROC value': 0.8134357771415608}\n","Training Epoch Loss after 162 is 244.5617551803589\n","{'Validation Epoch Loss': 61.85785619914532, 'Epoch': 162, 'Micro F1': 0.7536298854488412, 'Patience Count': 0, 'Best Val F1': 0.7536298854488412, 'Best Val Loss': 61.85785619914532, 'Micro ROC value': 0.8137615222813888, 'Macro ROC value': 0.8137615222813888}\n","Training Epoch Loss after 163 is 244.4101925343275\n","{'Validation Epoch Loss': 61.815646320581436, 'Epoch': 163, 'Micro F1': 0.7539564795930774, 'Patience Count': 0, 'Best Val F1': 0.7539564795930774, 'Best Val Loss': 61.815646320581436, 'Micro ROC value': 0.8140202665790627, 'Macro ROC value': 0.8140202665790627}\n","Training Epoch Loss after 164 is 244.26952989399433\n","{'Validation Epoch Loss': 61.80312459170818, 'Epoch': 164, 'Micro F1': 0.7542622273025754, 'Patience Count': 0, 'Best Val F1': 0.7542622273025754, 'Best Val Loss': 61.80312459170818, 'Micro ROC value': 0.8139933783008424, 'Macro ROC value': 0.8139933783008424}\n","Training Epoch Loss after 165 is 244.12516564130783\n","{'Validation Epoch Loss': 61.75503335893154, 'Epoch': 165, 'Micro F1': 0.7543699338820579, 'Patience Count': 0, 'Best Val F1': 0.7543699338820579, 'Best Val Loss': 61.75503335893154, 'Micro ROC value': 0.8142933898881652, 'Macro ROC value': 0.8142933898881652}\n","Training Epoch Loss after 166 is 243.9668530523777\n","{'Validation Epoch Loss': 61.71335232257843, 'Epoch': 166, 'Micro F1': 0.7545471285773351, 'Patience Count': 0, 'Best Val F1': 0.7545471285773351, 'Best Val Loss': 61.71335232257843, 'Micro ROC value': 0.8145921430818162, 'Macro ROC value': 0.8145921430818162}\n","Training Epoch Loss after 167 is 244.03952199220657\n","{'Validation Epoch Loss': 61.75131404399872, 'Epoch': 167, 'Micro F1': 0.7552559073584442, 'Patience Count': 0, 'Best Val F1': 0.7552559073584442, 'Best Val Loss': 61.71335232257843, 'Micro ROC value': 0.8144603401972892, 'Macro ROC value': 0.8144603401972892}\n","Training Epoch Loss after 168 is 244.20810963213444\n","{'Validation Epoch Loss': 61.72654092311859, 'Epoch': 168, 'Micro F1': 0.7548355042578843, 'Patience Count': 1, 'Best Val F1': 0.7552559073584442, 'Best Val Loss': 61.71335232257843, 'Micro ROC value': 0.8128998400962605, 'Macro ROC value': 0.8128998400962605}\n","Training Epoch Loss after 169 is 243.9699814170599\n","{'Validation Epoch Loss': 61.66505740582943, 'Epoch': 169, 'Micro F1': 0.7550960846921155, 'Patience Count': 0, 'Best Val F1': 0.7552559073584442, 'Best Val Loss': 61.66505740582943, 'Micro ROC value': 0.8137523387744796, 'Macro ROC value': 0.8137523387744796}\n","Training Epoch Loss after 170 is 243.7635016143322\n","{'Validation Epoch Loss': 61.60952687263489, 'Epoch': 170, 'Micro F1': 0.7553184466626595, 'Patience Count': 0, 'Best Val F1': 0.7553184466626595, 'Best Val Loss': 61.60952687263489, 'Micro ROC value': 0.8144359556089691, 'Macro ROC value': 0.8144359556089691}\n","Training Epoch Loss after 171 is 243.63464353978634\n","{'Validation Epoch Loss': 61.56308954954147, 'Epoch': 171, 'Micro F1': 0.7554782693289879, 'Patience Count': 0, 'Best Val F1': 0.7554782693289879, 'Best Val Loss': 61.56308954954147, 'Micro ROC value': 0.8149172168205923, 'Macro ROC value': 0.8149172168205923}\n","Training Epoch Loss after 172 is 243.48331207036972\n","{'Validation Epoch Loss': 61.519969180226326, 'Epoch': 172, 'Micro F1': 0.7556346175895267, 'Patience Count': 0, 'Best Val F1': 0.7556346175895267, 'Best Val Loss': 61.519969180226326, 'Micro ROC value': 0.8153081143714893, 'Macro ROC value': 0.8153081143714893}\n","Training Epoch Loss after 173 is 243.3507145792246\n","{'Validation Epoch Loss': 61.481386959552765, 'Epoch': 173, 'Micro F1': 0.7558118122848041, 'Patience Count': 0, 'Best Val F1': 0.7558118122848041, 'Best Val Loss': 61.481386959552765, 'Micro ROC value': 0.8156529130776582, 'Macro ROC value': 0.8156529130776582}\n","Training Epoch Loss after 174 is 243.21016949415207\n","{'Validation Epoch Loss': 61.44488373398781, 'Epoch': 174, 'Micro F1': 0.7558326587195425, 'Patience Count': 0, 'Best Val F1': 0.7558326587195425, 'Best Val Loss': 61.44488373398781, 'Micro ROC value': 0.8159411879782005, 'Macro ROC value': 0.8159411879782005}\n","Training Epoch Loss after 175 is 243.0827750712633\n","{'Validation Epoch Loss': 61.41040427982807, 'Epoch': 175, 'Micro F1': 0.7560063790090301, 'Patience Count': 0, 'Best Val F1': 0.7560063790090301, 'Best Val Loss': 61.41040427982807, 'Micro ROC value': 0.816184850738842, 'Macro ROC value': 0.816184850738842}\n","Training Epoch Loss after 176 is 242.94891856610775\n","{'Validation Epoch Loss': 61.37949214875698, 'Epoch': 176, 'Micro F1': 0.7562113689506252, 'Patience Count': 0, 'Best Val F1': 0.7562113689506252, 'Best Val Loss': 61.37949214875698, 'Micro ROC value': 0.8164928820213095, 'Macro ROC value': 0.8164928820213095}\n","Training Epoch Loss after 177 is 242.82003270089626\n","{'Validation Epoch Loss': 61.34846843779087, 'Epoch': 177, 'Micro F1': 0.7563225499358972, 'Patience Count': 0, 'Best Val F1': 0.7563225499358972, 'Best Val Loss': 61.34846843779087, 'Micro ROC value': 0.8166518015677071, 'Macro ROC value': 0.8166518015677071}\n","Training Epoch Loss after 178 is 242.73720833659172\n","{'Validation Epoch Loss': 61.31686642765999, 'Epoch': 178, 'Micro F1': 0.7564545773559078, 'Patience Count': 0, 'Best Val F1': 0.7564545773559078, 'Best Val Loss': 61.31686642765999, 'Micro ROC value': 0.8167596716773848, 'Macro ROC value': 0.8167596716773848}\n","Training Epoch Loss after 179 is 242.58126117289066\n","{'Validation Epoch Loss': 61.283743649721146, 'Epoch': 179, 'Micro F1': 0.7564024612690614, 'Patience Count': 0, 'Best Val F1': 0.7564545773559078, 'Best Val Loss': 61.283743649721146, 'Micro ROC value': 0.8168380967767122, 'Macro ROC value': 0.8168380967767122}\n","Training Epoch Loss after 180 is 242.4885369539261\n","{'Validation Epoch Loss': 61.25328043103218, 'Epoch': 180, 'Micro F1': 0.7565553351238105, 'Patience Count': 0, 'Best Val F1': 0.7565553351238105, 'Best Val Loss': 61.25328043103218, 'Micro ROC value': 0.8171508751816621, 'Macro ROC value': 0.8171508751816621}\n","Training Epoch Loss after 181 is 242.3345727622509\n","{'Validation Epoch Loss': 61.22258576750755, 'Epoch': 181, 'Micro F1': 0.7566873625438211, 'Patience Count': 0, 'Best Val F1': 0.7566873625438211, 'Best Val Loss': 61.22258576750755, 'Micro ROC value': 0.8172575809479449, 'Macro ROC value': 0.8172575809479449}\n","Training Epoch Loss after 182 is 242.22219587862492\n","{'Validation Epoch Loss': 61.19275414943695, 'Epoch': 182, 'Micro F1': 0.7567707482827748, 'Patience Count': 0, 'Best Val F1': 0.7567707482827748, 'Best Val Loss': 61.19275414943695, 'Micro ROC value': 0.8174292378064743, 'Macro ROC value': 0.8174292378064743}\n","Training Epoch Loss after 183 is 242.0886551141739\n","{'Validation Epoch Loss': 61.16624614596367, 'Epoch': 183, 'Micro F1': 0.7569305709491035, 'Patience Count': 0, 'Best Val F1': 0.7569305709491035, 'Best Val Loss': 61.16624614596367, 'Micro ROC value': 0.8175431014947836, 'Macro ROC value': 0.8175431014947836}\n","Training Epoch Loss after 184 is 242.00870415568352\n","{'Validation Epoch Loss': 61.13708011806011, 'Epoch': 184, 'Micro F1': 0.7571216632675397, 'Patience Count': 0, 'Best Val F1': 0.7571216632675397, 'Best Val Loss': 61.13708011806011, 'Micro ROC value': 0.8178297544388544, 'Macro ROC value': 0.8178297544388544}\n","Training Epoch Loss after 185 is 241.8583274781704\n","{'Validation Epoch Loss': 61.182220831513405, 'Epoch': 185, 'Micro F1': 0.7571911513833347, 'Patience Count': 0, 'Best Val F1': 0.7571911513833347, 'Best Val Loss': 61.13708011806011, 'Micro ROC value': 0.8177944673887436, 'Macro ROC value': 0.8177944673887436}\n","Training Epoch Loss after 186 is 241.73617000877857\n","{'Validation Epoch Loss': 61.10576508939266, 'Epoch': 186, 'Micro F1': 0.7574725782523044, 'Patience Count': 0, 'Best Val F1': 0.7574725782523044, 'Best Val Loss': 61.10576508939266, 'Micro ROC value': 0.8179808958678609, 'Macro ROC value': 0.8179808958678609}\n","Training Epoch Loss after 187 is 241.62398386001587\n","{'Validation Epoch Loss': 61.08312739431858, 'Epoch': 187, 'Micro F1': 0.7578130700197, 'Patience Count': 0, 'Best Val F1': 0.7578130700197, 'Best Val Loss': 61.08312739431858, 'Micro ROC value': 0.8182425847704795, 'Macro ROC value': 0.8182425847704795}\n","Training Epoch Loss after 188 is 241.5002492070198\n","{'Validation Epoch Loss': 61.09456254541874, 'Epoch': 188, 'Micro F1': 0.7578617117007563, 'Patience Count': 0, 'Best Val F1': 0.7578617117007563, 'Best Val Loss': 61.08312739431858, 'Micro ROC value': 0.8180811010007945, 'Macro ROC value': 0.8180811010007945}\n","Training Epoch Loss after 189 is 241.41187013685703\n","{'Validation Epoch Loss': 61.06744708120823, 'Epoch': 189, 'Micro F1': 0.7581083945118287, 'Patience Count': 0, 'Best Val F1': 0.7581083945118287, 'Best Val Loss': 61.06744708120823, 'Micro ROC value': 0.8184122026567027, 'Macro ROC value': 0.8184122026567027}\n","Training Epoch Loss after 190 is 241.27802105247974\n","{'Validation Epoch Loss': 61.042450442910194, 'Epoch': 190, 'Micro F1': 0.7583932957865881, 'Patience Count': 0, 'Best Val F1': 0.7583932957865881, 'Best Val Loss': 61.042450442910194, 'Micro ROC value': 0.818524054727514, 'Macro ROC value': 0.818524054727514}\n","Training Epoch Loss after 191 is 241.15816850960255\n","{'Validation Epoch Loss': 61.01408372819424, 'Epoch': 191, 'Micro F1': 0.7584975279602805, 'Patience Count': 0, 'Best Val F1': 0.7584975279602805, 'Best Val Loss': 61.01408372819424, 'Micro ROC value': 0.8186877312073939, 'Macro ROC value': 0.8186877312073939}\n","Training Epoch Loss after 192 is 241.04504473507404\n","{'Validation Epoch Loss': 60.98670753836632, 'Epoch': 192, 'Micro F1': 0.7587685316118811, 'Patience Count': 0, 'Best Val F1': 0.7587685316118811, 'Best Val Loss': 60.98670753836632, 'Micro ROC value': 0.8187097837983157, 'Macro ROC value': 0.8187097837983157}\n","Training Epoch Loss after 193 is 240.93220302462578\n","{'Validation Epoch Loss': 60.96079282462597, 'Epoch': 193, 'Micro F1': 0.7587859036408299, 'Patience Count': 0, 'Best Val F1': 0.7587859036408299, 'Best Val Loss': 60.96079282462597, 'Micro ROC value': 0.8189605434159658, 'Macro ROC value': 0.8189605434159658}\n","Training Epoch Loss after 194 is 240.8350325524807\n","{'Validation Epoch Loss': 60.93063196539879, 'Epoch': 194, 'Micro F1': 0.7588692893797838, 'Patience Count': 0, 'Best Val F1': 0.7588692893797838, 'Best Val Loss': 60.93063196539879, 'Micro ROC value': 0.8188804303654837, 'Macro ROC value': 0.8188804303654837}\n","Training Epoch Loss after 195 is 240.72573046386242\n","{'Validation Epoch Loss': 60.9073361903429, 'Epoch': 195, 'Micro F1': 0.7590395352634816, 'Patience Count': 0, 'Best Val F1': 0.7590395352634816, 'Best Val Loss': 60.9073361903429, 'Micro ROC value': 0.819262452320219, 'Macro ROC value': 0.819262452320219}\n","Training Epoch Loss after 196 is 240.60317024588585\n","{'Validation Epoch Loss': 60.880976378917694, 'Epoch': 196, 'Micro F1': 0.7593487573787693, 'Patience Count': 0, 'Best Val F1': 0.7593487573787693, 'Best Val Loss': 60.880976378917694, 'Micro ROC value': 0.8192073897978132, 'Macro ROC value': 0.8192073897978132}\n","Training Epoch Loss after 197 is 240.4914792329073\n","{'Validation Epoch Loss': 60.85462234914303, 'Epoch': 197, 'Micro F1': 0.7595954401898415, 'Patience Count': 0, 'Best Val F1': 0.7595954401898415, 'Best Val Loss': 60.85462234914303, 'Micro ROC value': 0.8194623133875647, 'Macro ROC value': 0.8194623133875647}\n","Training Epoch Loss after 198 is 240.37596301734447\n","{'Validation Epoch Loss': 60.82958288490772, 'Epoch': 198, 'Micro F1': 0.7601409218988322, 'Patience Count': 0, 'Best Val F1': 0.7601409218988322, 'Best Val Loss': 60.82958288490772, 'Micro ROC value': 0.8195119981286683, 'Macro ROC value': 0.8195119981286683}\n","Training Epoch Loss after 199 is 240.26384089887142\n","{'Validation Epoch Loss': 60.80488532781601, 'Epoch': 199, 'Micro F1': 0.7604119255504327, 'Patience Count': 0, 'Best Val F1': 0.7604119255504327, 'Best Val Loss': 60.80488532781601, 'Micro ROC value': 0.8196991790824961, 'Macro ROC value': 0.8196991790824961}\n","Training Epoch Loss after 200 is 240.15573646128178\n","{'Validation Epoch Loss': 60.78079354763031, 'Epoch': 200, 'Micro F1': 0.7607141988541409, 'Patience Count': 0, 'Best Val F1': 0.7607141988541409, 'Best Val Loss': 60.78079354763031, 'Micro ROC value': 0.8197647229428036, 'Macro ROC value': 0.8197647229428036}\n","Training Epoch Loss after 201 is 240.04602782428265\n","{'Validation Epoch Loss': 60.75566449761391, 'Epoch': 201, 'Micro F1': 0.7608219054336233, 'Patience Count': 0, 'Best Val F1': 0.7608219054336233, 'Best Val Loss': 60.75566449761391, 'Micro ROC value': 0.8199011216042619, 'Macro ROC value': 0.8199011216042619}\n","Training Epoch Loss after 202 is 239.94136564433575\n","{'Validation Epoch Loss': 60.731645971536636, 'Epoch': 202, 'Micro F1': 0.7609921513173209, 'Patience Count': 0, 'Best Val F1': 0.7609921513173209, 'Best Val Loss': 60.731645971536636, 'Micro ROC value': 0.8199880882182821, 'Macro ROC value': 0.8199880882182821}\n","Training Epoch Loss after 203 is 239.82988813519478\n","{'Validation Epoch Loss': 60.70776189863682, 'Epoch': 203, 'Micro F1': 0.7612145132878649, 'Patience Count': 0, 'Best Val F1': 0.7612145132878649, 'Best Val Loss': 60.70776189863682, 'Micro ROC value': 0.820169128911777, 'Macro ROC value': 0.820169128911777}\n","Training Epoch Loss after 204 is 239.7251726090908\n","{'Validation Epoch Loss': 60.68367700278759, 'Epoch': 204, 'Micro F1': 0.7614646705047269, 'Patience Count': 0, 'Best Val F1': 0.7614646705047269, 'Best Val Loss': 60.68367700278759, 'Micro ROC value': 0.8201904691177647, 'Macro ROC value': 0.8201904691177647}\n","Training Epoch Loss after 205 is 239.62171007692814\n","{'Validation Epoch Loss': 60.65983131527901, 'Epoch': 205, 'Micro F1': 0.7615793258957888, 'Patience Count': 0, 'Best Val F1': 0.7615793258957888, 'Best Val Loss': 60.65983131527901, 'Micro ROC value': 0.8204105368097796, 'Macro ROC value': 0.8204105368097796}\n","Training Epoch Loss after 206 is 239.5169581323862\n","{'Validation Epoch Loss': 60.63706314563751, 'Epoch': 206, 'Micro F1': 0.7617738926200148, 'Patience Count': 0, 'Best Val F1': 0.7617738926200148, 'Best Val Loss': 60.63706314563751, 'Micro ROC value': 0.8204347021729937, 'Macro ROC value': 0.8204347021729937}\n","Training Epoch Loss after 207 is 239.40860740840435\n","{'Validation Epoch Loss': 60.61299839615822, 'Epoch': 207, 'Micro F1': 0.7619163432573943, 'Patience Count': 0, 'Best Val F1': 0.7619163432573943, 'Best Val Loss': 60.61299839615822, 'Micro ROC value': 0.8206521052360427, 'Macro ROC value': 0.8206521052360427}\n","Training Epoch Loss after 208 is 239.31254002451897\n","{'Validation Epoch Loss': 60.588994681835175, 'Epoch': 208, 'Micro F1': 0.7620622683005639, 'Patience Count': 0, 'Best Val F1': 0.7620622683005639, 'Best Val Loss': 60.588994681835175, 'Micro ROC value': 0.8205481905784665, 'Macro ROC value': 0.8205481905784665}\n","Training Epoch Loss after 209 is 239.21444582939148\n","{'Validation Epoch Loss': 60.565483421087265, 'Epoch': 209, 'Micro F1': 0.7622047189379435, 'Patience Count': 0, 'Best Val F1': 0.7622047189379435, 'Best Val Loss': 60.565483421087265, 'Micro ROC value': 0.8208764882215449, 'Macro ROC value': 0.8208764882215449}\n","Training Epoch Loss after 210 is 239.09936733543873\n","{'Validation Epoch Loss': 60.542706057429314, 'Epoch': 210, 'Micro F1': 0.7623158999232156, 'Patience Count': 0, 'Best Val F1': 0.7623158999232156, 'Best Val Loss': 60.542706057429314, 'Micro ROC value': 0.8208705508990911, 'Macro ROC value': 0.8208705508990911}\n","Training Epoch Loss after 211 is 238.99332112073898\n","{'Validation Epoch Loss': 60.52024866640568, 'Epoch': 211, 'Micro F1': 0.7624583505605954, 'Patience Count': 0, 'Best Val F1': 0.7624583505605954, 'Best Val Loss': 60.52024866640568, 'Micro ROC value': 0.821126786794685, 'Macro ROC value': 0.821126786794685}\n","Training Epoch Loss after 212 is 238.89682064950466\n","{'Validation Epoch Loss': 60.4976609647274, 'Epoch': 212, 'Micro F1': 0.7627154565890368, 'Patience Count': 0, 'Best Val F1': 0.7627154565890368, 'Best Val Loss': 60.4976609647274, 'Micro ROC value': 0.82100834255341, 'Macro ROC value': 0.82100834255341}\n","Training Epoch Loss after 213 is 238.79331375658512\n","{'Validation Epoch Loss': 60.477983981370926, 'Epoch': 213, 'Micro F1': 0.7626529172848212, 'Patience Count': 0, 'Best Val F1': 0.7627154565890368, 'Best Val Loss': 60.477983981370926, 'Micro ROC value': 0.8213538422869515, 'Macro ROC value': 0.8213538422869515}\n","Training Epoch Loss after 214 is 238.70330800116062\n","{'Validation Epoch Loss': 60.45868682861328, 'Epoch': 214, 'Micro F1': 0.7629447673711603, 'Patience Count': 0, 'Best Val F1': 0.7629447673711603, 'Best Val Loss': 60.45868682861328, 'Micro ROC value': 0.8210449032211584, 'Macro ROC value': 0.8210449032211584}\n","Training Epoch Loss after 215 is 238.6176039725542\n","{'Validation Epoch Loss': 60.446372985839844, 'Epoch': 215, 'Micro F1': 0.7626946101542984, 'Patience Count': 0, 'Best Val F1': 0.7629447673711603, 'Best Val Loss': 60.446372985839844, 'Micro ROC value': 0.8214219846123869, 'Macro ROC value': 0.8214219846123869}\n","Training Epoch Loss after 216 is 238.49272461235523\n","{'Validation Epoch Loss': 60.42560005187988, 'Epoch': 216, 'Micro F1': 0.7629239209364218, 'Patience Count': 0, 'Best Val F1': 0.7629447673711603, 'Best Val Loss': 60.42560005187988, 'Micro ROC value': 0.821443242826445, 'Macro ROC value': 0.821443242826445}\n","Training Epoch Loss after 217 is 238.3977599143982\n","{'Validation Epoch Loss': 60.40529514849186, 'Epoch': 217, 'Micro F1': 0.7630142554869552, 'Patience Count': 0, 'Best Val F1': 0.7630142554869552, 'Best Val Loss': 60.40529514849186, 'Micro ROC value': 0.8214669580919052, 'Macro ROC value': 0.8214669580919052}\n","Training Epoch Loss after 218 is 238.3027860969305\n","{'Validation Epoch Loss': 60.3897080719471, 'Epoch': 218, 'Micro F1': 0.7630073066753759, 'Patience Count': 0, 'Best Val F1': 0.7630142554869552, 'Best Val Loss': 60.3897080719471, 'Micro ROC value': 0.8215442201285841, 'Macro ROC value': 0.8215442201285841}\n","Training Epoch Loss after 219 is 238.2056491225958\n","{'Validation Epoch Loss': 60.37273354828358, 'Epoch': 219, 'Micro F1': 0.7629795114290578, 'Patience Count': 0, 'Best Val F1': 0.7630142554869552, 'Best Val Loss': 60.37273354828358, 'Micro ROC value': 0.8219139988492867, 'Macro ROC value': 0.8219139988492867}\n","Training Epoch Loss after 220 is 238.11321178078651\n","{'Validation Epoch Loss': 60.35019092261791, 'Epoch': 220, 'Micro F1': 0.7633443240369816, 'Patience Count': 0, 'Best Val F1': 0.7633443240369816, 'Best Val Loss': 60.35019092261791, 'Micro ROC value': 0.8215836237390173, 'Macro ROC value': 0.8215836237390173}\n","Training Epoch Loss after 221 is 238.0497289597988\n","{'Validation Epoch Loss': 60.341000482439995, 'Epoch': 221, 'Micro F1': 0.7632192454285506, 'Patience Count': 0, 'Best Val F1': 0.7633443240369816, 'Best Val Loss': 60.341000482439995, 'Micro ROC value': 0.8220010134792112, 'Macro ROC value': 0.8220010134792112}\n","Training Epoch Loss after 222 is 237.92974427342415\n","{'Validation Epoch Loss': 60.317067950963974, 'Epoch': 222, 'Micro F1': 0.7634937234859408, 'Patience Count': 0, 'Best Val F1': 0.7634937234859408, 'Best Val Loss': 60.317067950963974, 'Micro ROC value': 0.8217380708951008, 'Macro ROC value': 0.8217380708951008}\n","Training Epoch Loss after 223 is 237.84289853274822\n","{'Validation Epoch Loss': 60.29965165257454, 'Epoch': 223, 'Micro F1': 0.7634971978917305, 'Patience Count': 0, 'Best Val F1': 0.7634971978917305, 'Best Val Loss': 60.29965165257454, 'Micro ROC value': 0.8222260133977992, 'Macro ROC value': 0.8222260133977992}\n","Training Epoch Loss after 224 is 237.7425035983324\n","{'Validation Epoch Loss': 60.279009222984314, 'Epoch': 224, 'Micro F1': 0.7637334574854335, 'Patience Count': 0, 'Best Val F1': 0.7637334574854335, 'Best Val Loss': 60.279009222984314, 'Micro ROC value': 0.822004390903917, 'Macro ROC value': 0.822004390903917}\n","Training Epoch Loss after 225 is 237.67066198587418\n","{'Validation Epoch Loss': 60.28662221133709, 'Epoch': 225, 'Micro F1': 0.7636604949638488, 'Patience Count': 1, 'Best Val F1': 0.7637334574854335, 'Best Val Loss': 60.279009222984314, 'Micro ROC value': 0.8221518816984463, 'Macro ROC value': 0.8221518816984463}\n","Training Epoch Loss after 226 is 237.58867898583412\n","{'Validation Epoch Loss': 60.26878464221954, 'Epoch': 226, 'Micro F1': 0.7638342152533364, 'Patience Count': 0, 'Best Val F1': 0.7638342152533364, 'Best Val Loss': 60.26878464221954, 'Micro ROC value': 0.8221732109335127, 'Macro ROC value': 0.8221732109335127}\n","Training Epoch Loss after 227 is 237.50151197612286\n","{'Validation Epoch Loss': 60.23912185430527, 'Epoch': 227, 'Micro F1': 0.7642893624117936, 'Patience Count': 0, 'Best Val F1': 0.7642893624117936, 'Best Val Loss': 60.23912185430527, 'Micro ROC value': 0.8220933431580334, 'Macro ROC value': 0.8220933431580334}\n","Training Epoch Loss after 228 is 237.422036126256\n","{'Validation Epoch Loss': 60.2098735421896, 'Epoch': 228, 'Micro F1': 0.7642441951365267, 'Patience Count': 0, 'Best Val F1': 0.7642893624117936, 'Best Val Loss': 60.2098735421896, 'Micro ROC value': 0.8224562036495914, 'Macro ROC value': 0.8224562036495914}\n","Training Epoch Loss after 229 is 237.27805542945862\n","{'Validation Epoch Loss': 60.189891532063484, 'Epoch': 229, 'Micro F1': 0.7641886046438908, 'Patience Count': 0, 'Best Val F1': 0.7642893624117936, 'Best Val Loss': 60.189891532063484, 'Micro ROC value': 0.8229183157463649, 'Macro ROC value': 0.8229183157463649}\n","Training Epoch Loss after 230 is 237.19470150768757\n","{'Validation Epoch Loss': 60.16985933482647, 'Epoch': 230, 'Micro F1': 0.7645464684402351, 'Patience Count': 0, 'Best Val F1': 0.7645464684402351, 'Best Val Loss': 60.16985933482647, 'Micro ROC value': 0.8225217265346572, 'Macro ROC value': 0.8225217265346572}\n","Training Epoch Loss after 231 is 237.12416909635067\n","{'Validation Epoch Loss': 60.15665578842163, 'Epoch': 231, 'Micro F1': 0.7643484273102192, 'Patience Count': 0, 'Best Val F1': 0.7645464684402351, 'Best Val Loss': 60.15665578842163, 'Micro ROC value': 0.8228989043443351, 'Macro ROC value': 0.8228989043443351}\n","Training Epoch Loss after 232 is 237.00418077409267\n","{'Validation Epoch Loss': 60.13393676280975, 'Epoch': 232, 'Micro F1': 0.7647757792223584, 'Patience Count': 0, 'Best Val F1': 0.7647757792223584, 'Best Val Loss': 60.13393676280975, 'Micro ROC value': 0.8226631575383867, 'Macro ROC value': 0.8226631575383867}\n","Training Epoch Loss after 233 is 236.99995420873165\n","{'Validation Epoch Loss': 60.19159823656082, 'Epoch': 233, 'Micro F1': 0.7635423651669974, 'Patience Count': 1, 'Best Val F1': 0.7647757792223584, 'Best Val Loss': 60.13393676280975, 'Micro ROC value': 0.8228719740189716, 'Macro ROC value': 0.8228719740189716}\n","Training Epoch Loss after 234 is 237.13152128458023\n","{'Validation Epoch Loss': 60.169753804802895, 'Epoch': 234, 'Micro F1': 0.7644040178028552, 'Patience Count': 2, 'Best Val F1': 0.7647757792223584, 'Best Val Loss': 60.13393676280975, 'Micro ROC value': 0.8220695971063314, 'Macro ROC value': 0.8220695971063314}\n","Training Epoch Loss after 235 is 236.90036864578724\n","{'Validation Epoch Loss': 60.13663300871849, 'Epoch': 235, 'Micro F1': 0.7643623249333784, 'Patience Count': 3, 'Best Val F1': 0.7647757792223584, 'Best Val Loss': 60.13393676280975, 'Micro ROC value': 0.8226423531918263, 'Macro ROC value': 0.8226423531918263}\n","Training Epoch Loss after 236 is 236.71970649063587\n","{'Validation Epoch Loss': 60.105595633387566, 'Epoch': 236, 'Micro F1': 0.7646333285849788, 'Patience Count': 0, 'Best Val F1': 0.7647757792223584, 'Best Val Loss': 60.105595633387566, 'Micro ROC value': 0.8228407639468724, 'Macro ROC value': 0.8228407639468724}\n","Training Epoch Loss after 237 is 236.62524831295013\n","{'Validation Epoch Loss': 60.077621743083, 'Epoch': 237, 'Micro F1': 0.764727137541302, 'Patience Count': 0, 'Best Val F1': 0.7647757792223584, 'Best Val Loss': 60.077621743083, 'Micro ROC value': 0.8231778818965358, 'Macro ROC value': 0.8231778818965358}\n","Training Epoch Loss after 238 is 236.51056551933289\n","{'Validation Epoch Loss': 60.049707755446434, 'Epoch': 238, 'Micro F1': 0.765088475743436, 'Patience Count': 0, 'Best Val F1': 0.765088475743436, 'Best Val Loss': 60.049707755446434, 'Micro ROC value': 0.8230859062353286, 'Macro ROC value': 0.8230859062353286}\n","Training Epoch Loss after 239 is 236.43375696241856\n","{'Validation Epoch Loss': 60.023879170417786, 'Epoch': 239, 'Micro F1': 0.7649564483234255, 'Patience Count': 0, 'Best Val F1': 0.765088475743436, 'Best Val Loss': 60.023879170417786, 'Micro ROC value': 0.8234235638141632, 'Macro ROC value': 0.8234235638141632}\n","Training Epoch Loss after 240 is 236.3008263707161\n","{'Validation Epoch Loss': 60.002426877617836, 'Epoch': 240, 'Micro F1': 0.7650189876276409, 'Patience Count': 0, 'Best Val F1': 0.765088475743436, 'Best Val Loss': 60.002426877617836, 'Micro ROC value': 0.8236204148135117, 'Macro ROC value': 0.8236204148135117}\n","Training Epoch Loss after 241 is 236.2056580632925\n","{'Validation Epoch Loss': 59.97890613973141, 'Epoch': 241, 'Micro F1': 0.765227451975026, 'Patience Count': 0, 'Best Val F1': 0.765227451975026, 'Best Val Loss': 59.97890613973141, 'Micro ROC value': 0.8235250611476381, 'Macro ROC value': 0.8235250611476381}\n","Training Epoch Loss after 242 is 236.1142807751894\n","{'Validation Epoch Loss': 59.95972861349583, 'Epoch': 242, 'Micro F1': 0.7651614382650207, 'Patience Count': 0, 'Best Val F1': 0.765227451975026, 'Best Val Loss': 59.95972861349583, 'Micro ROC value': 0.8238424076364008, 'Macro ROC value': 0.8238424076364008}\n","Training Epoch Loss after 243 is 236.04239377379417\n","{'Validation Epoch Loss': 59.95236738026142, 'Epoch': 243, 'Micro F1': 0.7653768514239853, 'Patience Count': 0, 'Best Val F1': 0.7653768514239853, 'Best Val Loss': 59.95236738026142, 'Micro ROC value': 0.8236013352456039, 'Macro ROC value': 0.8236013352456039}\n","Training Epoch Loss after 244 is 235.93754433095455\n","{'Validation Epoch Loss': 59.928480833768845, 'Epoch': 244, 'Micro F1': 0.7654289675108314, 'Patience Count': 0, 'Best Val F1': 0.7654289675108314, 'Best Val Loss': 59.928480833768845, 'Micro ROC value': 0.8236184476113294, 'Macro ROC value': 0.8236184476113294}\n","Training Epoch Loss after 245 is 235.86742383241653\n","{'Validation Epoch Loss': 59.93334065377712, 'Epoch': 245, 'Micro F1': 0.7652239775692362, 'Patience Count': 1, 'Best Val F1': 0.7654289675108314, 'Best Val Loss': 59.928480833768845, 'Micro ROC value': 0.8236714884635867, 'Macro ROC value': 0.8236714884635867}\n","Training Epoch Loss after 246 is 235.77783715724945\n","{'Validation Epoch Loss': 59.920705646276474, 'Epoch': 246, 'Micro F1': 0.7652934656850311, 'Patience Count': 0, 'Best Val F1': 0.7654289675108314, 'Best Val Loss': 59.920705646276474, 'Micro ROC value': 0.8239090135012226, 'Macro ROC value': 0.8239090135012226}\n","Training Epoch Loss after 247 is 235.69528199732304\n","{'Validation Epoch Loss': 59.889824748039246, 'Epoch': 247, 'Micro F1': 0.7655957389887393, 'Patience Count': 0, 'Best Val F1': 0.7655957389887393, 'Best Val Loss': 59.889824748039246, 'Micro ROC value': 0.8235956060081795, 'Macro ROC value': 0.8235956060081795}\n","Training Epoch Loss after 248 is 235.62456603348255\n","{'Validation Epoch Loss': 59.863864839076996, 'Epoch': 248, 'Micro F1': 0.7655783669597906, 'Patience Count': 0, 'Best Val F1': 0.7655957389887393, 'Best Val Loss': 59.863864839076996, 'Micro ROC value': 0.8239389695535194, 'Macro ROC value': 0.8239389695535194}\n","Training Epoch Loss after 249 is 235.54621855914593\n","{'Validation Epoch Loss': 59.89558482170105, 'Epoch': 249, 'Micro F1': 0.7651127965839642, 'Patience Count': 1, 'Best Val F1': 0.7655957389887393, 'Best Val Loss': 59.863864839076996, 'Micro ROC value': 0.8239135001005714, 'Macro ROC value': 0.8239135001005714}\n","Training Epoch Loss after 250 is 235.53606389462948\n","{'Validation Epoch Loss': 59.87595136463642, 'Epoch': 250, 'Micro F1': 0.7653421073660879, 'Patience Count': 2, 'Best Val F1': 0.7655957389887393, 'Best Val Loss': 59.863864839076996, 'Micro ROC value': 0.8236766771777341, 'Macro ROC value': 0.8236766771777341}\n","Training Epoch Loss after 251 is 235.3647509664297\n","{'Validation Epoch Loss': 59.846424862742424, 'Epoch': 251, 'Micro F1': 0.7654324419166212, 'Patience Count': 0, 'Best Val F1': 0.7655957389887393, 'Best Val Loss': 59.846424862742424, 'Micro ROC value': 0.8239013301107294, 'Macro ROC value': 0.8239013301107294}\n","Training Epoch Loss after 252 is 235.27962075173855\n","{'Validation Epoch Loss': 59.82196933031082, 'Epoch': 252, 'Micro F1': 0.7655297252787342, 'Patience Count': 0, 'Best Val F1': 0.7655957389887393, 'Best Val Loss': 59.82196933031082, 'Micro ROC value': 0.8242259921741413, 'Macro ROC value': 0.8242259921741413}\n","Training Epoch Loss after 253 is 235.17136715352535\n","{'Validation Epoch Loss': 59.794838801026344, 'Epoch': 253, 'Micro F1': 0.7657103943798012, 'Patience Count': 0, 'Best Val F1': 0.7657103943798012, 'Best Val Loss': 59.794838801026344, 'Micro ROC value': 0.8241192397451955, 'Macro ROC value': 0.8241192397451955}\n","Training Epoch Loss after 254 is 235.09099201858044\n","{'Validation Epoch Loss': 59.77028629183769, 'Epoch': 254, 'Micro F1': 0.7657103943798012, 'Patience Count': 0, 'Best Val F1': 0.7657103943798012, 'Best Val Loss': 59.77028629183769, 'Micro ROC value': 0.8244199824211815, 'Macro ROC value': 0.8244199824211815}\n","Training Epoch Loss after 255 is 234.97209200263023\n","{'Validation Epoch Loss': 59.7557914853096, 'Epoch': 255, 'Micro F1': 0.7657486128434885, 'Patience Count': 0, 'Best Val F1': 0.7657486128434885, 'Best Val Loss': 59.7557914853096, 'Micro ROC value': 0.8243595516143285, 'Macro ROC value': 0.8243595516143285}\n","Training Epoch Loss after 256 is 234.8903931081295\n","{'Validation Epoch Loss': 59.741021513938904, 'Epoch': 256, 'Micro F1': 0.7657764080898064, 'Patience Count': 0, 'Best Val F1': 0.7657764080898064, 'Best Val Loss': 59.741021513938904, 'Micro ROC value': 0.8246388829666589, 'Macro ROC value': 0.8246388829666589}\n","Training Epoch Loss after 257 is 234.82935048639774\n","{'Validation Epoch Loss': 59.74417670071125, 'Epoch': 257, 'Micro F1': 0.7659119099156066, 'Patience Count': 0, 'Best Val F1': 0.7659119099156066, 'Best Val Loss': 59.741021513938904, 'Micro ROC value': 0.8244147195687379, 'Macro ROC value': 0.8244147195687379}\n","Training Epoch Loss after 258 is 234.73771357536316\n","{'Validation Epoch Loss': 59.71914039552212, 'Epoch': 258, 'Micro F1': 0.765852845017181, 'Patience Count': 0, 'Best Val F1': 0.7659119099156066, 'Best Val Loss': 59.71914039552212, 'Micro ROC value': 0.8242642830335076, 'Macro ROC value': 0.8242642830335076}\n","Training Epoch Loss after 259 is 234.65635207295418\n","{'Validation Epoch Loss': 59.692600920796394, 'Epoch': 259, 'Micro F1': 0.7658563194229706, 'Patience Count': 0, 'Best Val F1': 0.7659119099156066, 'Best Val Loss': 59.692600920796394, 'Micro ROC value': 0.8246388836191145, 'Macro ROC value': 0.8246388836191145}\n","Training Epoch Loss after 260 is 234.58474622666836\n","{'Validation Epoch Loss': 59.71320129930973, 'Epoch': 260, 'Micro F1': 0.7657451384376986, 'Patience Count': 1, 'Best Val F1': 0.7659119099156066, 'Best Val Loss': 59.692600920796394, 'Micro ROC value': 0.8245590643186751, 'Macro ROC value': 0.8245590643186751}\n","Training Epoch Loss after 261 is 234.50578112900257\n","{'Validation Epoch Loss': 59.690498664975166, 'Epoch': 261, 'Micro F1': 0.7657798824955961, 'Patience Count': 0, 'Best Val F1': 0.7659119099156066, 'Best Val Loss': 59.690498664975166, 'Micro ROC value': 0.8243346806323874, 'Macro ROC value': 0.8243346806323874}\n","Training Epoch Loss after 262 is 234.43686164915562\n","{'Validation Epoch Loss': 59.661690801382065, 'Epoch': 262, 'Micro F1': 0.7659327563503452, 'Patience Count': 0, 'Best Val F1': 0.7659327563503452, 'Best Val Loss': 59.661690801382065, 'Micro ROC value': 0.8246860594748375, 'Macro ROC value': 0.8246860594748375}\n","Training Epoch Loss after 263 is 234.2931762933731\n","{'Validation Epoch Loss': 59.638038262724876, 'Epoch': 263, 'Micro F1': 0.7660300397124581, 'Patience Count': 0, 'Best Val F1': 0.7660300397124581, 'Best Val Loss': 59.638038262724876, 'Micro ROC value': 0.8248318618349121, 'Macro ROC value': 0.8248318618349121}\n","Training Epoch Loss after 264 is 234.19539652764797\n","{'Validation Epoch Loss': 59.61414614319801, 'Epoch': 264, 'Micro F1': 0.7660647837703557, 'Patience Count': 0, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.61414614319801, 'Micro ROC value': 0.824976820569802, 'Macro ROC value': 0.824976820569802}\n","Training Epoch Loss after 265 is 234.15997701883316\n","{'Validation Epoch Loss': 59.63026222586632, 'Epoch': 265, 'Micro F1': 0.7658076777419142, 'Patience Count': 1, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.61414614319801, 'Micro ROC value': 0.8248353928283509, 'Macro ROC value': 0.8248353928283509}\n","Training Epoch Loss after 266 is 234.0633135586977\n","{'Validation Epoch Loss': 59.60510301589966, 'Epoch': 266, 'Micro F1': 0.765991821248771, 'Patience Count': 0, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.60510301589966, 'Micro ROC value': 0.8245811854899376, 'Macro ROC value': 0.8245811854899376}\n","Training Epoch Loss after 267 is 234.01503683626652\n","{'Validation Epoch Loss': 59.57521252334118, 'Epoch': 267, 'Micro F1': 0.765922333132976, 'Patience Count': 0, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.57521252334118, 'Micro ROC value': 0.824921269817233, 'Macro ROC value': 0.824921269817233}\n","Training Epoch Loss after 268 is 233.85656195878983\n","{'Validation Epoch Loss': 59.555402263998985, 'Epoch': 268, 'Micro F1': 0.7659431795677144, 'Patience Count': 0, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.555402263998985, 'Micro ROC value': 0.8252291202969843, 'Macro ROC value': 0.8252291202969843}\n","Training Epoch Loss after 269 is 233.7902633845806\n","{'Validation Epoch Loss': 59.545073971152306, 'Epoch': 269, 'Micro F1': 0.7659431795677144, 'Patience Count': 0, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.545073971152306, 'Micro ROC value': 0.8250149028608386, 'Macro ROC value': 0.8250149028608386}\n","Training Epoch Loss after 270 is 233.68683542311192\n","{'Validation Epoch Loss': 59.51871934533119, 'Epoch': 270, 'Micro F1': 0.7658771658577092, 'Patience Count': 0, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.51871934533119, 'Micro ROC value': 0.8250468228772041, 'Macro ROC value': 0.8250468228772041}\n","Training Epoch Loss after 271 is 233.67996203899384\n","{'Validation Epoch Loss': 59.578037932515144, 'Epoch': 271, 'Micro F1': 0.765505404438206, 'Patience Count': 1, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.51871934533119, 'Micro ROC value': 0.8251599065185098, 'Macro ROC value': 0.8251599065185098}\n","Training Epoch Loss after 272 is 233.6873405277729\n","{'Validation Epoch Loss': 59.550506576895714, 'Epoch': 272, 'Micro F1': 0.7653525305834569, 'Patience Count': 2, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.51871934533119, 'Micro ROC value': 0.8244948474082152, 'Macro ROC value': 0.8244948474082152}\n","Training Epoch Loss after 273 is 233.54864697158337\n","{'Validation Epoch Loss': 59.51958040893078, 'Epoch': 273, 'Micro F1': 0.7654254931050417, 'Patience Count': 3, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.51871934533119, 'Micro ROC value': 0.8250046306470622, 'Macro ROC value': 0.8250046306470622}\n","Training Epoch Loss after 274 is 233.3976599574089\n","{'Validation Epoch Loss': 59.48713509738445, 'Epoch': 274, 'Micro F1': 0.7655818413655805, 'Patience Count': 0, 'Best Val F1': 0.7660647837703557, 'Best Val Loss': 59.48713509738445, 'Micro ROC value': 0.82506699207025, 'Macro ROC value': 0.82506699207025}\n","Epoch   275: reducing learning rate of group 0 to 1.0000e-05.\n","Training Epoch Loss after 275 is 232.58165645599365\n","{'Validation Epoch Loss': 59.39365682005882, 'Epoch': 275, 'Micro F1': 0.7677846146362818, 'Patience Count': 0, 'Best Val F1': 0.7677846146362818, 'Best Val Loss': 59.39365682005882, 'Micro ROC value': 0.8267037799949786, 'Macro ROC value': 0.8267037799949786}\n","Training Epoch Loss after 276 is 232.53852938115597\n","{'Validation Epoch Loss': 59.390496611595154, 'Epoch': 276, 'Micro F1': 0.7677324985494356, 'Patience Count': 0, 'Best Val F1': 0.7677846146362818, 'Best Val Loss': 59.390496611595154, 'Micro ROC value': 0.8272026816747813, 'Macro ROC value': 0.8272026816747813}\n","Training Epoch Loss after 277 is 232.5171012431383\n","{'Validation Epoch Loss': 59.388184055686, 'Epoch': 277, 'Micro F1': 0.7677220753320664, 'Patience Count': 0, 'Best Val F1': 0.7677846146362818, 'Best Val Loss': 59.388184055686, 'Micro ROC value': 0.8275035059560566, 'Macro ROC value': 0.8275035059560566}\n","Training Epoch Loss after 278 is 232.5011429488659\n","{'Validation Epoch Loss': 59.38594380021095, 'Epoch': 278, 'Micro F1': 0.7678749491868153, 'Patience Count': 0, 'Best Val F1': 0.7678749491868153, 'Best Val Loss': 59.38594380021095, 'Micro ROC value': 0.8276979595432845, 'Macro ROC value': 0.8276979595432845}\n","Training Epoch Loss after 279 is 232.48726196587086\n","{'Validation Epoch Loss': 59.38363300263882, 'Epoch': 279, 'Micro F1': 0.7678784235926052, 'Patience Count': 0, 'Best Val F1': 0.7678784235926052, 'Best Val Loss': 59.38363300263882, 'Micro ROC value': 0.8278290984454223, 'Macro ROC value': 0.8278290984454223}\n","Training Epoch Loss after 280 is 232.47424879670143\n","{'Validation Epoch Loss': 59.38118031620979, 'Epoch': 280, 'Micro F1': 0.7679409628968206, 'Patience Count': 0, 'Best Val F1': 0.7679409628968206, 'Best Val Loss': 59.38118031620979, 'Micro ROC value': 0.827923422777895, 'Macro ROC value': 0.827923422777895}\n","Training Epoch Loss after 281 is 232.46169304847717\n","{'Validation Epoch Loss': 59.378568947315216, 'Epoch': 281, 'Micro F1': 0.7680278230415644, 'Patience Count': 0, 'Best Val F1': 0.7680278230415644, 'Best Val Loss': 59.378568947315216, 'Micro ROC value': 0.8279954856853009, 'Macro ROC value': 0.8279954856853009}\n","Training Epoch Loss after 282 is 232.44948515295982\n","{'Validation Epoch Loss': 59.375912085175514, 'Epoch': 282, 'Micro F1': 0.7680903623457798, 'Patience Count': 0, 'Best Val F1': 0.7680903623457798, 'Best Val Loss': 59.375912085175514, 'Micro ROC value': 0.8280535513403415, 'Macro ROC value': 0.8280535513403415}\n","Training Epoch Loss after 283 is 232.437466442585\n","{'Validation Epoch Loss': 59.37310642004013, 'Epoch': 283, 'Micro F1': 0.7681494272442055, 'Patience Count': 0, 'Best Val F1': 0.7681494272442055, 'Best Val Loss': 59.37310642004013, 'Micro ROC value': 0.8281018959858242, 'Macro ROC value': 0.8281018959858242}\n","Training Epoch Loss after 284 is 232.4254701435566\n","{'Validation Epoch Loss': 59.37027631700039, 'Epoch': 284, 'Micro F1': 0.76822586417158, 'Patience Count': 0, 'Best Val F1': 0.76822586417158, 'Best Val Loss': 59.37027631700039, 'Micro ROC value': 0.8281438369238722, 'Macro ROC value': 0.8281438369238722}\n","Training Epoch Loss after 285 is 232.413538351655\n","{'Validation Epoch Loss': 59.36731894314289, 'Epoch': 285, 'Micro F1': 0.768281454664216, 'Patience Count': 0, 'Best Val F1': 0.768281454664216, 'Best Val Loss': 59.36731894314289, 'Micro ROC value': 0.8281804033912266, 'Macro ROC value': 0.8281804033912266}\n","Training Epoch Loss after 286 is 232.40169589221478\n","{'Validation Epoch Loss': 59.364399284124374, 'Epoch': 286, 'Micro F1': 0.768295352287375, 'Patience Count': 0, 'Best Val F1': 0.768295352287375, 'Best Val Loss': 59.364399284124374, 'Micro ROC value': 0.8282127862403142, 'Macro ROC value': 0.8282127862403142}\n","Training Epoch Loss after 287 is 232.39003762602806\n","{'Validation Epoch Loss': 59.361484318971634, 'Epoch': 287, 'Micro F1': 0.7683370451568521, 'Patience Count': 0, 'Best Val F1': 0.7683370451568521, 'Best Val Loss': 59.361484318971634, 'Micro ROC value': 0.828243175184867, 'Macro ROC value': 0.828243175184867}\n","Training Epoch Loss after 288 is 232.3785301744938\n","{'Validation Epoch Loss': 59.35853685438633, 'Epoch': 288, 'Micro F1': 0.76836831480896, 'Patience Count': 0, 'Best Val F1': 0.76836831480896, 'Best Val Loss': 59.35853685438633, 'Micro ROC value': 0.8282707623156076, 'Macro ROC value': 0.8282707623156076}\n","Training Epoch Loss after 289 is 232.36729185283184\n","{'Validation Epoch Loss': 59.35564748942852, 'Epoch': 289, 'Micro F1': 0.7684065332726471, 'Patience Count': 0, 'Best Val F1': 0.7684065332726471, 'Best Val Loss': 59.35564748942852, 'Micro ROC value': 0.8282966860226938, 'Macro ROC value': 0.8282966860226938}\n","Training Epoch Loss after 290 is 232.35626700520515\n","{'Validation Epoch Loss': 59.35276548564434, 'Epoch': 290, 'Micro F1': 0.768392635649488, 'Patience Count': 0, 'Best Val F1': 0.7684065332726471, 'Best Val Loss': 59.35276548564434, 'Micro ROC value': 0.8283217526688416, 'Macro ROC value': 0.8283217526688416}\n","Training Epoch Loss after 291 is 232.34514428675175\n","{'Validation Epoch Loss': 59.34993430972099, 'Epoch': 291, 'Micro F1': 0.768392635649488, 'Patience Count': 0, 'Best Val F1': 0.7684065332726471, 'Best Val Loss': 59.34993430972099, 'Micro ROC value': 0.8283453014614454, 'Macro ROC value': 0.8283453014614454}\n","Training Epoch Loss after 292 is 232.3342388868332\n","{'Validation Epoch Loss': 59.34703692793846, 'Epoch': 292, 'Micro F1': 0.7684204308958061, 'Patience Count': 0, 'Best Val F1': 0.7684204308958061, 'Best Val Loss': 59.34703692793846, 'Micro ROC value': 0.8283686377709849, 'Macro ROC value': 0.8283686377709849}\n","Training Epoch Loss after 293 is 232.32331950962543\n","{'Validation Epoch Loss': 59.3442302942276, 'Epoch': 293, 'Micro F1': 0.7684447517363342, 'Patience Count': 0, 'Best Val F1': 0.7684447517363342, 'Best Val Loss': 59.3442302942276, 'Micro ROC value': 0.828390322811878, 'Macro ROC value': 0.828390322811878}\n","Training Epoch Loss after 294 is 232.31249025464058\n","{'Validation Epoch Loss': 59.341469407081604, 'Epoch': 294, 'Micro F1': 0.768448226142124, 'Patience Count': 0, 'Best Val F1': 0.768448226142124, 'Best Val Loss': 59.341469407081604, 'Micro ROC value': 0.8284106780997805, 'Macro ROC value': 0.8284106780997805}\n","Training Epoch Loss after 295 is 232.30159279704094\n","{'Validation Epoch Loss': 59.33861726522446, 'Epoch': 295, 'Micro F1': 0.768448226142124, 'Patience Count': 0, 'Best Val F1': 0.768448226142124, 'Best Val Loss': 59.33861726522446, 'Micro ROC value': 0.8284300813098668, 'Macro ROC value': 0.8284300813098668}\n","Training Epoch Loss after 296 is 232.29087030887604\n","{'Validation Epoch Loss': 59.33588509261608, 'Epoch': 296, 'Micro F1': 0.7684586493594934, 'Patience Count': 0, 'Best Val F1': 0.7684586493594934, 'Best Val Loss': 59.33588509261608, 'Micro ROC value': 0.8284491851636246, 'Macro ROC value': 0.8284491851636246}\n","Training Epoch Loss after 297 is 232.2800273001194\n","{'Validation Epoch Loss': 59.33307448029518, 'Epoch': 297, 'Micro F1': 0.7684725469826523, 'Patience Count': 0, 'Best Val F1': 0.7684725469826523, 'Best Val Loss': 59.33307448029518, 'Micro ROC value': 0.8284676285630869, 'Macro ROC value': 0.8284676285630869}\n","Training Epoch Loss after 298 is 232.26935125887394\n","{'Validation Epoch Loss': 59.33033986389637, 'Epoch': 298, 'Micro F1': 0.7684829702000215, 'Patience Count': 0, 'Best Val F1': 0.7684829702000215, 'Best Val Loss': 59.33033986389637, 'Micro ROC value': 0.8284850641843504, 'Macro ROC value': 0.8284850641843504}\n","Training Epoch Loss after 299 is 232.2586648464203\n","{'Validation Epoch Loss': 59.32762759923935, 'Epoch': 299, 'Micro F1': 0.7685038166347601, 'Patience Count': 0, 'Best Val F1': 0.7685038166347601, 'Best Val Loss': 59.32762759923935, 'Micro ROC value': 0.8285022120726626, 'Macro ROC value': 0.8285022120726626}\n","Training Epoch Loss after 300 is 232.2479899674654\n","{'Validation Epoch Loss': 59.32493470609188, 'Epoch': 300, 'Micro F1': 0.768517714257919, 'Patience Count': 0, 'Best Val F1': 0.768517714257919, 'Best Val Loss': 59.32493470609188, 'Micro ROC value': 0.8285183900977002, 'Macro ROC value': 0.8285183900977002}\n","Training Epoch Loss after 301 is 232.23736235499382\n","{'Validation Epoch Loss': 59.322250589728355, 'Epoch': 301, 'Micro F1': 0.7685211886637088, 'Patience Count': 0, 'Best Val F1': 0.7685211886637088, 'Best Val Loss': 59.322250589728355, 'Micro ROC value': 0.8285343815445805, 'Macro ROC value': 0.8285343815445805}\n","Training Epoch Loss after 302 is 232.2267525345087\n","{'Validation Epoch Loss': 59.31962835788727, 'Epoch': 302, 'Micro F1': 0.7685281374752884, 'Patience Count': 0, 'Best Val F1': 0.7685281374752884, 'Best Val Loss': 59.31962835788727, 'Micro ROC value': 0.8285497766228113, 'Macro ROC value': 0.8285497766228113}\n","Training Epoch Loss after 303 is 232.21627919375896\n","{'Validation Epoch Loss': 59.31697891652584, 'Epoch': 303, 'Micro F1': 0.7685420350984472, 'Patience Count': 0, 'Best Val F1': 0.7685420350984472, 'Best Val Loss': 59.31697891652584, 'Micro ROC value': 0.8285652732424765, 'Macro ROC value': 0.8285652732424765}\n","Training Epoch Loss after 304 is 232.2058071643114\n","{'Validation Epoch Loss': 59.314408659935, 'Epoch': 304, 'Micro F1': 0.7685524583158165, 'Patience Count': 0, 'Best Val F1': 0.7685524583158165, 'Best Val Loss': 59.314408659935, 'Micro ROC value': 0.828579702686312, 'Macro ROC value': 0.828579702686312}\n","Training Epoch Loss after 305 is 232.1954664438963\n","{'Validation Epoch Loss': 59.31190663576126, 'Epoch': 305, 'Micro F1': 0.7685455095042371, 'Patience Count': 0, 'Best Val F1': 0.7685524583158165, 'Best Val Loss': 59.31190663576126, 'Micro ROC value': 0.8285933392756806, 'Macro ROC value': 0.8285933392756806}\n","Training Epoch Loss after 306 is 232.18519912660122\n","{'Validation Epoch Loss': 59.30949664115906, 'Epoch': 306, 'Micro F1': 0.7685420350984472, 'Patience Count': 0, 'Best Val F1': 0.7685524583158165, 'Best Val Loss': 59.30949664115906, 'Micro ROC value': 0.8286068531308874, 'Macro ROC value': 0.8286068531308874}\n","Training Epoch Loss after 307 is 232.17524194717407\n","{'Validation Epoch Loss': 59.30723550915718, 'Epoch': 307, 'Micro F1': 0.7685698303447653, 'Patience Count': 0, 'Best Val F1': 0.7685698303447653, 'Best Val Loss': 59.30723550915718, 'Micro ROC value': 0.82861876651233, 'Macro ROC value': 0.82861876651233}\n","Training Epoch Loss after 308 is 232.1653323918581\n","{'Validation Epoch Loss': 59.305047035217285, 'Epoch': 308, 'Micro F1': 0.7685767791563448, 'Patience Count': 0, 'Best Val F1': 0.7685767791563448, 'Best Val Loss': 59.305047035217285, 'Micro ROC value': 0.8286301441068404, 'Macro ROC value': 0.8286301441068404}\n","Training Epoch Loss after 309 is 232.15569493174553\n","{'Validation Epoch Loss': 59.30304977297783, 'Epoch': 309, 'Micro F1': 0.7686115232142423, 'Patience Count': 0, 'Best Val F1': 0.7686115232142423, 'Best Val Loss': 59.30304977297783, 'Micro ROC value': 0.8286399943509517, 'Macro ROC value': 0.8286399943509517}\n","Training Epoch Loss after 310 is 232.1461291462183\n","{'Validation Epoch Loss': 59.30115506052971, 'Epoch': 310, 'Micro F1': 0.7686080488084526, 'Patience Count': 0, 'Best Val F1': 0.7686115232142423, 'Best Val Loss': 59.30115506052971, 'Micro ROC value': 0.828649487435995, 'Macro ROC value': 0.828649487435995}\n","Training Epoch Loss after 311 is 232.1368246525526\n","{'Validation Epoch Loss': 59.29941448569298, 'Epoch': 311, 'Micro F1': 0.7686080488084526, 'Patience Count': 0, 'Best Val F1': 0.7686115232142423, 'Best Val Loss': 59.29941448569298, 'Micro ROC value': 0.8286569627897891, 'Macro ROC value': 0.8286569627897891}\n","Training Epoch Loss after 312 is 232.12752287089825\n","{'Validation Epoch Loss': 59.2976948171854, 'Epoch': 312, 'Micro F1': 0.7686532160837192, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.2976948171854, 'Micro ROC value': 0.8286642090833118, 'Macro ROC value': 0.8286642090833118}\n","Training Epoch Loss after 313 is 232.11825904250145\n","{'Validation Epoch Loss': 59.29607445001602, 'Epoch': 313, 'Micro F1': 0.7686462672721398, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.29607445001602, 'Micro ROC value': 0.8286703165758709, 'Macro ROC value': 0.8286703165758709}\n","Training Epoch Loss after 314 is 232.10906502604485\n","{'Validation Epoch Loss': 59.294426307082176, 'Epoch': 314, 'Micro F1': 0.7686045744026628, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.294426307082176, 'Micro ROC value': 0.8286757834536199, 'Macro ROC value': 0.8286757834536199}\n","Training Epoch Loss after 315 is 232.09986005723476\n","{'Validation Epoch Loss': 59.29284232854843, 'Epoch': 315, 'Micro F1': 0.7685906767795037, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.29284232854843, 'Micro ROC value': 0.8286812675127017, 'Macro ROC value': 0.8286812675127017}\n","Training Epoch Loss after 316 is 232.09063087403774\n","{'Validation Epoch Loss': 59.29121349751949, 'Epoch': 316, 'Micro F1': 0.7686149976200319, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.29121349751949, 'Micro ROC value': 0.8286863086027118, 'Macro ROC value': 0.8286863086027118}\n","Training Epoch Loss after 317 is 232.08148182928562\n","{'Validation Epoch Loss': 59.2896581441164, 'Epoch': 317, 'Micro F1': 0.7686149976200319, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.2896581441164, 'Micro ROC value': 0.8286907066130793, 'Macro ROC value': 0.8286907066130793}\n","Training Epoch Loss after 318 is 232.07234905660152\n","{'Validation Epoch Loss': 59.28806035220623, 'Epoch': 318, 'Micro F1': 0.7686149976200319, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.28806035220623, 'Micro ROC value': 0.8286958116195804, 'Macro ROC value': 0.8286958116195804}\n","Training Epoch Loss after 319 is 232.0632130354643\n","{'Validation Epoch Loss': 59.28651349246502, 'Epoch': 319, 'Micro F1': 0.7686045744026628, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.28651349246502, 'Micro ROC value': 0.8286999408907059, 'Macro ROC value': 0.8286999408907059}\n","Training Epoch Loss after 320 is 232.0540549904108\n","{'Validation Epoch Loss': 59.284919902682304, 'Epoch': 320, 'Micro F1': 0.7686149976200319, 'Patience Count': 0, 'Best Val F1': 0.7686532160837192, 'Best Val Loss': 59.284919902682304, 'Micro ROC value': 0.8287051445388387, 'Macro ROC value': 0.8287051445388387}\n","Epoch   321: reducing learning rate of group 0 to 1.0000e-06.\n","Training Epoch Loss after 321 is 231.9575742483139\n","{'Validation Epoch Loss': 59.28290420770645, 'Epoch': 321, 'Micro F1': 0.7686879601416167, 'Patience Count': 0, 'Best Val F1': 0.7686879601416167, 'Best Val Loss': 59.28290420770645, 'Micro ROC value': 0.8287478253857842, 'Macro ROC value': 0.8287478253857842}\n","Training Epoch Loss after 322 is 231.95617571473122\n","{'Validation Epoch Loss': 59.28177949786186, 'Epoch': 322, 'Micro F1': 0.7688060899384683, 'Patience Count': 0, 'Best Val F1': 0.7688060899384683, 'Best Val Loss': 59.28177949786186, 'Micro ROC value': 0.8287752917638951, 'Macro ROC value': 0.8287752917638951}\n","Training Epoch Loss after 323 is 231.95532432198524\n","{'Validation Epoch Loss': 59.281177043914795, 'Epoch': 323, 'Micro F1': 0.7688547316195248, 'Patience Count': 0, 'Best Val F1': 0.7688547316195248, 'Best Val Loss': 59.281177043914795, 'Micro ROC value': 0.8287931811559963, 'Macro ROC value': 0.8287931811559963}\n","Training Epoch Loss after 324 is 231.95444239676\n","{'Validation Epoch Loss': 59.28074133396149, 'Epoch': 324, 'Micro F1': 0.7688998988947915, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.28074133396149, 'Micro ROC value': 0.828806687858356, 'Macro ROC value': 0.828806687858356}\n","Training Epoch Loss after 325 is 231.9535766094923\n","{'Validation Epoch Loss': 59.28041914105415, 'Epoch': 325, 'Micro F1': 0.7688825268658429, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.28041914105415, 'Micro ROC value': 0.8288173636038831, 'Macro ROC value': 0.8288173636038831}\n","Training Epoch Loss after 326 is 231.95265999436378\n","{'Validation Epoch Loss': 59.28022627532482, 'Epoch': 326, 'Micro F1': 0.7688825268658429, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.28022627532482, 'Micro ROC value': 0.8288257268048571, 'Macro ROC value': 0.8288257268048571}\n","Training Epoch Loss after 327 is 231.95180270075798\n","{'Validation Epoch Loss': 59.28003388643265, 'Epoch': 327, 'Micro F1': 0.7688860012716325, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.28003388643265, 'Micro ROC value': 0.8288335267432654, 'Macro ROC value': 0.8288335267432654}\n","Training Epoch Loss after 328 is 231.95088456571102\n","{'Validation Epoch Loss': 59.27988465130329, 'Epoch': 328, 'Micro F1': 0.7688825268658429, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27988465130329, 'Micro ROC value': 0.8288404747678858, 'Macro ROC value': 0.8288404747678858}\n","Training Epoch Loss after 329 is 231.94994880259037\n","{'Validation Epoch Loss': 59.27971827983856, 'Epoch': 329, 'Micro F1': 0.7688894756774223, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27971827983856, 'Micro ROC value': 0.8288467523580552, 'Macro ROC value': 0.8288467523580552}\n","Training Epoch Loss after 330 is 231.94908772408962\n","{'Validation Epoch Loss': 59.27961352467537, 'Epoch': 330, 'Micro F1': 0.7688860012716325, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27961352467537, 'Micro ROC value': 0.8288524725094302, 'Macro ROC value': 0.8288524725094302}\n","Training Epoch Loss after 331 is 231.94817833602428\n","{'Validation Epoch Loss': 59.27946425974369, 'Epoch': 331, 'Micro F1': 0.7688790524600532, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27946425974369, 'Micro ROC value': 0.8288584086477979, 'Macro ROC value': 0.8288584086477979}\n","Training Epoch Loss after 332 is 231.9472796022892\n","{'Validation Epoch Loss': 59.27934588491917, 'Epoch': 332, 'Micro F1': 0.7688790524600532, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27934588491917, 'Micro ROC value': 0.8288634792916335, 'Macro ROC value': 0.8288634792916335}\n","Training Epoch Loss after 333 is 231.94634537398815\n","{'Validation Epoch Loss': 59.27919967472553, 'Epoch': 333, 'Micro F1': 0.7688825268658429, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27919967472553, 'Micro ROC value': 0.8288686966413353, 'Macro ROC value': 0.8288686966413353}\n","Training Epoch Loss after 334 is 231.94547718763351\n","{'Validation Epoch Loss': 59.27903801202774, 'Epoch': 334, 'Micro F1': 0.7688790524600532, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27903801202774, 'Micro ROC value': 0.8288742479033512, 'Macro ROC value': 0.8288742479033512}\n","Training Epoch Loss after 335 is 231.94459806382656\n","{'Validation Epoch Loss': 59.278879567980766, 'Epoch': 335, 'Micro F1': 0.7688860012716325, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288787849351071, 'Macro ROC value': 0.8288787849351071}\n","Epoch   336: reducing learning rate of group 0 to 1.0000e-07.\n","Training Epoch Loss after 336 is 231.93355038762093\n","{'Validation Epoch Loss': 59.27891053259373, 'Epoch': 336, 'Micro F1': 0.7688825268658429, 'Patience Count': 1, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288781999723491, 'Macro ROC value': 0.8288781999723491}\n","Training Epoch Loss after 337 is 231.93357107043266\n","{'Validation Epoch Loss': 59.2789051681757, 'Epoch': 337, 'Micro F1': 0.7688825268658429, 'Patience Count': 2, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288779612702332, 'Macro ROC value': 0.8288779612702332}\n","Training Epoch Loss after 338 is 231.9335174113512\n","{'Validation Epoch Loss': 59.278895527124405, 'Epoch': 338, 'Micro F1': 0.7688755780542632, 'Patience Count': 3, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288775070644252, 'Macro ROC value': 0.8288775070644252}\n","Training Epoch Loss after 339 is 231.93347899615765\n","{'Validation Epoch Loss': 59.27888920903206, 'Epoch': 339, 'Micro F1': 0.7688721036484734, 'Patience Count': 4, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288772430131981, 'Macro ROC value': 0.8288772430131981}\n","Training Epoch Loss after 340 is 231.9334166198969\n","{'Validation Epoch Loss': 59.27891170978546, 'Epoch': 340, 'Micro F1': 0.7688755780542632, 'Patience Count': 5, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288768278580702, 'Macro ROC value': 0.8288768278580702}\n","Training Epoch Loss after 341 is 231.9333514124155\n","{'Validation Epoch Loss': 59.27889131009579, 'Epoch': 341, 'Micro F1': 0.7688755780542632, 'Patience Count': 6, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288766328463191, 'Macro ROC value': 0.8288766328463191}\n","Training Epoch Loss after 342 is 231.93329033255577\n","{'Validation Epoch Loss': 59.278904408216476, 'Epoch': 342, 'Micro F1': 0.7688755780542632, 'Patience Count': 7, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288761180346287, 'Macro ROC value': 0.8288761180346287}\n","Training Epoch Loss after 343 is 231.93327218294144\n","{'Validation Epoch Loss': 59.27888526022434, 'Epoch': 343, 'Micro F1': 0.7688721036484734, 'Patience Count': 8, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.278879567980766, 'Micro ROC value': 0.8288755077710899, 'Macro ROC value': 0.8288755077710899}\n","Training Epoch Loss after 344 is 231.93324552476406\n","{'Validation Epoch Loss': 59.27886727452278, 'Epoch': 344, 'Micro F1': 0.7688686292426837, 'Patience Count': 0, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288753765550044, 'Macro ROC value': 0.8288753765550044}\n","Training Epoch Loss after 345 is 231.93320164084435\n","{'Validation Epoch Loss': 59.27889125049114, 'Epoch': 345, 'Micro F1': 0.7688686292426837, 'Patience Count': 1, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288752507518848, 'Macro ROC value': 0.8288752507518848}\n","Training Epoch Loss after 346 is 231.93306510150433\n","{'Validation Epoch Loss': 59.278890028595924, 'Epoch': 346, 'Micro F1': 0.7688721036484734, 'Patience Count': 2, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288744004813186, 'Macro ROC value': 0.8288744004813186}\n","Epoch   347: reducing learning rate of group 0 to 1.0000e-08.\n","Training Epoch Loss after 347 is 231.9320169687271\n","{'Validation Epoch Loss': 59.27887134253979, 'Epoch': 347, 'Micro F1': 0.7688721036484734, 'Patience Count': 3, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288744213115702, 'Macro ROC value': 0.8288744213115702}\n","Training Epoch Loss after 348 is 231.93202956020832\n","{'Validation Epoch Loss': 59.27888186275959, 'Epoch': 348, 'Micro F1': 0.7688721036484734, 'Patience Count': 4, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288743329159088, 'Macro ROC value': 0.8288743329159088}\n","Training Epoch Loss after 349 is 231.93199937045574\n","{'Validation Epoch Loss': 59.27893778681755, 'Epoch': 349, 'Micro F1': 0.7688721036484734, 'Patience Count': 5, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288741009075048, 'Macro ROC value': 0.8288741009075048}\n","Training Epoch Loss after 350 is 231.93201172351837\n","{'Validation Epoch Loss': 59.27890059351921, 'Epoch': 350, 'Micro F1': 0.7688721036484734, 'Patience Count': 6, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288741024299013, 'Macro ROC value': 0.8288741024299013}\n","Training Epoch Loss after 351 is 231.93200966715813\n","{'Validation Epoch Loss': 59.27889324724674, 'Epoch': 351, 'Micro F1': 0.7688721036484734, 'Patience Count': 7, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.828874080802204, 'Macro ROC value': 0.828874080802204}\n","Training Epoch Loss after 352 is 231.93202313780785\n","{'Validation Epoch Loss': 59.27889122068882, 'Epoch': 352, 'Micro F1': 0.7688721036484734, 'Patience Count': 8, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288737658594345, 'Macro ROC value': 0.8288737658594345}\n","Training Epoch Loss after 353 is 231.9320182353258\n","{'Validation Epoch Loss': 59.27890142798424, 'Epoch': 353, 'Micro F1': 0.7688721036484734, 'Patience Count': 9, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.828873899274537, 'Macro ROC value': 0.828873899274537}\n","Training Epoch Loss after 354 is 231.93202659487724\n","{'Validation Epoch Loss': 59.27891616523266, 'Epoch': 354, 'Micro F1': 0.7688721036484734, 'Patience Count': 10, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288739025609804, 'Macro ROC value': 0.8288739025609804}\n","Training Epoch Loss after 355 is 231.93203282356262\n","{'Validation Epoch Loss': 59.2788952589035, 'Epoch': 355, 'Micro F1': 0.7688721036484734, 'Patience Count': 11, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288738279152186, 'Macro ROC value': 0.8288738279152186}\n","Training Epoch Loss after 356 is 231.93202947080135\n","{'Validation Epoch Loss': 59.27890318632126, 'Epoch': 356, 'Micro F1': 0.7688721036484734, 'Patience Count': 12, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.828873662505623, 'Macro ROC value': 0.828873662505623}\n","Training Epoch Loss after 357 is 231.9319919794798\n","{'Validation Epoch Loss': 59.27890807390213, 'Epoch': 357, 'Micro F1': 0.7688721036484734, 'Patience Count': 13, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288734817995669, 'Macro ROC value': 0.8288734817995669}\n","Training Epoch Loss after 358 is 231.93200059235096\n","{'Validation Epoch Loss': 59.27892018854618, 'Epoch': 358, 'Micro F1': 0.7688721036484734, 'Patience Count': 14, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288735382007348, 'Macro ROC value': 0.8288735382007348}\n","Training Epoch Loss after 359 is 231.93196119368076\n","{'Validation Epoch Loss': 59.278910741209984, 'Epoch': 359, 'Micro F1': 0.7688686292426837, 'Patience Count': 15, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288735685278412, 'Macro ROC value': 0.8288735685278412}\n","Training Epoch Loss after 360 is 231.93195955455303\n","{'Validation Epoch Loss': 59.27892614901066, 'Epoch': 360, 'Micro F1': 0.7688686292426837, 'Patience Count': 16, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288733858644179, 'Macro ROC value': 0.8288733858644179}\n","Training Epoch Loss after 361 is 231.93198427557945\n","{'Validation Epoch Loss': 59.27893793582916, 'Epoch': 361, 'Micro F1': 0.7688686292426837, 'Patience Count': 17, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288731651894106, 'Macro ROC value': 0.8288731651894106}\n","Training Epoch Loss after 362 is 231.93196530640125\n","{'Validation Epoch Loss': 59.27890919148922, 'Epoch': 362, 'Micro F1': 0.7688686292426837, 'Patience Count': 18, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288733372927178, 'Macro ROC value': 0.8288733372927178}\n","Training Epoch Loss after 363 is 231.93198303878307\n","{'Validation Epoch Loss': 59.27891671657562, 'Epoch': 363, 'Micro F1': 0.7688686292426837, 'Patience Count': 19, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288732194157264, 'Macro ROC value': 0.8288732194157264}\n","Training Epoch Loss after 364 is 231.93195827305317\n","{'Validation Epoch Loss': 59.278917610645294, 'Epoch': 364, 'Micro F1': 0.7688755780542632, 'Patience Count': 20, 'Best Val F1': 0.7688998988947915, 'Best Val Loss': 59.27886727452278, 'Micro ROC value': 0.8288732129394996, 'Macro ROC value': 0.8288732129394996}\n","Testing stats.\n","\n","\n","\n","{'Micro F1': 0.7523635649929454, 'Micro Recall': 0.7523635649929454, 'Micro Precision': 0.7523635649929454, 'Micro ROC_AUC_Score': 0.7989051649188257, 'Macro ROC_AUC_Score': 0.7989051649188257}\n","\n","\n","\n","\n","Training Epoch Loss after 0 is 331.21077187359333\n","{'Validation Epoch Loss': 82.48410174250603, 'Epoch': 0, 'Micro F1': 0.5118847238067952, 'Patience Count': 0, 'Best Val F1': 0.5118847238067952, 'Best Val Loss': 82.48410174250603, 'Micro ROC value': 0.5039713855594735, 'Macro ROC value': 0.5039713855594735}\n","Training Epoch Loss after 1 is 331.60727083683014\n","{'Validation Epoch Loss': 102.43374815583229, 'Epoch': 1, 'Micro F1': 0.4984677250193133, 'Patience Count': 1, 'Best Val F1': 0.5118847238067952, 'Best Val Loss': 82.48410174250603, 'Micro ROC value': 0.4713316447787395, 'Macro ROC value': 0.4713316447787395}\n","Training Epoch Loss after 2 is 328.48896799981594\n","{'Validation Epoch Loss': 80.4941166639328, 'Epoch': 2, 'Micro F1': 0.5496058037153192, 'Patience Count': 0, 'Best Val F1': 0.5496058037153192, 'Best Val Loss': 80.4941166639328, 'Micro ROC value': 0.5745178432300545, 'Macro ROC value': 0.5745178432300545}\n","Training Epoch Loss after 3 is 323.14787486195564\n","{'Validation Epoch Loss': 81.56773436069489, 'Epoch': 3, 'Micro F1': 0.5421746537672477, 'Patience Count': 1, 'Best Val F1': 0.5496058037153192, 'Best Val Loss': 80.4941166639328, 'Micro ROC value': 0.561596626670205, 'Macro ROC value': 0.561596626670205}\n","Training Epoch Loss after 4 is 320.18117505311966\n","{'Validation Epoch Loss': 82.85543662309647, 'Epoch': 4, 'Micro F1': 0.513240492988371, 'Patience Count': 2, 'Best Val F1': 0.5496058037153192, 'Best Val Loss': 80.4941166639328, 'Micro ROC value': 0.5362703677349212, 'Macro ROC value': 0.5362703677349212}\n","Training Epoch Loss after 5 is 314.31570756435394\n","{'Validation Epoch Loss': 80.80745670199394, 'Epoch': 5, 'Micro F1': 0.5309550242759425, 'Patience Count': 3, 'Best Val F1': 0.5496058037153192, 'Best Val Loss': 80.4941166639328, 'Micro ROC value': 0.5326199998427739, 'Macro ROC value': 0.5326199998427739}\n","Training Epoch Loss after 6 is 310.683994024992\n","{'Validation Epoch Loss': 80.63689312338829, 'Epoch': 6, 'Micro F1': 0.5371736561257745, 'Patience Count': 4, 'Best Val F1': 0.5496058037153192, 'Best Val Loss': 80.4941166639328, 'Micro ROC value': 0.5532896300872879, 'Macro ROC value': 0.5532896300872879}\n","Training Epoch Loss after 7 is 308.6189907491207\n","{'Validation Epoch Loss': 79.90474507212639, 'Epoch': 7, 'Micro F1': 0.556085357181228, 'Patience Count': 0, 'Best Val F1': 0.556085357181228, 'Best Val Loss': 79.90474507212639, 'Micro ROC value': 0.5593035952957648, 'Macro ROC value': 0.5593035952957648}\n","Training Epoch Loss after 8 is 307.02528873085976\n","{'Validation Epoch Loss': 78.1256114244461, 'Epoch': 8, 'Micro F1': 0.5621402735072469, 'Patience Count': 0, 'Best Val F1': 0.5621402735072469, 'Best Val Loss': 78.1256114244461, 'Micro ROC value': 0.5713663729737992, 'Macro ROC value': 0.5713663729737992}\n","Training Epoch Loss after 9 is 306.093535810709\n","{'Validation Epoch Loss': 79.52968665957451, 'Epoch': 9, 'Micro F1': 0.5330730938652724, 'Patience Count': 1, 'Best Val F1': 0.5621402735072469, 'Best Val Loss': 78.1256114244461, 'Micro ROC value': 0.5649098674615523, 'Macro ROC value': 0.5649098674615523}\n","Training Epoch Loss after 10 is 305.21724286675453\n","{'Validation Epoch Loss': 79.02805554866791, 'Epoch': 10, 'Micro F1': 0.5303436491167036, 'Patience Count': 2, 'Best Val F1': 0.5621402735072469, 'Best Val Loss': 78.1256114244461, 'Micro ROC value': 0.5611165844437709, 'Macro ROC value': 0.5611165844437709}\n","Training Epoch Loss after 11 is 303.37979558110237\n","{'Validation Epoch Loss': 78.05861699581146, 'Epoch': 11, 'Micro F1': 0.5628335064283924, 'Patience Count': 0, 'Best Val F1': 0.5628335064283924, 'Best Val Loss': 78.05861699581146, 'Micro ROC value': 0.5636519129072042, 'Macro ROC value': 0.5636519129072042}\n","Training Epoch Loss after 12 is 304.0965927243233\n","{'Validation Epoch Loss': 78.44279846549034, 'Epoch': 12, 'Micro F1': 0.5691314379850712, 'Patience Count': 0, 'Best Val F1': 0.5691314379850712, 'Best Val Loss': 78.05861699581146, 'Micro ROC value': 0.5666099011930708, 'Macro ROC value': 0.5666099011930708}\n","Training Epoch Loss after 13 is 302.4905128777027\n","{'Validation Epoch Loss': 77.66489714384079, 'Epoch': 13, 'Micro F1': 0.5729864269598539, 'Patience Count': 0, 'Best Val F1': 0.5729864269598539, 'Best Val Loss': 77.66489714384079, 'Micro ROC value': 0.5680021281619869, 'Macro ROC value': 0.5680021281619869}\n","Training Epoch Loss after 14 is 302.659108042717\n","{'Validation Epoch Loss': 78.22577920556068, 'Epoch': 14, 'Micro F1': 0.5627337422810689, 'Patience Count': 1, 'Best Val F1': 0.5729864269598539, 'Best Val Loss': 77.66489714384079, 'Micro ROC value': 0.5671778142845224, 'Macro ROC value': 0.5671778142845224}\n","Training Epoch Loss after 15 is 304.28456884622574\n","{'Validation Epoch Loss': 79.48848286271095, 'Epoch': 15, 'Micro F1': 0.5531794066335484, 'Patience Count': 2, 'Best Val F1': 0.5729864269598539, 'Best Val Loss': 77.66489714384079, 'Micro ROC value': 0.5620779724139646, 'Macro ROC value': 0.5620779724139646}\n","Training Epoch Loss after 16 is 300.17550003528595\n","{'Validation Epoch Loss': 76.37731546163559, 'Epoch': 16, 'Micro F1': 0.575877029177176, 'Patience Count': 0, 'Best Val F1': 0.575877029177176, 'Best Val Loss': 76.37731546163559, 'Micro ROC value': 0.5926837058961163, 'Macro ROC value': 0.5926837058961163}\n","Training Epoch Loss after 17 is 291.26631420850754\n","{'Validation Epoch Loss': 74.91715022921562, 'Epoch': 17, 'Micro F1': 0.5926297317623465, 'Patience Count': 0, 'Best Val F1': 0.5926297317623465, 'Best Val Loss': 74.91715022921562, 'Micro ROC value': 0.6212386010438761, 'Macro ROC value': 0.6212386010438761}\n","Training Epoch Loss after 18 is 274.791717171669\n","{'Validation Epoch Loss': 71.80654880404472, 'Epoch': 18, 'Micro F1': 0.6413760289776477, 'Patience Count': 0, 'Best Val F1': 0.6413760289776477, 'Best Val Loss': 71.80654880404472, 'Micro ROC value': 0.6537582447241469, 'Macro ROC value': 0.6537582447241469}\n","Training Epoch Loss after 19 is 265.0859572738409\n","{'Validation Epoch Loss': 73.61963319778442, 'Epoch': 19, 'Micro F1': 0.5822593765508208, 'Patience Count': 1, 'Best Val F1': 0.6413760289776477, 'Best Val Loss': 71.80654880404472, 'Micro ROC value': 0.6385225721567421, 'Macro ROC value': 0.6385225721567421}\n","Training Epoch Loss after 20 is 256.9828248769045\n","{'Validation Epoch Loss': 73.25533753633499, 'Epoch': 20, 'Micro F1': 0.6077555113296259, 'Patience Count': 2, 'Best Val F1': 0.6413760289776477, 'Best Val Loss': 71.80654880404472, 'Micro ROC value': 0.6695166756277426, 'Macro ROC value': 0.6695166756277426}\n","Training Epoch Loss after 21 is 268.8827986866236\n","{'Validation Epoch Loss': 66.80862587690353, 'Epoch': 21, 'Micro F1': 0.6561718194422417, 'Patience Count': 0, 'Best Val F1': 0.6561718194422417, 'Best Val Loss': 66.80862587690353, 'Micro ROC value': 0.7067766524037716, 'Macro ROC value': 0.7067766524037716}\n","Training Epoch Loss after 22 is 244.12812524288893\n","{'Validation Epoch Loss': 64.08694916963577, 'Epoch': 22, 'Micro F1': 0.7031863133822093, 'Patience Count': 0, 'Best Val F1': 0.7031863133822093, 'Best Val Loss': 64.08694916963577, 'Micro ROC value': 0.7306770473618831, 'Macro ROC value': 0.7306770473618831}\n","Training Epoch Loss after 23 is 235.16349839419127\n","{'Validation Epoch Loss': 61.53816246986389, 'Epoch': 23, 'Micro F1': 0.6852594635246929, 'Patience Count': 0, 'Best Val F1': 0.7031863133822093, 'Best Val Loss': 61.53816246986389, 'Micro ROC value': 0.7588095859735235, 'Macro ROC value': 0.7588095859735235}\n","Training Epoch Loss after 24 is 231.1287579536438\n","{'Validation Epoch Loss': 66.1079086959362, 'Epoch': 24, 'Micro F1': 0.6619018627756944, 'Patience Count': 1, 'Best Val F1': 0.7031863133822093, 'Best Val Loss': 61.53816246986389, 'Micro ROC value': 0.7266802418730519, 'Macro ROC value': 0.7266802418730519}\n","Training Epoch Loss after 25 is 226.96370860934258\n","{'Validation Epoch Loss': 60.67895954847336, 'Epoch': 25, 'Micro F1': 0.6987787845145579, 'Patience Count': 0, 'Best Val F1': 0.7031863133822093, 'Best Val Loss': 60.67895954847336, 'Micro ROC value': 0.7756404736143084, 'Macro ROC value': 0.7756404736143084}\n","Training Epoch Loss after 26 is 223.76387324929237\n","{'Validation Epoch Loss': 56.71352443099022, 'Epoch': 26, 'Micro F1': 0.7252469802160021, 'Patience Count': 0, 'Best Val F1': 0.7252469802160021, 'Best Val Loss': 56.71352443099022, 'Micro ROC value': 0.7914540192831325, 'Macro ROC value': 0.7914540192831325}\n","Training Epoch Loss after 27 is 215.2238818258047\n","{'Validation Epoch Loss': 57.57115590572357, 'Epoch': 27, 'Micro F1': 0.6842541478862791, 'Patience Count': 1, 'Best Val F1': 0.7252469802160021, 'Best Val Loss': 56.71352443099022, 'Micro ROC value': 0.7772998637209041, 'Macro ROC value': 0.7772998637209041}\n","Training Epoch Loss after 28 is 205.1733570098877\n","{'Validation Epoch Loss': 53.75133775174618, 'Epoch': 28, 'Micro F1': 0.8008963424928758, 'Patience Count': 0, 'Best Val F1': 0.8008963424928758, 'Best Val Loss': 53.75133775174618, 'Micro ROC value': 0.8256749023800635, 'Macro ROC value': 0.8256749023800635}\n","Training Epoch Loss after 29 is 206.90994318574667\n","{'Validation Epoch Loss': 53.88022504746914, 'Epoch': 29, 'Micro F1': 0.73796307191716, 'Patience Count': 1, 'Best Val F1': 0.8008963424928758, 'Best Val Loss': 53.75133775174618, 'Micro ROC value': 0.7865912242703503, 'Macro ROC value': 0.7865912242703503}\n","Training Epoch Loss after 30 is 193.87265567854047\n","{'Validation Epoch Loss': 46.91206830739975, 'Epoch': 30, 'Micro F1': 0.7742669893226782, 'Patience Count': 0, 'Best Val F1': 0.8008963424928758, 'Best Val Loss': 46.91206830739975, 'Micro ROC value': 0.8265721582584991, 'Macro ROC value': 0.8265721582584991}\n","Training Epoch Loss after 31 is 238.61747144162655\n","{'Validation Epoch Loss': 55.44774208217859, 'Epoch': 31, 'Micro F1': 0.6731112600467613, 'Patience Count': 1, 'Best Val F1': 0.8008963424928758, 'Best Val Loss': 46.91206830739975, 'Micro ROC value': 0.7736042010196904, 'Macro ROC value': 0.7736042010196904}\n","Training Epoch Loss after 32 is 205.2169756218791\n","{'Validation Epoch Loss': 52.412817627191544, 'Epoch': 32, 'Micro F1': 0.7459365295378618, 'Patience Count': 2, 'Best Val F1': 0.8008963424928758, 'Best Val Loss': 46.91206830739975, 'Micro ROC value': 0.81255336848856, 'Macro ROC value': 0.81255336848856}\n","Training Epoch Loss after 33 is 201.37175261974335\n","{'Validation Epoch Loss': 59.25996923446655, 'Epoch': 33, 'Micro F1': 0.6381835762632955, 'Patience Count': 3, 'Best Val F1': 0.8008963424928758, 'Best Val Loss': 46.91206830739975, 'Micro ROC value': 0.7455532526039236, 'Macro ROC value': 0.7455532526039236}\n","Training Epoch Loss after 34 is 206.53053115308285\n","{'Validation Epoch Loss': 49.0153568610549, 'Epoch': 34, 'Micro F1': 0.7419459636449215, 'Patience Count': 4, 'Best Val F1': 0.8008963424928758, 'Best Val Loss': 46.91206830739975, 'Micro ROC value': 0.7989816007834416, 'Macro ROC value': 0.7989816007834416}\n","Training Epoch Loss after 35 is 188.1774065643549\n","{'Validation Epoch Loss': 46.26332591474056, 'Epoch': 35, 'Micro F1': 0.8044366906953305, 'Patience Count': 0, 'Best Val F1': 0.8044366906953305, 'Best Val Loss': 46.26332591474056, 'Micro ROC value': 0.8452903298154197, 'Macro ROC value': 0.8452903298154197}\n","Training Epoch Loss after 36 is 184.41291729733348\n","{'Validation Epoch Loss': 49.56442102044821, 'Epoch': 36, 'Micro F1': 0.7185141792991953, 'Patience Count': 1, 'Best Val F1': 0.8044366906953305, 'Best Val Loss': 46.26332591474056, 'Micro ROC value': 0.8037578637335578, 'Macro ROC value': 0.8037578637335578}\n","Training Epoch Loss after 37 is 179.49083565175533\n","{'Validation Epoch Loss': 47.7831112369895, 'Epoch': 37, 'Micro F1': 0.8137352208368933, 'Patience Count': 0, 'Best Val F1': 0.8137352208368933, 'Best Val Loss': 46.26332591474056, 'Micro ROC value': 0.8471256727078086, 'Macro ROC value': 0.8471256727078086}\n","Training Epoch Loss after 38 is 173.79209141805768\n","{'Validation Epoch Loss': 42.10917042940855, 'Epoch': 38, 'Micro F1': 0.8157535262788997, 'Patience Count': 0, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8593255102650936, 'Macro ROC value': 0.8593255102650936}\n","Training Epoch Loss after 39 is 174.02736904844642\n","{'Validation Epoch Loss': 51.724889293313026, 'Epoch': 39, 'Micro F1': 0.7642419715441955, 'Patience Count': 1, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8223698081760911, 'Macro ROC value': 0.8223698081760911}\n","Training Epoch Loss after 40 is 170.18204107135534\n","{'Validation Epoch Loss': 47.33439837396145, 'Epoch': 40, 'Micro F1': 0.7782524391054993, 'Patience Count': 2, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8479938446943649, 'Macro ROC value': 0.8479938446943649}\n","Training Epoch Loss after 41 is 175.2206050120294\n","{'Validation Epoch Loss': 45.12748910486698, 'Epoch': 41, 'Micro F1': 0.8049252792117099, 'Patience Count': 3, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.851670257398494, 'Macro ROC value': 0.851670257398494}\n","Training Epoch Loss after 42 is 171.8477259799838\n","{'Validation Epoch Loss': 44.70287311822176, 'Epoch': 42, 'Micro F1': 0.7147845350223319, 'Patience Count': 4, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8387626491972486, 'Macro ROC value': 0.8387626491972486}\n","Training Epoch Loss after 43 is 159.9680319353938\n","{'Validation Epoch Loss': 64.19903333485126, 'Epoch': 43, 'Micro F1': 0.7325041824200224, 'Patience Count': 5, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.7855780916213485, 'Macro ROC value': 0.7855780916213485}\n","Training Epoch Loss after 44 is 195.43318389728665\n","{'Validation Epoch Loss': 52.05851753056049, 'Epoch': 44, 'Micro F1': 0.7548360030901305, 'Patience Count': 6, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8101527084539044, 'Macro ROC value': 0.8101527084539044}\n","Training Epoch Loss after 45 is 218.53555355221033\n","{'Validation Epoch Loss': 53.659590512514114, 'Epoch': 45, 'Micro F1': 0.7839620179984754, 'Patience Count': 7, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8018088342419913, 'Macro ROC value': 0.8018088342419913}\n","Training Epoch Loss after 46 is 240.62809740006924\n","{'Validation Epoch Loss': 64.2987417280674, 'Epoch': 46, 'Micro F1': 0.6766976532402883, 'Patience Count': 8, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.731860314523662, 'Macro ROC value': 0.731860314523662}\n","Training Epoch Loss after 47 is 223.7819068878889\n","{'Validation Epoch Loss': 57.28103902935982, 'Epoch': 47, 'Micro F1': 0.7631343337033987, 'Patience Count': 9, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8083096565948406, 'Macro ROC value': 0.8083096565948406}\n","Training Epoch Loss after 48 is 198.78165243566036\n","{'Validation Epoch Loss': 53.07850317656994, 'Epoch': 48, 'Micro F1': 0.7914161904420831, 'Patience Count': 10, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8372135631306244, 'Macro ROC value': 0.8372135631306244}\n","Training Epoch Loss after 49 is 183.9928708821535\n","{'Validation Epoch Loss': 49.59100100398064, 'Epoch': 49, 'Micro F1': 0.8017456167726554, 'Patience Count': 11, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8463998288799592, 'Macro ROC value': 0.8463998288799592}\n","Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n","Training Epoch Loss after 50 is 166.4476779103279\n","{'Validation Epoch Loss': 47.60026026517153, 'Epoch': 50, 'Micro F1': 0.8035311392042402, 'Patience Count': 12, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8554577772041284, 'Macro ROC value': 0.8554577772041284}\n","Training Epoch Loss after 51 is 162.93336191400886\n","{'Validation Epoch Loss': 47.225008234381676, 'Epoch': 51, 'Micro F1': 0.8112615815942822, 'Patience Count': 13, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8595763986034606, 'Macro ROC value': 0.8595763986034606}\n","Training Epoch Loss after 52 is 161.79569002613425\n","{'Validation Epoch Loss': 46.936416409909725, 'Epoch': 52, 'Micro F1': 0.805050623909629, 'Patience Count': 14, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8501513165360721, 'Macro ROC value': 0.8501513165360721}\n","Training Epoch Loss after 53 is 159.7303378842771\n","{'Validation Epoch Loss': 46.02950644493103, 'Epoch': 53, 'Micro F1': 0.8134742992208164, 'Patience Count': 15, 'Best Val F1': 0.8157535262788997, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8615039259945281, 'Macro ROC value': 0.8615039259945281}\n","{'Validation Epoch Loss': 45.392357766628265, 'Epoch': 54, 'Micro F1': 0.8157791068294954, 'Patience Count': 0, 'Best Val F1': 0.8157791068294954, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8635102589961287, 'Macro ROC value': 0.8635102589961287}\n","Training Epoch Loss after 55 is 155.7883203998208\n","{'Validation Epoch Loss': 44.92249797284603, 'Epoch': 55, 'Micro F1': 0.8175364906554249, 'Patience Count': 0, 'Best Val F1': 0.8175364906554249, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.864254780748186, 'Macro ROC value': 0.864254780748186}\n","Training Epoch Loss after 56 is 155.03344835713506\n","{'Validation Epoch Loss': 44.54821699112654, 'Epoch': 56, 'Micro F1': 0.8098955801924681, 'Patience Count': 1, 'Best Val F1': 0.8175364906554249, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8639909758261858, 'Macro ROC value': 0.8639909758261858}\n","Training Epoch Loss after 57 is 154.55294642597437\n","{'Validation Epoch Loss': 44.569324143230915, 'Epoch': 57, 'Micro F1': 0.8120059756166191, 'Patience Count': 2, 'Best Val F1': 0.8175364906554249, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8586211646506319, 'Macro ROC value': 0.8586211646506319}\n","Training Epoch Loss after 58 is 152.96775900572538\n","{'Validation Epoch Loss': 43.58935488015413, 'Epoch': 58, 'Micro F1': 0.8174469587283398, 'Patience Count': 3, 'Best Val F1': 0.8175364906554249, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8671346720819035, 'Macro ROC value': 0.8671346720819035}\n","Training Epoch Loss after 59 is 150.86183907464147\n","{'Validation Epoch Loss': 43.0144018009305, 'Epoch': 59, 'Micro F1': 0.8240390666168699, 'Patience Count': 0, 'Best Val F1': 0.8240390666168699, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.8724539471169572, 'Macro ROC value': 0.8724539471169572}\n","Training Epoch Loss after 60 is 149.47910656407475\n","{'Validation Epoch Loss': 42.48857007175684, 'Epoch': 60, 'Micro F1': 0.8217572815037271, 'Patience Count': 1, 'Best Val F1': 0.8240390666168699, 'Best Val Loss': 42.10917042940855, 'Micro ROC value': 0.872982132279638, 'Macro ROC value': 0.872982132279638}\n","Training Epoch Loss after 61 is 148.0265744253993\n","{'Validation Epoch Loss': 42.09539058804512, 'Epoch': 61, 'Micro F1': 0.8198208338236274, 'Patience Count': 0, 'Best Val F1': 0.8240390666168699, 'Best Val Loss': 42.09539058804512, 'Micro ROC value': 0.8754416437977773, 'Macro ROC value': 0.8754416437977773}\n","Training Epoch Loss after 62 is 146.70540453493595\n","{'Validation Epoch Loss': 41.9008878543973, 'Epoch': 62, 'Micro F1': 0.8238088416615079, 'Patience Count': 0, 'Best Val F1': 0.8240390666168699, 'Best Val Loss': 41.9008878543973, 'Micro ROC value': 0.8774073531466171, 'Macro ROC value': 0.8774073531466171}\n","Training Epoch Loss after 63 is 145.7154092565179\n","{'Validation Epoch Loss': 41.52111867815256, 'Epoch': 63, 'Micro F1': 0.8209514941599603, 'Patience Count': 0, 'Best Val F1': 0.8240390666168699, 'Best Val Loss': 41.52111867815256, 'Micro ROC value': 0.8775391626506828, 'Macro ROC value': 0.8775391626506828}\n","Training Epoch Loss after 64 is 144.8600637204945\n","{'Validation Epoch Loss': 41.12953605502844, 'Epoch': 64, 'Micro F1': 0.8260931848297103, 'Patience Count': 0, 'Best Val F1': 0.8260931848297103, 'Best Val Loss': 41.12953605502844, 'Micro ROC value': 0.8818986103842722, 'Macro ROC value': 0.8818986103842722}\n","Training Epoch Loss after 65 is 143.6680980734527\n","{'Validation Epoch Loss': 40.92860137671232, 'Epoch': 65, 'Micro F1': 0.8192631778206394, 'Patience Count': 0, 'Best Val F1': 0.8260931848297103, 'Best Val Loss': 40.92860137671232, 'Micro ROC value': 0.8806306739762219, 'Macro ROC value': 0.8806306739762219}\n","Training Epoch Loss after 66 is 143.81102685257792\n","{'Validation Epoch Loss': 41.01753108203411, 'Epoch': 66, 'Micro F1': 0.807554959812955, 'Patience Count': 1, 'Best Val F1': 0.8260931848297103, 'Best Val Loss': 40.92860137671232, 'Micro ROC value': 0.8731053651142701, 'Macro ROC value': 0.8731053651142701}\n","Training Epoch Loss after 67 is 142.16167416796088\n","{'Validation Epoch Loss': 40.07964190840721, 'Epoch': 67, 'Micro F1': 0.8206598758831685, 'Patience Count': 0, 'Best Val F1': 0.8260931848297103, 'Best Val Loss': 40.07964190840721, 'Micro ROC value': 0.8809860027711739, 'Macro ROC value': 0.8809860027711739}\n","Training Epoch Loss after 68 is 140.97603503987193\n","{'Validation Epoch Loss': 39.77256739139557, 'Epoch': 68, 'Micro F1': 0.8272673321020562, 'Patience Count': 0, 'Best Val F1': 0.8272673321020562, 'Best Val Loss': 39.77256739139557, 'Micro ROC value': 0.8873150448056127, 'Macro ROC value': 0.8873150448056127}\n","Training Epoch Loss after 69 is 140.12290886975825\n","{'Validation Epoch Loss': 39.55853344500065, 'Epoch': 69, 'Micro F1': 0.8225119077463023, 'Patience Count': 0, 'Best Val F1': 0.8272673321020562, 'Best Val Loss': 39.55853344500065, 'Micro ROC value': 0.8853009685731689, 'Macro ROC value': 0.8853009685731689}\n","Training Epoch Loss after 70 is 139.3215329349041\n","{'Validation Epoch Loss': 39.01333048194647, 'Epoch': 70, 'Micro F1': 0.8310455794250514, 'Patience Count': 0, 'Best Val F1': 0.8310455794250514, 'Best Val Loss': 39.01333048194647, 'Micro ROC value': 0.891806846225792, 'Macro ROC value': 0.891806846225792}\n","Training Epoch Loss after 71 is 138.28140987828374\n","{'Validation Epoch Loss': 38.57848985865712, 'Epoch': 71, 'Micro F1': 0.8346652273343531, 'Patience Count': 0, 'Best Val F1': 0.8346652273343531, 'Best Val Loss': 38.57848985865712, 'Micro ROC value': 0.8945315489381598, 'Macro ROC value': 0.8945315489381598}\n","Training Epoch Loss after 72 is 137.26199382916093\n","{'Validation Epoch Loss': 40.998606372624636, 'Epoch': 72, 'Micro F1': 0.7734663180890305, 'Patience Count': 1, 'Best Val F1': 0.8346652273343531, 'Best Val Loss': 38.57848985865712, 'Micro ROC value': 0.8704209750988297, 'Macro ROC value': 0.8704209750988297}\n","Training Epoch Loss after 73 is 136.8399983420968\n","{'Validation Epoch Loss': 38.46593353897333, 'Epoch': 73, 'Micro F1': 0.8357626329549117, 'Patience Count': 0, 'Best Val F1': 0.8357626329549117, 'Best Val Loss': 38.46593353897333, 'Micro ROC value': 0.89596956673513, 'Macro ROC value': 0.89596956673513}\n","Training Epoch Loss after 74 is 135.93132377415895\n","{'Validation Epoch Loss': 38.60772208869457, 'Epoch': 74, 'Micro F1': 0.837085147420713, 'Patience Count': 0, 'Best Val F1': 0.837085147420713, 'Best Val Loss': 38.46593353897333, 'Micro ROC value': 0.8959836887421465, 'Macro ROC value': 0.8959836887421465}\n","Training Epoch Loss after 75 is 135.4323404431343\n","{'Validation Epoch Loss': 38.28124541044235, 'Epoch': 75, 'Micro F1': 0.8393848389192728, 'Patience Count': 0, 'Best Val F1': 0.8393848389192728, 'Best Val Loss': 38.28124541044235, 'Micro ROC value': 0.895928464928389, 'Macro ROC value': 0.895928464928389}\n","Training Epoch Loss after 76 is 134.87122314423323\n","{'Validation Epoch Loss': 37.73173286020756, 'Epoch': 76, 'Micro F1': 0.834798246197451, 'Patience Count': 0, 'Best Val F1': 0.8393848389192728, 'Best Val Loss': 37.73173286020756, 'Micro ROC value': 0.8990956801065263, 'Macro ROC value': 0.8990956801065263}\n","Training Epoch Loss after 77 is 134.20521560311317\n","{'Validation Epoch Loss': 37.82520446553826, 'Epoch': 77, 'Micro F1': 0.8397301763523158, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 37.73173286020756, 'Micro ROC value': 0.8999109149741057, 'Macro ROC value': 0.8999109149741057}\n","Training Epoch Loss after 78 is 132.8874714486301\n","{'Validation Epoch Loss': 37.4730416610837, 'Epoch': 78, 'Micro F1': 0.8370288702094024, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 37.4730416610837, 'Micro ROC value': 0.9009838713294596, 'Macro ROC value': 0.9009838713294596}\n","Training Epoch Loss after 79 is 132.18024884164333\n","{'Validation Epoch Loss': 37.387538492679596, 'Epoch': 79, 'Micro F1': 0.8355093855040134, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 37.387538492679596, 'Micro ROC value': 0.9013534889631132, 'Macro ROC value': 0.9013534889631132}\n","Training Epoch Loss after 80 is 131.75813515484333\n","{'Validation Epoch Loss': 37.291859064251184, 'Epoch': 80, 'Micro F1': 0.8385023099237188, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 37.291859064251184, 'Micro ROC value': 0.9027699756829347, 'Macro ROC value': 0.9027699756829347}\n","Training Epoch Loss after 81 is 131.01275765895844\n","{'Validation Epoch Loss': 37.077078711241484, 'Epoch': 81, 'Micro F1': 0.8386941640531871, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 37.077078711241484, 'Micro ROC value': 0.9041568440788514, 'Macro ROC value': 0.9041568440788514}\n","Training Epoch Loss after 82 is 130.51423397287726\n","{'Validation Epoch Loss': 36.644433952867985, 'Epoch': 82, 'Micro F1': 0.8381953433165695, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.9058876296395513, 'Macro ROC value': 0.9058876296395513}\n","Training Epoch Loss after 83 is 139.08547047525644\n","{'Validation Epoch Loss': 38.90052172541618, 'Epoch': 83, 'Micro F1': 0.8104737006359325, 'Patience Count': 1, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.8757607400541019, 'Macro ROC value': 0.8757607400541019}\n","Training Epoch Loss after 84 is 134.0459477417171\n","{'Validation Epoch Loss': 37.75877400115132, 'Epoch': 84, 'Micro F1': 0.8225221399665407, 'Patience Count': 2, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.887740600081136, 'Macro ROC value': 0.887740600081136}\n","Training Epoch Loss after 85 is 132.34250981360674\n","{'Validation Epoch Loss': 37.76338444277644, 'Epoch': 85, 'Micro F1': 0.813095707071999, 'Patience Count': 3, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.882399572612984, 'Macro ROC value': 0.882399572612984}\n","Training Epoch Loss after 86 is 130.62930236011744\n","{'Validation Epoch Loss': 37.704497404396534, 'Epoch': 86, 'Micro F1': 0.817293475424765, 'Patience Count': 4, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.8827470643105482, 'Macro ROC value': 0.8827470643105482}\n","Training Epoch Loss after 87 is 131.04011369496584\n","{'Validation Epoch Loss': 37.7676883302629, 'Epoch': 87, 'Micro F1': 0.825786218222561, 'Patience Count': 5, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.8885955339139244, 'Macro ROC value': 0.8885955339139244}\n","Training Epoch Loss after 88 is 129.8098283931613\n","{'Validation Epoch Loss': 37.0609641186893, 'Epoch': 88, 'Micro F1': 0.8187311023682474, 'Patience Count': 6, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.8851478880619644, 'Macro ROC value': 0.8851478880619644}\n","Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n","Training Epoch Loss after 89 is 125.17315843701363\n","{'Validation Epoch Loss': 36.712035946547985, 'Epoch': 89, 'Micro F1': 0.8279682391883803, 'Patience Count': 7, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.644433952867985, 'Micro ROC value': 0.8919918385352231, 'Macro ROC value': 0.8919918385352231}\n","Training Epoch Loss after 90 is 124.68179668113589\n","{'Validation Epoch Loss': 36.633193876594305, 'Epoch': 90, 'Micro F1': 0.8288942551199472, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.633193876594305, 'Micro ROC value': 0.8921071492795307, 'Macro ROC value': 0.8921071492795307}\n","Training Epoch Loss after 91 is 124.4734424315393\n","{'Validation Epoch Loss': 36.61187353357673, 'Epoch': 91, 'Micro F1': 0.8296284169220458, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.61187353357673, 'Micro ROC value': 0.8927655849004492, 'Macro ROC value': 0.8927655849004492}\n","Training Epoch Loss after 92 is 124.33414819464087\n","{'Validation Epoch Loss': 36.6451986245811, 'Epoch': 92, 'Micro F1': 0.8296437652524032, 'Patience Count': 1, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.61187353357673, 'Micro ROC value': 0.8925167690207403, 'Macro ROC value': 0.8925167690207403}\n","Training Epoch Loss after 93 is 124.17667884379625\n","{'Validation Epoch Loss': 36.597450133413076, 'Epoch': 93, 'Micro F1': 0.829682136078297, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.597450133413076, 'Micro ROC value': 0.8928078194271916, 'Macro ROC value': 0.8928078194271916}\n","Training Epoch Loss after 94 is 124.06061892583966\n","{'Validation Epoch Loss': 36.58995517715812, 'Epoch': 94, 'Micro F1': 0.8295695816556755, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.58995517715812, 'Micro ROC value': 0.8929838726627519, 'Macro ROC value': 0.8929838726627519}\n","Training Epoch Loss after 95 is 123.94462598487735\n","{'Validation Epoch Loss': 36.55999509617686, 'Epoch': 95, 'Micro F1': 0.8297153907940713, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.55999509617686, 'Micro ROC value': 0.8931099251714314, 'Macro ROC value': 0.8931099251714314}\n","Training Epoch Loss after 96 is 123.85658798739314\n","{'Validation Epoch Loss': 36.560319390147924, 'Epoch': 96, 'Micro F1': 0.8294774916735309, 'Patience Count': 1, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.55999509617686, 'Micro ROC value': 0.8931780700448902, 'Macro ROC value': 0.8931780700448902}\n","Training Epoch Loss after 97 is 123.7408649995923\n","{'Validation Epoch Loss': 36.52317436784506, 'Epoch': 97, 'Micro F1': 0.8295312108297819, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.52317436784506, 'Micro ROC value': 0.8933795234994043, 'Macro ROC value': 0.8933795234994043}\n","Training Epoch Loss after 98 is 123.67187888920307\n","{'Validation Epoch Loss': 36.51814832165837, 'Epoch': 98, 'Micro F1': 0.8294800497285904, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.51814832165837, 'Micro ROC value': 0.8933533322859769, 'Macro ROC value': 0.8933533322859769}\n","Training Epoch Loss after 99 is 123.57432278618217\n","{'Validation Epoch Loss': 36.49463392049074, 'Epoch': 99, 'Micro F1': 0.8294314466824585, 'Patience Count': 0, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8935330996762226, 'Macro ROC value': 0.8935330996762226}\n","Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n","Training Epoch Loss after 100 is 123.22190808877349\n","{'Validation Epoch Loss': 36.532986242324114, 'Epoch': 100, 'Micro F1': 0.8304367623208723, 'Patience Count': 1, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8942191687598202, 'Macro ROC value': 0.8942191687598202}\n","Training Epoch Loss after 101 is 123.15855929628015\n","{'Validation Epoch Loss': 36.55611126869917, 'Epoch': 101, 'Micro F1': 0.8306695453312936, 'Patience Count': 2, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8944666763189377, 'Macro ROC value': 0.8944666763189377}\n","Training Epoch Loss after 102 is 123.13799004256725\n","{'Validation Epoch Loss': 36.56675750017166, 'Epoch': 102, 'Micro F1': 0.830843493075345, 'Patience Count': 3, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8945818654634032, 'Macro ROC value': 0.8945818654634032}\n","Training Epoch Loss after 103 is 123.12545656785369\n","{'Validation Epoch Loss': 36.570764414966106, 'Epoch': 103, 'Micro F1': 0.8310097666542174, 'Patience Count': 4, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8946465334137704, 'Macro ROC value': 0.8946465334137704}\n","Training Epoch Loss after 104 is 123.11481008678675\n","{'Validation Epoch Loss': 36.57139616832137, 'Epoch': 104, 'Micro F1': 0.8310992985813027, 'Patience Count': 5, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8946884559899977, 'Macro ROC value': 0.8946884559899977}\n","Training Epoch Loss after 105 is 123.10496889799833\n","{'Validation Epoch Loss': 36.57037669420242, 'Epoch': 105, 'Micro F1': 0.831145343572375, 'Patience Count': 6, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8947199454280368, 'Macro ROC value': 0.8947199454280368}\n","Training Epoch Loss after 106 is 123.09571529179811\n","{'Validation Epoch Loss': 36.568557392805815, 'Epoch': 106, 'Micro F1': 0.8311990627286262, 'Patience Count': 7, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8947464398754263, 'Macro ROC value': 0.8947464398754263}\n","Training Epoch Loss after 107 is 123.0867744795978\n","{'Validation Epoch Loss': 36.56636879593134, 'Epoch': 107, 'Micro F1': 0.8312399916095794, 'Patience Count': 8, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8947700466308606, 'Macro ROC value': 0.8947700466308606}\n","Training Epoch Loss after 108 is 123.07798230275512\n","{'Validation Epoch Loss': 36.563966542482376, 'Epoch': 108, 'Micro F1': 0.8312578979949965, 'Patience Count': 9, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8947909352352239, 'Macro ROC value': 0.8947909352352239}\n","Training Epoch Loss after 109 is 123.06941416114569\n","{'Validation Epoch Loss': 36.561518136411905, 'Epoch': 109, 'Micro F1': 0.8312809204905325, 'Patience Count': 10, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948104306831146, 'Macro ROC value': 0.8948104306831146}\n","Training Epoch Loss after 110 is 123.06089543178678\n","{'Validation Epoch Loss': 36.558937072753906, 'Epoch': 110, 'Micro F1': 0.8313039429860688, 'Patience Count': 11, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948289844946002, 'Macro ROC value': 0.8948289844946002}\n","Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n","Training Epoch Loss after 111 is 123.00340975821018\n","{'Validation Epoch Loss': 36.55836361646652, 'Epoch': 111, 'Micro F1': 0.831309059096188, 'Patience Count': 12, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948327785117587, 'Macro ROC value': 0.8948327785117587}\n","Training Epoch Loss after 112 is 123.00228396058083\n","{'Validation Epoch Loss': 36.55781275033951, 'Epoch': 112, 'Micro F1': 0.8313218493714859, 'Patience Count': 13, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948351618738983, 'Macro ROC value': 0.8948351618738983}\n","Training Epoch Loss after 113 is 123.00119037553668\n","{'Validation Epoch Loss': 36.55731198191643, 'Epoch': 113, 'Micro F1': 0.8313295235366646, 'Patience Count': 14, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948362230291663, 'Macro ROC value': 0.8948362230291663}\n","Training Epoch Loss after 114 is 123.00020617246628\n","{'Validation Epoch Loss': 36.556811813265085, 'Epoch': 114, 'Micro F1': 0.8313244074265455, 'Patience Count': 15, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948368842962011, 'Macro ROC value': 0.8948368842962011}\n","Training Epoch Loss after 115 is 122.99922102689743\n","{'Validation Epoch Loss': 36.55632986873388, 'Epoch': 115, 'Micro F1': 0.831314175206307, 'Patience Count': 16, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948372698139009, 'Macro ROC value': 0.8948372698139009}\n","Training Epoch Loss after 116 is 122.99823470786214\n","{'Validation Epoch Loss': 36.55587977543473, 'Epoch': 116, 'Micro F1': 0.8313013849310092, 'Patience Count': 17, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948371826876338, 'Macro ROC value': 0.8948371826876338}\n","Training Epoch Loss after 117 is 122.99734397232533\n","{'Validation Epoch Loss': 36.555437080562115, 'Epoch': 117, 'Micro F1': 0.8312937107658305, 'Patience Count': 18, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948370472669507, 'Macro ROC value': 0.8948370472669507}\n","Training Epoch Loss after 118 is 122.99641687422991\n","{'Validation Epoch Loss': 36.5550316311419, 'Epoch': 118, 'Micro F1': 0.8312911527107709, 'Patience Count': 19, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948368787338361, 'Macro ROC value': 0.8948368787338361}\n","Training Epoch Loss after 119 is 122.99555112048984\n","{'Validation Epoch Loss': 36.554656729102135, 'Epoch': 119, 'Micro F1': 0.8312809204905325, 'Patience Count': 20, 'Best Val F1': 0.8397301763523158, 'Best Val Loss': 36.49463392049074, 'Micro ROC value': 0.8948367631413483, 'Macro ROC value': 0.8948367631413483}\n","Testing stats.\n","\n","\n","\n","{'Micro F1': 0.875380344427366, 'Micro Recall': 0.875380344427366, 'Micro Precision': 0.875380344427366, 'Micro ROC_AUC_Score': 0.9426370384580317, 'Macro ROC_AUC_Score': 0.9426370384580317}\n","\n","\n","\n","\n","Average Statistics\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRYLzARVJI19","executionInfo":{"status":"ok","timestamp":1617351037584,"user_tz":-330,"elapsed":1280,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"c7a56a08-92f9-451c-84e6-b70eea288066"},"source":["average[\"avg_test_micro_f1\"] = average[\"avg_test_micro_f1\"]/5\n","average[\"avg_test_loss\"] = average[\"avg_test_loss\"]/5\n","average[\"avg_test_micro_recall\"] = average[\"avg_test_micro_recall\"]/5\n","average[\"avg_test_micro_precision\"] = average[\"avg_test_micro_precision\"]/5\n","average[\"avg_test_micro_roc_auc_score\"] = average[\"avg_test_micro_roc_auc_score\"]/5\n","\n","\n","print(average)\n","time_taken = (end - begin)\n","print(f\"Time taken is :{time_taken}\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["{'avg_test_micro_f1': 0.828780728737069, 'avg_test_loss': 50.416387795470655, 'avg_test_micro_recall': 0.828780728737069, 'avg_test_micro_precision': 0.0, 'avg_test_micro_roc_auc_score': 0.8960074549366072}\n","Time taken is :7868.1227695941925\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":809},"id":"jBxumZR9m0Ys","executionInfo":{"status":"ok","timestamp":1617353212556,"user_tz":-330,"elapsed":2032,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"182a5735-ffb8-4852-a845-35e73cf7b126"},"source":["import matplotlib.pyplot as plt\n","\n","plt.title(\"Validation accuracy vs epoch\")\n","colors = [\"red\",\"blue\",\"green\",\"orange\",'purple']\n","for i in range(0,5):\n","  x_axis = np.arange(len(val_acc_fin[i]))\n","  y_axis= val_acc_fin[i]\n","  plt.plot(x_axis, y_axis, color = colors[i],label=str(i));\n","  plt.legend()\n","plt.savefig(\"/content/drive/My Drive/graph/Protein/Val_accuracy.png\")\n","plt.show()\n","\n","plt.title(\"Validation f1 score vs epoch\")\n","colors = [\"red\",\"blue\",\"green\",\"orange\",'purple']\n","for i in range(0,5):\n","  x_axis = np.arange(len(val_f1_fin[i]))\n","  y_axis= val_f1_fin[i]\n","  plt.plot(x_axis, y_axis, color = colors[i],label=str(i));\n","  plt.legend()\n","plt.savefig(\"/content/drive/My Drive/graph/Protein/Val_f1_score.png\")\n","plt.show()\n","\n","\n","plt.title(\"Validation roc_auc score vs epoch\")\n","colors = [\"red\",\"blue\",\"green\",\"orange\",'purple']\n","for i in range(0,5):\n","  x_axis = np.arange(len(val_roc_auc_fin[i]))\n","  y_axis= val_roc_auc_fin[i]\n","  plt.plot(x_axis, y_axis, color = colors[i],label=str(i));\n","  plt.legend()\n","plt.savefig(\"/content/drive/My Drive/graph/Protein/Val_roc_auc_score.png\")\n","plt.show()\n"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU1fn/38/s2ROysAUI+y4qi6JoQRRx+Wm1VcFK1Vpxr6i1rVardatL69K6+61V64JWWxcUXFFRlE0RBJQdEtZAyJ5JZjm/P86dmTuTBAIkJITzfr3mNfeec+69585kPvfJc57zHFFKYTAYDIb2i6O1O2AwGAyGlsUIvcFgMLRzjNAbDAZDO8cIvcFgMLRzjNAbDAZDO8cIvcFgMLRzjNAbGkVElIj0sbafFJFbm9J2H67zCxH5YF/7uYdzXyEi20SkUkSyW+Iaht0jImNFpKi1+3EoY4S+HSMis0TkjgbKzxSRrSLiauq5lFKXK6XubIY+FVgPhei1lVIvKaUm7O+5G7iWG3gQmKCUSlVK7RSRO0VkqYgEReT25r6mwdAWMULfvnkeuEBEJKF8CvCSUirYCn06kHQEfMAyW9lq4HfAu63SIxt786A1GPYHI/TtmzeBbOC4SIGIZAGnAy+IyCgR+UpESkVki4g8KiKehk4kIs+JyF22/RutYzaLyK8S2p4mIt+KSLmIFCZYzp9b76WWO2W0iFwkIl/Yjj9GRBaISJn1foyt7lPLKv9SRCpE5AMRyWmgv/2AH23X+gRAKfW8UmomULGnD8/6fBZa97FNRB601Y0RkbnWZ1coIhdZ5Rki8oKIFIvIBhG5RUQcVt1FVr8fEpGdwO0i4hWRv4rIRusaT4pIUgN98VrXGmIryxWRGhHJE5EcEZlhtSkRkTmR6zZwrgEi8qHV7kcROddW95zVhw+tz/czEenRxO+mg4j8y/qb2CUibyZc9wYR2W793Vy8p8/f0IwopcyrHb+AZ4D/s+1fBiy2tocDRwMuoABYAUyztVVAH2v7OeAua3sisA0YAqQALye0HQsMRRsSh1ltf2rVFVhtXbbrXAR8YW13AHah/+twAZOt/Wyr/lNgDdAPSLL2723k3utdy1b3InD7Hj67r4Ap1nYqcLS13QP9oJgMuNEP08OtuheAt4A06/orgUts9xkErrHuLQl4CHjbuu804B3gL43051ngbtv+VcAsa/svwJNWf9zoh7s0cI4UoBC42OrDEcAOYJDte64Ajge8wCN78d28C7wKZFl9+Int7yEI3GGVnwpUA1mt/fs4VF6t3gHzauEvGMYApYDP2v8SuK6RttOA/9n2GxP6Z+3iaolutG0D530YeMjarie+xAv9FGB+wvFfARdZ258Ct9jqroyIXQPXrXctW11ThP5z4M9ATkL5TfbPyVbuBOoiommVXQZ8arvPjbY6AaqA3ray0cC6RvpzIrDGtv8l8Etr+w70A6bB78B2zHnAnISyp4DbbN/zdFtdKhACuu3uuwE6A+GGxNsS+pqE73w71oPTvFr+ZVw37Ryl1Bdoi+2nItIbGIW2wBGRfta/+1tFpBy4B6jnBmmALmirMMIGe6WIHCUisy33RRlweRPPGzn3hoSyDUBX2/5W23Y1WoxagkvQD7EfLDfF6VZ5N/R/FYnkoC1We/8T+27/3HKBZGCR5XIpBWZZ5Q0xG0i2Pt8C4HDgf1bdA+jxhw9EZK2I/KGRc/QAjopcz7rmL4BODfVRKVUJlKC/l919N92AEqXUrkauu1PFjwm15PdmSMAI/aHBC8AvgQuA95VS26zyJ4AfgL5KqXTgZrSVuSe2oH/YEbon1L+Mdkd0U0ploF0KkfPuKV3qZrQY2ekObGpCv5oVpdQqpdRkIA+4D3hdRCKuj94NHLIDCBDf/8S+q4T2NcBgpVSm9cpQSjUogEqpEPAa2mUyGZihlKqw6iqUUjcopXoBZwDXi8j4Bk5TCHxmu16m0hFJV9jaRL9bEUlFu2w2s/vvphDoICKZDfXd0LoYoT80eAH9b/+l6EicCGlAOVApIgOAKxo4tiFeAy4SkUEikgzcllCfhrbu/CIyCjjfVleM/he/VyPnfg/oJyLni4hLRM4DBgEzmti33SIibhHxof/2XSLiExFnI20vEJFcpVQY7f7C6vtLwIkicq7Vx2wROdwmxHeLSJo1iHk92k1UD+u8zwAPiUiedc2uInLybm7hZbT75RfWdqSvp4tIHxERoAztbgk3cPwM9Oc7xfos3CIyUkQG2tqcag02e4A7ga+VUoXs5rtRSm0BZgKPi0iWdd7jd3MfhgOIEfpDAKXUemAueiDubVvVb9EiXIEWnFebeL6ZaL/7J2h3wScJTa4E7hCRCuBPaPGLHFsN3A18abkOjk449050VNANwE50KOTpSqkdTelbE3gGbUVPBv5obU9ppO1EYJmIVKIHJScppWqUUhvRA4o3oN0ai4Fh1jHXoP3ua4Ev0GL87G7683v0Z/i15T77COjfWGOl1Dzr/F3Qwhqhr3VsJdpv/rhSanYDx1cAE4BJaAt9K/q/Fa+t2cvoh3cJesD+AuvYPX03U9D/0fyA9sFP2819Gw4gopRZeMRgMGhE5DmgSCl1S2v3xdB8GIveYDAY2jlG6A0Gg6GdY1w3BoPB0M4xFr3BYDC0c9pcUqWcnBxVUFDQ2t0wGAyGg4pFixbtUEo1ONmuzQl9QUEBCxcubO1uGAwGw0GFiCTOWo5iXDcGg8HQzjFCbzAYDO0cI/QGg8HQzjFCbzAYDO0cI/QGg8HQzjFCbzAYDO0cI/QGg8HQzmlzcfQGw/4SDMKuXVBdrV+hEITDoJR+t283d1lLnjuxrDnxeOCPf2zecxraDkboDW2SL76AmTOhuFi/qqogKQlSUqCiQou5zwdeb+xVWamP27RJi6Gh6aSmGqFvzxihN7Q5/vMfOPdccDggN1e/UlNh+3Yt+Ckp4HZDbW38y+2G0aOhf3/Iy9PtkpLA5QIRfT6HI7Z9IMpa6tzSlAUfDQYLI/SGA0ZpKRQVweDBuxeqWbO0uK9fD8nJB6x7BkO7xQzGGlqEykpYtSrmV66pgRNOgCOOgEGD4IYbGj9240bo1cuIvMHQXBihN+w1330Hy5c3XLd1K7zzDgwdCv36wVlnQbduMHw4fPutdsH88AM8+CDMm9fwOTZsgO7dW67/BsOhhhF6w15z/vlwySV6OxQCv1+L9/TpWtTPOENb8RdcAG+9BZs3w4oVcMstsGgRLFwI2dlw3331z62Utuh79Diw92QwtGeMj96wV5SUaGve44Gnn4Zrr9URMMGgrh82DO69V7tpAgGYPRtOPhmuvFK7bRyWaXHJJfDXv2rr3S7q27frgVVj0RsMzUeThF5EJgKPAE7g/5RS9ybUdweeBzKtNn9QSr0nIgXACuBHq+nXSqnLm6frhgOBUvEDpxF3S10dXHaZ9refcQYMGaKjXMaNg4wM3cbj0Za+16sjYuxcdRX8/e9w9dXw5pv6OsuX6wcFGKE3GJqTPQq9iDiBx4CTgCJggYi8rZSye2lvAV5TSj0hIoOA94ACq26NUurw5u22oaUIh2NW95//DLffDiedBDfeqKNgpk6Nb//559oN0xipqQ2Xd+8O99wD118PI0fCzp3aZWOvNxgMzUNTLPpRwGql1FoAEZkOnAnYhV4B6dZ2BrC5OTtpODBs3Ag/+Qmcdhqkp+tBVYC5c2HCBL2dmQkXXqjbnnLK7kV+T0ybpn36116rHzBeL1x0kb720KH7fTsGg8GiKULfFSi07RcBRyW0uR34QESuAVKAE211PUXkW6AcuEUpNSfxAiIyFZgK0N2Ycq2CUnqQdf16eOyxWPn11+tB1PnzYfFi7XJpzErfW0Tg5z+H00/Xg7oieoKTmQxkMDQvzRV1Mxl4TimVD5wK/FtEHMAWoLtS6gjgeuBlEUlPPFgp9bRSaoRSakRuboNr2xpakJoa7ab58kvtqhk9OlZ3xBGQlaUHVH//++YTeTs+n/bvJycbkTcYWoKmCP0moJttP98qs3MJ8BqAUuorwAfkKKVqlVI7rfJFwBqg3/522rD/hMPadfLVV/DAA1roBw+Gm2/WrpoIh5vRFYPhoKcprpsFQF8R6YkW+EnA+QltNgLjgedEZCBa6ItFJBcoUUqFRKQX0BdY22y9N+wzH3wAjzwCS5dqt0m3bto9E4mOefddPalpwIDW7afBYNh/9mjRK6WCwNXA++hQydeUUstE5A4ROcNqdgNwqYh8B7wCXKSUUsDxwBIRWQy8DlyulCppiRs51FFhhb/UT1Vx1R7bvv++tuYBBg6Er7+Gc86JTzlw6qnw0Uc6IZjBYDi4adLPWCn1Hjpk0l72J9v2cuDYBo57A3hjP/to2AOLnl7Ehzd+iC/TR9nGMm7ccSNf3vcl5YXlbEwdSEmnQdx+Ozz7rJ7ANH06FBToY7/5Rk9QOv741rwDg8HQkhh77SBDKZ0wLC1N76//bD0zLpsBQG15LQAP5DwQbR9iOXcxkH79hKlTtdX+m9/AX/4CHTtCoRVP1avXAb0Ng8FwADFCf5Dg98OZZ2qRX7AAnrtlNUcMCfDmhW+S3T+bQHWA8sJyCsYVsH72elbTm7X0YgIf4qGOG27wMmSITkgWmRDldGprHurPXDUYDO0HI/QHCW+/rQdQAXp3D7LqtpdYZdWNuGIEmQWZfPfyCt5y/JSlrh/IGtYD/6IVAPiopbjYy113xUQetP89IvRO54G7F4PBcGAxQt+GqbLGVf/6Vx3fnp+vJzS99NulrHs41q5oi4vPawfwzDcDWL8eLr10ILfeCmf29kENePED6Zx6avz5Yxa9wukEFQZx6ED2is0VLHttGbvW7aJiUwX+XX4CNQGC/iDhQJhwMEw4FEaFlZ4XDSAgIvocAklZSVzy1SUt+REZDIYmYIS+DfLMM/Dpp/Daazqz45o1evD0hhu0OPs2rQEggAs3Qe65z8m36AfB7NkwZow+z0NPePnoIm3RY9UDBP1B5v19Hr8snkdyuAIBXhrgQByCJ9WDw+mgtryWoD+IN91LWpc0krKT8KR4SM5OxuF24HA5cDgdUVEXEVRYoZTS4g94Uj0H8mMzGAyNYIS+DfHEEzrlgN+v910uWLsmzNOPhbj0Sjc1u2r47y9msvb91QC40bmBu3RzcvdTMHFi/MzS7v28AFz5Kz89J8TK37/+fRY+sZBdvt4s9OsZUddeFibJGyZQHSAcCuP0OBl19Siy+2UjZrqqwXBQY4S+jRAO6+RegYBCUDzxpINTToH3Ln2LzVctQV3+J5a+tJSlLy+td+x9f3My+JT65/Rl+AA4/aRahpwHmxdu5o3Jb+Av89P31L688MP5rLWmr02/VS+obTAY2h9G6NsIs2frhTpuHfgG2ZRw1pif8uqJr1KySs8v2/HjDrZ8uyXaPj0/nfKicgBc3oa/Rm+Gtuh3/LADf6mfVTNXUbJan6/jsI44V8XamolRBkP7xSwluK8opXMHNBP33Qcdc0I4VyyjdMUWnhjyRFTkATbO2cjGz2MJ2/NH50e3nd6GQ2YiFv1nf/6MxwY9xtZvt0br8obmxYm7EXqDof1ihH5fuf56rY7h8H6f6tln4cMP4brJ2mL3pnujdck5yYhT+PHtHylZXcL4e8czbcM0snpnRds4PQ0LvTslFhxfuaWSrYttQj8kLy6k0oRXGgztFyP0+8rDVnzjfgr9sm9qef2Smfy/Y3ZydKcNAFzx/RWMu3Mc166/lt9u/y19T+nLmg90pE12v2wyumfEuWsac90kDqKWriuNbuf0zzkkLHqlFM8vfp6p70zFH/S3dncMhlahnf68W5iamti2JfTFy4uZc/ccTn/q9CaHFYZDYV49+1WOYh2HHeZk4+xt5A7KJaNbBsffEks+k9Uni/AMfZ3Mgkwg3l3TmEXfEFM+mkKnYZ1wepxxVnx7FfpbZ9/K3XPuBmBu4VzuPfFeTu93OgBhFebWT25ll38XN425iZAKUZBZ0Iq9NRhahnb6825hvv46th0OE6wN8vjgxwE46tqj6DqqKzt36mX3ducSmffIPJwb1gFQsriQzYs2c/S0o+u169C7Q3Q7s4cWersV35iPviF6jusZnRRlF3fHQfK/3YJNC1i0ZRFd07oyJG8IPTJ74JBY599b9R5PLnySu064ixkrZ3D3nLv59RG/pmNqR+6eczc/e+1n/GbUb1iyfQkfrf2IsArjFCdPLXqKsArz8tkvM3noZHZU72Dh5oUs276M8tpyKusq6ZbRjWlHT2vFuzcY9g0j9PtCUVFsOxymdGPMJRKsDaIUdOqkF/L4+OP666rWlteyaf4mFj79DesooNfwLIq+/haAvqf1rXe5iD/ek+rBl6UHWO1WfGOum0SOuvaoqMhD7CHkdLaNlZ3qQnU8v/h5LjjsApLcSfXqH1/wONfMvIawirnLUtwpHN/jePpn92dZ8TI+XPshAO+s1Avenj3wbJ48/UmcDifTjp7GmGfH8PC8h+ma1pUrR1zJYR0PY1zPcdzyyS28uuxVLptxGXfNuYvlxcvjrh25jhF6w8GIEfp9oaIith3W6QAiBP1Btm2DYFAnEMvNhWXLdN73CPP+MY/Zt8wGYD2DGXVYKsWLviWpQxLdj62/Zm7Eos8syIz63ffWdXNz1c24kuK/7ohFfyDdNu+ufJf5m+YzdfhUOqd15oM1H7CxbCNTh0/ltx/8ln/M/wchFeLyEZfHHfePef/gN7N+w+n9TufRUx5lc8Vmvt/+PUu3L+W1Za/x6fpP6ZXVi65pXXnq9KfYUrmFgswCxhWMw+nQn09Ocg7Lr1qOIPXGL6b/fDp3nXAXf/zkj1TUVnDB0AsY3W00h3U8jExfZtx/DQbDwYYR+n2hvDy23YDQRyYhTZwIs2bptVjtQr/p69hKjFvpRP8zupJVvIoJD07A4aovKJkFmYhDyOiRES1rquvmiqVX4C/z406un54yYtG3hNAHw0Gq6qpYV7qO7VXbObbbsTww9wH+/NmfAZi+bDo7qndQUqNDSLdUbOHR+Y8CsHDzQl5f/jolNSVMHjKZW2ffyiPzHuGUPqfw5nlv4nQ46ZHZg9Hd9OK2D098GKVUVNB3x+4Eu0+HPrz681f399YNhjaHEfp9IcGiDwVi8fRBf5A1q8MIwoMPCl99BYsWwa9/reuVUmxaYBf6zvQbnsb4n05u9HJOj5Oe43tSMLYgrqyh7UTyhjQ+3TUi8M0dWllYVshZr57F0u1LqQvVAXBYx8NYsm0JZw88mxGdR3DzJzeT5EpiymFT+PeSf3P7Z7dzcu+T8Qf9fLLuE9768S0q6yp5Z+U7zFg5gyF5Q3j8tMcbFHOHOKANuJ4MhrZKk/4fFZGJIvKjiKwWkT80UN9dRGaLyLciskRETrXV3WQd96OInNycnW81bBb9uzd8wpy750T3g/4gay+5h8t4ip494Ygj9CpO0UOLyqnaFlvur8qZTpcue77klA+mcMxvj4nu2634pvroE2kJi35j2UbGPj+WVSWrOHfwuVx39HUALNm2hHRvOq+f8zpXj7qa4Z2H8/xPn+fZM5+NHnvfifdxcu+TWVe6jh3VO/AH/cxYOYMHTnqApVcsNRExBsM+ssefuIg4gceAk4AiYIGIvG0tHxjhFvRask+IyCD0soMF1vYkYDDQBfhIRPoppZpvSmlLU1Gh19779a9jI5aWRf977iX52fjcM0F/EIIhOrENnw+OPBIee0ynN3C5FB/9/iMALpx9Ibf9LZ1uy2SfLOp9jbqJO0cz+ejDKkxlXSWXzbiM91e/T1iF+WjKR4zsOhKA+Zvm82XhlwzIGYCIkOZNY+HUhdHjT+h5Aj/u+JFhnYaRnZzNku1L8Dq9FJYX0i29GzeMvmH/OmgwHOI05Sc+ClitlFoLICLTgTMBu9ArIN3azgA2W9tnAtOVUrXAOhFZbZ3vq2boe8tSWakV8NxzYdYs/vO6sGVNNb9Z/ZuoRX8/v+d2/hx3WNAfjNsfPRoefFCvCtU/p4TvX/me4/54HAVjC1hzC3SvP/baJOzi3pBfv0nncMa/7wt1oTrOfvVs3l31LgAn9z6Ze8bfw5Gdj4y2GZgzkC8Lv6R/dv8GzzHrF7OikTT56fm88rNXAO3mMpkzDYb9pylC3xUotO0XAUcltLkd+EBErgFSgBNtx9qCzimyyuIQkanAVIDu+6p8zU1amh5BXaFXaVr+QcyvTkUFFaQ2eFhdVbzQjx2r3z/5BDoMLQag/xla8LZuhVGj9q17Eb+80+vcZzHcH4teKcU3W77h7jl38+6qdzms42GcP+R8fj/m9/XaDsgZEPeeiNvZ8DqGRuQNhuahubyzk4HnlFJ/E5HRwL9FZEhTD1ZKPQ08DTBixAi1h+YHDkvk61FeziKGN1hVuCp+mn1ODgwbpuPpx7p3AJDdXwfWb9umF+jeFyKum72ZFZvIvvroN5Ru4NzXz2X+pvkA/P7Y33Pvifc22n5grg45asyiNxgMLUtTfuKbgG62/XyrzM4lwEQApdRXIuIDcpp47MFHRQWLGNNg1cYVlfXKRo7Ua77uLNhJSqdUfnOjjzvv1N6hTp32rQsR182+DsTC3lv0VXVVhFWYE144gZ3VO3nitCfIS8njjP5n7Pa4k3qdxIMTHoymHjAYDAeWpvzEFwB9RaQnWqQnAecntNkIjAeeE5GBgA8oBt4GXhaRB9GDsX2B+c3U99ajvJwyMhqsKtlQRUpCWU4OlJRA8Q87qPDm8MwzMWt6Xy16u+tmX9mTj77UX0p5bTlKKabOmMrHaz9mbMFY1peu57OLPmNM94Yfdom4nW6uG33dPvfTYDDsH3sUeqVUUESuBt4HnMCzSqllInIHsFAp9TZwA/CMiFyHHpi9SCmlgGUi8hp64DYIXHVQRdw0RkUFAW8q1lKscdSW1Bf6Dh30TNmdK3fi6DkINsDKlbquNV03u7PoawI1DHtyGBvLNtIptRPbKrehUHy87mOmHDalySJvMBhanyb9066Ueg8dMmkv+5NtezlwbCPH3g3cvR99bFsopYU+NZWk2qp61U5/fddNdjYICv+uGtxH6sdAZPZsp4Uz4JS9d2k0h+umIR/9G8vf4L8//JeXl74cLdtauZU5F8/hxSUv8tSip7hm1DX7fE2DwXDgMTNj9xJVUYkoRcCTQhI18ZUOITVcX+g7dAAPdaBAfHpRkfXrdV3HL/8L7L3QN6dFHxH877d/z8//83MARnUdxflDzufZxc+SnZTNmO5j6J/dn/E9x0fj4w0Gw8GBEfq9JLRjFy4g4EnGR8JCFh4PTr/250Ri28OhMGlOP1502KWf2OpRQpjcySeyLzSHj74o6V0YN49NPcr5dsuF/O2rv+F2uHlz0puc1Osk3E43Fx9xMU7R18hNyeWcwefs8/UMBkPrYIS+IVTjEZ5vvhHiaLoScCXjTXDSV/g9pFllkWX8Zk2bxYJHF5CKTnbjD/ui7bPZifusfYtE2R/XzRcbv+CReY8wI+N1OM7BNuXmyKcfAeCmMTdxat9oBgvSvemNncZgMBwkGKGPUFICGRnajxEMNtrswt/lMYC3GOqsqCf0tXhIs7YjFvfify0GIJlqAKpCsdWnjuixC9L77VN3oxb9Xrhu1pSsYfIbk1mweQGZvkyOqr2ZefffxuifVNPtisspri7mtp/ctk/9MRgMbReTZBvA79cjpldfrfd3I/ROQpSRQVDcDQh9zC2jQvq/gkB1ACDqz6/aEXP3jLmw1z53WURwuB1Ndt0UVxXzly/+woLNC7hz3J1sun4TPwndDSEPPjKZ/vPpfPzLj/G6vHs+mcFgOKgwQg9Qp1Pp8sIL+j0QaLSpixDd2UhAPHqA1X4aYtZ6NHWx5QXK8GihryiODeAec9z+/UPl8rpwuB28uORFaoOxh45SijeWv0FhWSEzVs7gT7P/RP5D+fzz238y5bAp3HL8LSS7k1tl4RGDwXDgMT9xgJAWZVUXoHg75LniLfqQ7XnoxU83NlLBEXgpi2tnF/pwIBxX18FXA3VQvnEXAFlZcHT95WH3CqfXyZbaLdzwvxuorKuMrsr00dqPotEzdjqndub60dfHjm/BhUcMBkPbwfzEIeqqeTx4KVd3hOWfh7EtCEWhLYvD5TxNJcmU4K5n0YccHrD03b7qFECGS8fcl5LJaTlfM6N4P1UeCLvDLCzW6X7/s/w/XD7ictaUrOFfi/8FwB+P+yNuhxu3083g3MGcOeDMuONbauERg8HQtjBCD1Ghn804AJYslTihX0PvuOYpVBPAhYeYi0cB4nERibgMB8MoW/RO3+wSQiWwkFGc5/p0v7u8o3oHHxz2AZuyN5Hly+LT9Z/y5g9v8rPXfkZYhRlbMJa7Trhrt+cwFr3BcGhgfuIQFfoMyxVT/sPmuOpEoVcIAeUmxWbRh3GQ7NB+8rQuaVRsrogOyAL0TNrKCtwohLR+TVhSajdsrtjMZTMuY/Yxs3n0lEc5pe8pTHxxIme9ehYAXqeXa4+6do/nMT56Q5siHIRwLYT8EA6ACgNhK9w5bO0r/d7YdrR95LdnvSt7fTi2Ha6DYJV+JYZVx6XJTkyZ3UIptL3Z0PmkZj+t+YlDPaEvW7IhrrqIfJzE/gjCOAioeIs+jIMU0e6ZzJ6ZVGyuiFtL1l9SDejY+rThexdSGQgFeHfVuywvXs7kIZO58cMbeX/1+9w85mauGnUVAHMvmcvTi54mPz2fXw77ZZPO2xwLjxgMu8W/AxZcBv7tgGhBDVVbYl4LodrYdjtIg7XfZB9lhL7FsKJsokK/LX7Gqx8fKbZ0BxGhd9uEPoSTpLAW+qxeWRR+WRjnp68pD+ASByjweJtuDSilOO3l0/hw7YcAPDD3AUr9pVwz6hruHh9LIZSTnMPNx93c5POCsejbHaFaUEEtqsndQRwQrIDyH6FijRZSFYS6UlABqN0J7gwIlEN1EaR0A08W+LdBXZk+NlABwUot0OIAhwccbn2tQJm2iN2ZEPbrc7kzwZMBng7g9MK2z6D0O8g9VlvMSV3AlQwOLzh9uo3Tp/ftZQ43iBMQfV0cloXtsPatcvt23LsQs7qtd3HGjomc0+EGV2lP6FEAACAASURBVKruU1wQompkm91OqNxvnL49t9kHzE8coha9WF9o2c74qJtavA0IvRNXgkWvPF6ogYweOoWxfVnBmmrweRTUQqF9va498NLSl/hw7YfcO/5eTuh5AqP+Ty9JNWnIpL27xwYwPvo2SKASajZDbbEW3doSLcQAlWu0UNdsgbpdWnz922HXN1q4AhVaeAFSekLVeuqJlB1xavEXJyR1hZpNet/p04LtSgV3mn55cyyXR0C7VZxJkNQJxKX74krWD4eaIihbBnU79cPAmwOjnoJeF7XwB2fYHeYnDlGhj0x42rkzvtoeNgk63DIQduEmJuRhHGwecy6//dlagjW6vKYk9nDwB53k5DlhM+Tl7b47czbMYcWOFXy+4XNeWvoSR+cfzW+P+S1Oh5OtN2xl3qZ5jM4fva93G8VE3RxAwiGoLtSWc83mhl/Vm7UVvSccHvBkgitNW9Hdfq7LXCnamg4HYN0L0O8aSO4Caf0gra9ug4C3g2XJpmk3isMLDpd+UKgwuNMT/NOGgx0j9FBP6IvDHeKq7TNeQbtptEUfL/RJnTI44uIjWPTMIiBe6BUOsgZ04qMX9ILhjfH3eX/n2ll6IDXTl8ng3MG8fPbLOB1ajTumdtzjik5NxVj0zUw4qN0hoRot6BUrYed82P4ZVK6NWdsRHB7tykjqAhlDodPJWpiTumhLuG6Xfnena3dBSnctyt7sPQvx0CamsnDZVk9wpzXeznBQY37iEBX6iOW+nXiTu0GhD9UX+jTrdxLJXFmzMz6NsSMjlfHjG+5CSU0JN3xwA88tfo6zBpzF/SfdT8/MnlGBbwmMj34vUEq7UPxboWardp9UrILK1Xq7cp12laiE9BmuFOg4HvLPhNTe2nceEXNPB2M5Gw4I5icO9S16cuOqE4U+iItA2IGTWJRAGAcZltA73Vqc7Ra9vbwhbvnkFl5c8iLXHX0d9590Py5Hy381h7RFH6yCitXg66gFunKdFnH/Nu33jrxqi7WFHijT0SFxCCR30+focAR0PweSu1r+6y7aXZJSAC34sDYYmkKTfuIiMhF4BL2U4P8ppe5NqH8IrNlGkAzkKaUyrboQsNSq26iUah6/Q3NiRd1EBH07eQRx4rKEvLaej95FIOSIs+hDOGMWvVtb9NU7q+OOi1j6iZT6S3n+u+e54LALePDkB/f/fppIu/fRK6WFu3Jt/VfpEi3eiTg84MsDb55+T++vrXJXqh589HXW70mdtcgbd4fhIGCPQi8iTuAx4CSgCFggIm9bywcCoJS6ztb+GuAI2ylqlFKHN1+XW4AE100QN2vpRT9WxZVHCFhCn2jRJ7puqrbHLzUYeQAk8vry16kOVHPVyKv2/172gnZj0deVwq5voeRb/V7+o/Zv12zS1ngU0RZ3ai9tfeceq6NcUnvqV1IXPbhp3CmGdkZTfuKjgNVKqbUAIjIdOBO94HdDTAYOrqTmCa4bgBUMbFToQzgJJrhuFA66WSlxIi6aqm2NC71SipKaEjJ8Gbyx4g16ZfVieOfhzXdPTeCg9NEHq6DkGyhZCDsX6PeKVbH6pK6QMRjS+oDv/0Faby3sqb0gpUeLxSkbDG2ZpvzEuwL2yO8i4KiGGopID6An8Imt2CciC4EgcK9S6s0GjpsKTAXo3r1703renNiEvjerWUMffmAAZ/I2UF/oAQJBiRP6IcMcnGotzBS16BOEPvIAUErxi//+gle+f4V0bzrlteXceMyNyAG2JNv8zNiQH3YtgZIFMWEvX2FNX0e7TrJHQq+LIetI7Sf37SF21WA4BGluW24S8LpScXOZeyilNolIL+ATEVmqlFpjP0gp9TTwNMCIESNacNpZI9hcN7nsoIYkVtjSmgWs1AURHITpUrceB7GZr75kR/Q//ojlXrktfqFwh9tBbbCW6d9P55XvX2HykMmkedLwOD1MO3paS9zZbmlzFn31Jtj2KRTP0aJetlTHhIMW8A4jdcx49kjoMAKSOrZqdw2Gg4Wm/MQ3gS1PL+RbZQ0xCYhzNCulNlnva0XkU7T/fk39Q1sRm0XvdQYZEPqBH+kfrU606LtTxPnBF+PmHNoHWhtz3Wyr2Ub2/dlUBaoYkDOAl85+6YBb8XZa3UdfvRm2f6rFfdtsHaoI2k+ePRIG3GCJ+khIzje+c4NhH2nKT3wB0FdEeqIFfhJwfmIjERkAZAFf2cqygGqlVK2I5ADHAvc3R8ebFVvUTYbLT3qohK10ilYHG/mYdMoELT720MmI6Fduq8QnfvxK+4VnrJ1BVVct/ucNPq9VRR4OcNSNUlC1QVvr2+foSUQVK3WdOwPyfgL9roSO4/TkIROSaDA0G3sUeqVUUESuBt5Hh1c+q5RaJiJ3AAuVUm9bTScB05WKy/gzEHhKRMLojEH32qN12gw2i97jqsZTWxdnxSe6bhrCbtFHXDfhQJhkqcaPFvqSQAk3jbmJuYVzufTIS5vzDvaJFrXowyFtoZd8CzvnQeF/oXqjrnNnQO4Y6DNVC3vmMCPsBkML0qSfuFLqPeC9hLI/Jezf3sBxc4Gh+9G/A4PNR+91hfFSGxeB07jQxyzyOKG3baeoSkrQKRXCjjDTjp7GPePvacbO7zvN7qMv+RaKv4RNb8GOebG8LQ63nt4/8EbIOw4yhhhhNxgOIG1lGK51sfvo3WE8NN2iF4cOArGHTtrdOKnEBmQ7Z3YmL6XtRIXsl0WvwrDpXdjwip72X7kWSnSOH9L7Q88p2r+edTikD9SpZw0GQ6tghB7iXTeds/Hs+CHOoo/46CfwPp/IeIIq9rG53EKgVjVq0ScTG5Dt3zE2wNsW2Gsffd0uLea7lsDaZ3U6Wl9HnU7X0wGOfAjyf6rj1c3AqcHQZjBCDzHXTVZHvEfk4F36SbxFnz8firR17lKBuMFZt6cBobdZ96k2oR/Yyb4SbeuzW9dNoELHru/6DnYt1n728h9i9RlDYPS/ocd52jVjMBjaLEboIRZ1E3LjTSbOdRPEieOMqfD4VYQkjCNhuTOXW1uuDYVXAqTYhL4gp6Cl7mCfiLluwlDynY6EKf9Bx7CXLo5NTPJ11CGOPadA9ijIPMxMTDIYDiKM0EPMdVMHnmQXXmoJ4iaMUIsXCeiomRpPGGdtw0LfUHglQG1SOZHFqXaXvfKAosJQtoyOpbP577TZnOr+DGbt0nWeDpA1DAb/EXKOgawjzMQkg+Egxwg9xFw3deBNcuBBLxBRh4davDgCSQD43aqe0Dstr4W4bBE4NtfNu0Mr8M2PtG0loQ9WaRfMlg9gx1d6MYxAKV2AYT16skl+Sq/R43SoY3J+6/TRYDC0GEboAYJBgjgJhwWvl6jQ1+KlnDTGzjkGgBp3OC6/DYDDpaz3hgdjX/xJiF9bQt9Y9spmRykoWw5b3tev7Z/q1Y3EoX3r3c+B3GNQuWN5+58F/Op0IP3AdM1gMBx4jNADBIPRKBuvF7zUAtqin8PxDFhTAEC1p77Qi1sLvd1at29vStquw+1VC1j0dWVAWC+asf4lvZBGoEwn/vJv123SB0K/qyH3OB3D7s2O9R2YduBT7BgMhgOMEXrQQu9MgRB4PPEWfTWxNTVrPOG4xUYAxK0HLBuz6F847FbWuRyEA+FGFx7ZK0q/h8I3dDqBDa/qxZ1BryWa3k8v+NzlVMg5FjpP0OuMGgyGQxoj9ACBAHWuZAjVt+hDto/oq3xF3x3+6OAqgHKGACd+5UcphezahdpREq3/RcEZ3OOapYV+X1w3Kgwb/wOF/4Mdc6G6EBAdCdP1NOgwHLy50O0sHc9uMBgMCRihB8uiTwaI89HX4SEoLiJpKt/rH6afbOPYuX2ihypnCFeKlwe/e5CiBUVc9c8lzFg3C/gVAOLz4XBqgd8r141/O/zwIGyeBaXf6QU1csfoVZEKzo9zwRgMBsPuMEIPWuhd2kXj8cQs+lq8hIiJc9gRJuwIxx0akjAFzxUwf+F8stZmcdWmIH/ruZkJkQZeb9Rl0ySLvnwVrPy7dsvU7dKrJR3zEvSYpAdTDQaDYS8xQg8QDFLn1CGUiRZ9eE9C7wjiGuDCv8yPx+lhLuuY2yXIBKAzm+OFvjEfvQrDir/Cqie0793hhi6nwZBb9apJBoPBsB8YoQcIBql2pALg88UPxoawrfMqqgGLPkRdSLf3OD08mbeRzBq4+HduOt7/HHjvjAp8PdeNUrDtE/j+Dtj+OXQ6US+L12cqJHXCYDAYmgMj9ADBIFukMwCdO0O1MwShpln0fqmjvLYcALfTzczcck5dBd37VQB1jbtudsyH7/6gV1by5sJR/9Qib5KBGQyGZuaQF/qvv4aqjX0pUn4A8vNh/cy3YIK26MM2i74hof+Cdbw38zEAVu5cybbkMCetBbKKdQOfL96iry2B7/4Iq5/UAj/879qCN2l8DQZDC3HIC/3o0QA38Yesp3C5IC8PtuSkAZHwyt0LvX1/buFcAMavBbpbQu/xIE4r8dmqh2H1YzolwYDrYeht4DZTUg0GQ8vSpDAOEZkoIj+KyGoR+UMD9Q+JyGLrtVJESm11F4rIKut1YXN2vjkpCnema1dwOMDl0DNga/EQVjFXyp6EHkAU5JcDxcXgcUPpUhxBLfqOjf/S+dpPXQJH/s2IvMFgOCDs0aIXESfwGHASUAQsEJG37Wu/KqWus7W/BjjC2u4A3AaMQEejL7KO3dWsd9EMrAl0J9/K5zV78jPcylbKXC4IxoT+V56RfOYoiTsuUehT60C6AoN/gJ+FYOYwHKGrgFycP5kOo05o4TsxGAyGeJpi0Y8CViul1iql6oDpwJm7aT8ZeMXaPhn4UClVYon7h8DE/elwS7GwZnBU6Het2ArAvAHb4tp0dWc0atGP8sK92fBtH+B+4Ce7oNIJI5/A0WEAAI6OR7boPRgMBkNDNEXouwKFtv0iq6weItID6Al8sjfHishUEVkoIguLi4ub0u/mxREkcJuHbT0fjiv2J6yclOzy1hP6gb4w87vBvO5wfRZs8QPPAtcAz+RB38txuPUiJs2S68ZgMBj2kuZWnknA60olLMO0B5RSTyulRiilRuTm5jZzl5qAW68C9anvurjicCg+EibZ5SHkjL+1czLCZDjgiu2QuxauXgp8DJSiZ19B43H0BoPBcABoitBvArrZ9vOtsoaYRMxts7fHth6u2gaLHdbKUhFSXT46uOIt+peqwgzYAE+WQVlY++ij+PTxkVw3BywfvcFgMNhoivIsAPqKSE8R8aDF/O3ERiIyAMgCvrIVvw9MEJEsEckCJlhlbQJrqVhw+aNlj85/NLrtDMRb9CmeJNLd8UK/LBiO5DzTbeqITXoyFr3BYGgD7FHolVJB4Gq0QK8AXlNKLRORO0TkDFvTScB0pZSyHVsC3Il+WCwA7rDK2gRVkXW7nTGL/pqZ10S33XXxFn2KJ4kk1+7DK1PrgE5W+oIEoTc+eoPB0Bo0acKUUuo94L2Esj8l7N/eyLHPoocn2xwRoT/TNZ23GqhPrk6O20/1+PA56wv9tKOm8caKNygsLyRVuSA7G7ZsqS/0xnVjMBhagUNaeaqtxZmOdOkZrcM7DwdAefQ/JamVqXHtUz3JJDlVXNnNwaN4aOJDTOitExOnOHx6ei3EC73EfPUGg8FwIDmklSdi0btceuMv4//CiM4jkDrtY/cGPHHt0zzJJDvihT7fWmowyaXTHKe6kqGbNf5sE3rjnzcYDK3FoS30ZXr9V6dTC73P5WNoh6FxbRSKZYOWAZDqTSGJ+OySDtGuHI9TPxRSPCnQ3Vqn1anFXZxi/PMGg6HVOKTVp2qH9t2ISy8C63V5GZI+JK5NnaeO/579X7oPvh+fK4kuSfHrsjqsmJuw0oKf4k2LWfQletzZ4XIY/7zBYGg1Dl31KS2l6pV3AHD007nofS4fA9IHxDWr89QRcoVIkmrE5WJ899Fx9Q60wIesOWLupNSYRb99u25jXDcGg6EVOXSF/sYbqXpjJgAydiQAXqeXvil9AQiJttQDbh1s7wkBTicqUBN3mohFHwprN5AjOSVm0duE3lj0BoOhtTjk1Oepp2D2bJhb2I0pvAiAIy3ElRnQ9fubyKzV7pyqFD2Jqs5jLRPYmNBbPvpQnY7Fd6ak1nPdpOenk9Eto0Xvy2AwGBrjkFt45PLL9fukAXqu11kj/svFqc+QmQZs/h/l5QDDKM/YRXplEsqy7D0hwOWCeha9JfQ1+gHhTEmFtDQYOBCu07lzxt0xjuNvPb6lb81gMBga5JCz6CP8b7UedL3ypMfJlDJO2wQ1Q+8iuGURAOXpeu0UZ0j71t2WRd+l9+a480SF3h8Rer06FcuXw6WX6jYuB+6k+EyYBoPBcKA4pIRe2ULga4P6n5nM5FLWuHrzXjXQ4zwCdbq8Iq0CiAm9EsDpJCNzO7d98QMF4wqAmNBf3kFPmJrQbWxL34bBYDDsFYeU0NfZMkvmJVeyhKH0S1lJlVPntPGm9SLo0hEzEaF3BbUlXudEx8UHK8CdHstIaQ3Gjgp1Qt0O3Tv1PzA3YzAYDE3kkBL6SMqD4cNh8ZS/MZTvSU+uoMrhwe1w4xAHwaRhAPgzygFwWpZ/wIEW+kA5uNJi+Wssi95y7kO6WQfWYDC0LQ5Job/sMujs3gECpAoVyo3Ppa36QKqOkx+ZZ7lu6nRqgwE7gOA6CNVASneb0FsLkVTo9qSlHZB7MRgMhqZySAl9JLdNcjJQWwvdckEUlTijQh909wLgdwWW0AfdLL5vIH1LgLLXwJkEBRfUt+iN0BsMhjbKISX0EYs+ORntsM/U/veysAOvSycgC9ZqC32hp4peQ9bgPzpIl1A5FABl70Cvi8HboWGh93j0y2AwGNoQh1QcfcSiT0lBW/Tp+vZnbPgSn6cPAIEaPRN28s4As679N+PrOpL1XRn8DHBlwLC7ABoWemPNGwyGNsiha9HX1kKaDp0sDen0BwDBGp3KIOgKck8JdMnchmtCHQwCMk8Gj05qJk6dxTJuMNYMxBoMhjZIk4ReRCaKyI8islpE/tBIm3NFZLmILBORl23lIRFZbL3qrTXbYgQqoWZbXFFE6KMWfZq+/V1hcDu1GyfoDyJeAYFPamDmdxPg3DD4gMwx0XNFLXplG4w1Fr3BYGiD7FHoRcQJPAacgrZrJ4vIoIQ2fYGbgGOVUoOBabbqGqXU4dbLvsZsy/LFOfC/TvB6Nmz5AGhgMFavGUJpCHbV7AK068bhsz4WJVz1r8dj58w8NrppXDcGg+FgoSkW/ShgtVJqrVKqDpgOnJnQ5lLgMaXULgCl1Pbm7eZeEvLD1o/A4Ya6Etj6MQDB6lLSk8q0RZ+2E6yVAneFYXuV7nLQH8TptVIKB32sK+4Nlzvgd4A3M3oJY9EbDIaDhaYIfVeg0LZfZJXZ6Qf0E5EvReRrEZloq/OJyEKr/KcNXUBEplptFhYXF+/VDTTIzvmggjDmdUgfAJWrYc0/OT+pE9/cfSQZVbPgnMVw9BoAysNQE9TJyoI1QVxJ1hh1UIdcUgVsIrpiFDRg0ZeXG6E3GAxtkuaKunEBfYGxQD7wuYgMVUqVAj2UUptEpBfwiYgsVUqtsR+slHoaeBpgxIgR8Yuy7gvbPwcE8o5DpfYhWPghrs0zqQun0bvjWlh0SrTph9VEpBrQFr3LlyD0kSQ5NqGPDsbaLXozGGswGNogTbHoNwHdbPv5VpmdIuBtpVRAKbUOWIkWfpRSm6z3tcCnwBH72ec9U7EakvPBk8XiNX1wU4EKBnhs7be8Mf9nuk2Ziy0fj2NCwp0Ea4KxTJNBXzTfPNCwRW9cNwaDoY3TFKFfAPQVkZ4i4gEmAYnRM2+irXlEJAftylkrIlki4rWVHwssb6a+N45/G/g6AjB/eW8AymQQW8ry+WjFabpNCHaqZEAv7P3EaU8A2qKPCL0n6ODfxzzZoEUf57oJh6Gy0gi9wWBok+xR6JVSQeBq4H1gBfCaUmqZiNwhIpEomveBnSKyHJgN3KiU2gkMBBaKyHdW+b1KqQMg9NvBlwfAdz9qwd8mJ1NdDV+utYYPvvdSpkPneeuct/Dd4GP1rNUEagJ4kvTs1kHBNZzfZ37svI1Z9FVV+mFghN5gMLRBmuSjV0q9B7yXUPYn27YCrrde9jZzgaH73829pHY7ZA1j82Z4euZZKP/jHPvLi6muhspQZzhjDVw/irJJ2lJPCaWw4fMN9DyxJ0F/kLQOWrB9QcBhexY2JvSRPDfGR28wGNog7S8FglLg347y5jF2LITCLp78+AqW1MDcuZCTA6T2guo6Sj3a/56GFvZQbUj76JPdeBxufMEAuGxC74p9XKmdUklyBbTQl5XpQiP0BoOhDdL+UiAEyiBcR6k/j1Wr4LbbdPHcufo9qtW1tZS5tdAnh7WvPlgbjEbdJLuSdmvRH/nrI7l61DxEhWGbNQO3U6cWvDGDwWDYN9qf0Pv1xKeVG7WPfvz4+OqZM9FWf10dpS6dwCzZGpQN1YYI1ARwJblIdlpCbxN3+7bT7STZG9IDsVu36sKOHVvklgwGg2F/aIdCr63rJT/m4fHAyJGxqgED4PDDia4pWOIM6JWlAvpjsFv0md500mvRFn2qNYXWkfBxORzxQm8seoPB0AZph0KvLfoPPu/I8OHg88VSxCclWW1qawH4TrYxKHcQISsHfdRHn+TmpbH/4I7ZaDFfsAD+8Q8Qib+WSEzo3W7IyjoAN2gwGAx7R/sbjK3VKRTmfpPDbffqIp9PG/HJyVabujrCAvNVEed1nULQb6UmrgkSqgvh8rk4PHcQlKGFfsAA/UrEbtF36lT/QWAwGA4qAoEARUVF+P3+1u5Ko/h8PvLz83G73U0+pv0IfcgPWz+BsmUAhB1pXHCBrvL5dCqaqNDX1rIyG8pUDUflH0Vwixb62nJt6buSXDF/fKK7xk6i0BsMhoOaoqIi0tLSKCgoQNqg4aaUYufOnRQVFdGzZ88mH9d+XDeBcvjsNNj4GgAdcpOjwu6zUtbYXTffWro8ssvIqEXvL9VPcZfPFRN4+2BsIkboDYZ2hd/vJzs7u02KPICIkJ2dvdf/cbQfoXdZA6a1O6kLeejQIfZFRYQ+ORkoKYGyMkqtsryUvOjygf4y/eG5k9wxoTcWvcFwSNFWRT7CvvSv/Qh9yAkIqBB+v4+cubF0PHEWfXY2HHkk1ZZ7K8mdFLXoa8ss143dot+T0NfVQXGxEXqDwdBmaT9CX1oKfp3SoKo2mVxiee2jFn1SLANyTUToXUnRdWIjFr0raS+EfvNmbdV3TUzRbzAYDHvPrFmz6N+/P3369OHee+9tlnO2H6FPTQVtkFNZl0oOO6JZJ6NC76qLNq/2OnA5XLid7qhFH6jSLpy9suh36SUIjdAbDIb9JRQKcdVVVzFz5kyWL1/OK6+8wvLl+58Hsv1E3SQlRYW+OmLR19aCzxdz3YStRWNPOonqS7uRvOZ1gKiPPoI7yR0bhN3TYGyE/PzmuAuDwdBWmDYNFi9u3nMefjg8/HCj1fPnz6dPnz706tULgEmTJvHWW28xaNCgRo9pCu3Honc4wJrhWl2XrC36mhooL8e3/BsAkkNWlsnrr6fG5yLZbeW4sSz6CHtl0UcwFr3BYNhPNm3aRLdusXWe8vPz2bQpcZ2nvaf9WPQAQScQprrWEvrqanjzTXxFOcCRJAXKdbvcXKo3VpPk0vGW9YS+qT56e26bnJzmuw+DwdD67MbyPthoPxY9QEg/t6rrLNdNTQ14vfjQg6zJtZY/PS+PmkBNzKKvacCid7vhtNPgqKMav549Y1obD8kyGAxtn65du1JYWBjdLyoqomszeAval0UfdgM18a6bsjK8Vr755MVWruLcXKoD1SS5G7bo3cluLdwzZuz+euPGNfcdGAyGQ5iRI0eyatUq1q1bR9euXZk+fTovv/zyfp+3SRa9iEwUkR9FZLWI/KGRNueKyHIRWSYiL9vKLxSRVdbrwv3u8e5QOntZlT+FFKq062bbtqhFn7R0nm7n81EdqG7Uovdl+pp2vfR0OP10uOWW5um/wWA4pHG5XDz66KOcfPLJDBw4kHPPPZfBgwfv/3n31EBEnMBjwElAEbBARN62r/0qIn2Bm4BjlVK7RCTPKu8A3AaMABSwyDp21373vEH0IrDVdcm4CGqLfvt2fGj/eTLV0ZY1wRqyfDrbZKJF7033Nv2S77yzn302GAyGGKeeeiqnnnpqs56zKRb9KGC1UmqtUqoOmA6cmdDmUuCxiIArpbZb5ScDHyqlSqy6D4GJzdP1BhBtiVfXJeMkZBN6y6KnBvr3121sFr09vNLpceJwtq+hC4PBcGjTFEXrChTa9ousMjv9gH4i8qWIfC0iE/fiWERkqogsFJGFxcXFidVNx6F97tW1CRZ9L33J5DkfwLffAsQPxtoseldS+xq2MBgMhuYyXV1AX2AsMBl4RkQym3qwUupppdQIpdSI3Nzcfe+FUwt31KKvrtZCn63Lk7J80RSW1YGGwyvdyU3P8WwwGAwHA00R+k1AN9t+vlVmpwh4WykVUEqtA1aihb8pxzYfVgbLeha9NbgazUcPjQ7GupOM0BsMhvZFU4R+AdBXRHqKiAeYBLyd0OZNtDWPiOSgXTlrgfeBCSKSJSJZwASrrGVw6zDK6rpkHIRhyxaoreXYoRVMnAhdusSa1gRrGgyvNK4bg8HQ3tij0CulgsDVaIFeAbymlFomIneIyBlWs/eBnSKyHJgN3KiU2qmUKgHuRD8sFgB3WGUtg0db9P46HwKwZAkAw45LZ+ZM8FrBNKFwiLpQXdSi95f5o5E2xqI3GAztjSaZr0qp94D3Esr+ZNtWwPXWK/HYZ4Fn96+bTcSbAUBtwFpK6rvv9Hu/fnHNaoI1gE5RHA6FqS6uJm9IHtuWbDMWvcFgaFV+9atfMWPGDPLy8vj++++b5ZztK44wScfFV9el6tzEq1frGa69zexwOQAAELxJREFUe8c1qw7oePpkdzJV26tQYUV6t3TAWPQGg6F1ueiii5g1a1aznrN9ma8pw3nlofP4es0YHV3j90NBQcxnY2EX+sqtlQAkZen/AoxFbzAYoFWyFANw/PHHs379+ma9bvuy6LOymfvZsYjDFQuxSXDbgI6hB72MYETovRnGR28wGNon7cZ8ra2Fz2vGsO6I3jgLXbEFQwYOjGsXVmFu/+x2QPvoK7dooe88vDMAXUZ1wWAwGNpRluL2I/Tl5TBhogPoqtfp3rhRVxx/PABKKUSEZxY9w2vLXmN8z/EcnX80K7euBGDo5KHkDc6jy0gj9AaDoX3Rblw3Ltsjy776nzruOO6Zcw8FjxTwytJXuP6D6xlXMI4Pp3xIx9SOVGypwJfpw+Vz0XVU1//f3v0HR13ndxx/vsludslPQBJMXX7p6UBicVHEo7UWdPDQcUSMZ/HHFKfeOGfrKNrenAwzonY6d+VGC51hemfVO6steGfvrqiUKzVwvUHx/EFQRNEIERIBc4SAhCTmx7t/fD/ZLGt+rOwm383X92NmJ9/9fvf74cUnyTuf/ex3P4vYuvLGmIAJTKEPJ02tJxf9d7s/ZWXNSg4cP8Ctv7yVWEmM9dXrEwW99XArRWcXjXBaY4zp3y233MK8efPYu3cvsViMp556KuM2AzN186UR/b590NPD4ZMfA7BkxhL2t+znxVtepLywnIOvHSR2WYxTfzhFYXmhP6GNMSbF+vXrs95mYAr9l0b006cDcOqDdwF46M8fIn52HICdP93Jxr/aSPWGak4dPcWE8yaMdFxjjBkxgZm6GTMGKG6E6DHaK2p4ZNsjALR+0QqQWO4A4K2fvAVAc10zbc1tRCek+YlSxhgzCgWm0Ne37Ie/jcGFGziw4Coe/u3DHGs7RmunV+gLw970zMnDJ2l83VtA81jdMdqa2xg7YaxvuY0xZrgFZupm2rhpyPEp6HlbGNNVQE/oFN/+xbcpiXhLGxTme4V+/9b9gPdxgYd2HqKrrcsKvTEm0AJT6EWE0IGFdJ7/Avntk2kv2ssr+19JHO8d0ddvrSdSGqHqL6p4+4m3ASg4q6DfNo0xJggCM3UDkN+wEKLHaS/ae9r+iccnsvX7W9Ee5cDvDjD1z6ZSXlWeOG4jemNMkAWq0Edb4ontG2bcQHmhV8xvf+Z2XnvsNZo/bqb1s1ZKp5ZSVtn3kYVW6I0xueLgwYMsWLCAyspKqqqqWLt2bcZtBqrQR05NS2zPi81jzh/NAWBcs/fxtZ2tnXR83kF+cT5lVVbojTG5JxQK8dhjj7Fnzx527NjBunXr2LNnT2ZtZilbTsjP61uOuLywnNJIKQWtffPvrU2t9HT2kF+Uf9q7Ya3QG2NSLd+8nNrD2V2nOH52nDWLBl8traKigooKb5HF4uJiZs6cSWNjI5WVlWf876Y1oheRRSKyV0TqROTBfo7fISJNIlLrbt9JOtadtD/1s2azKhQCvvBedC0rKKM0UsqkI5MSxz//9HMAIsWR09a0sUJvjMlF9fX17Ny5k8suuyyjdoYc0YtIHrAOWAg0AG+IyEZVTX0u8byq3tNPE22qGu9nf9aFw0BHMeS3eiP6aCmFrX3LG3ze6BX6/OJ8wCvwbc1thAttDXpjzOmGGnkPt5MnT1JdXc2aNWsoKSnJqK10pm7mAnWqug9ARDYAi4HMJo2GQSgENJ9HJHyM0mgpJZGS0wr9icYTAOQXeYX+u7u+S9OeJlux0hiTUzo7O6murua2227jxhtvzLi9dAr9OcDBpPsNQH/PI6pF5ArgQ+B+Ve09JyoibwJdwA9V9depJ4rIXcBdAFOmTPkK8U8XDsPc/1jFtR2vUn63m6M/1TdHf/JT92lSxd5cfkmshJJYZn8pjTEmm1SVO++8k5kzZ/LAAw9kpc1sXXXzIjBNVWcBW4Bnko5NVdU5wK3AGhE5L/VkVX1CVeeo6pyysrLUw2kLhWBaxzEAPvntJ4mpm47iDiRP+kb0burGGGNyzfbt23n22WepqakhHo8Tj8fZtGlTRm2mM6JvBCYn3Y+5fQmqejTp7pPA6qRjje7rPhHZBswGPj7DvIMKh6GJiQAc2XWE0rl9hb40VMqJhtOnbowxJtdcfvnlqGpW20xnRP8GcL6ITBeRfGApcNrVMyJSkXT3euB9t3+8iETc9kTgTxnGuf1QCBRvvv3Q24cSI/r24nYiJZHE58P2Tt0YY8zXwZAjelXtEpF7gN8AecDTqvqeiDwKvKmqG4F7ReR6vHn4ZuAOd/pM4Cci0oP3R+WH/VytkzXemvRdABx55wgXRS6isLWQ1rJWIvl9xd2mbowxXydpvWFKVTcBm1L2PZS0vQJY0c95rwJ/nGHGtHmfMuUV+vaWdqJ5UQpbC2kqaiLa07fmvI3ojTFfJ4FaAiEchpAr9NqtFH9RTLQjyuSpk4mUeMVd8oS8SN5gzRhjTKAEqtCHQhCiO3H/5NvenPyti25NFPrUd8UaY0zQBarQJ4/oAT741QcAfOOqb5Bf4s3L2/y8MebrJlCF3hvRJxX6X39AWVUZRZOKOOuCswA4cfCEX/GMMWZI7e3tzJ07l4suuoiqqipWrVqVcZuBKvSpI/r2Y+1M/hPvLQCX3n0pAKGxgVqw0xgTMJFIhJqaGnbt2kVtbS2bN29mx44dGbUZqKoXCoHQhUaiSEc7QGKJg3BBmHs/vpeerh4/IxpjRou3lsOx7C5TzPg4XDL4YmkiQlGRt4x6Z2cnnZ2dGb+uGMwRfWHfQmaFk/q2x587PjGFY4wxuaq7u5t4PE55eTkLFy4c/mWKR5PEdfRFhdDsrcpQNKlo0HOMMaZfQ4y8h1NeXh61tbW0tLSwZMkSdu/ezYUXXnjG7QVqRD9mjDeilwFG9MYYM5qMGzeOBQsWsHnz5ozaCVShF4EwncjYvne+2ojeGDOaNDU10dLSAkBbWxtbtmxhxowZGbUZqKkbEW9EPyacl3jblI3ojTGjyaFDh1i2bBnd3d309PRw8803c91112XUZiALveT3/bfyC+0NUsaY0WPWrFns3Lkzq20GbuomRBcSCtTfL2OMyUhgKmJ7SzuR7a+SR0/v5TfGGGMIUKFHIPL67wDQUIjvNX0v65/SYowxo1FgCn20tG+9efJCFEwsGPjBxhjzNRKoOXodO9bbsKkbY4xJSKvQi8giEdkrInUi8mA/x+8QkSYRqXW37yQdWyYiH7nbsmyGT6UF3jXzaoXeGGMShiz0IpIHrAOuASqBW0Sksp+HPq+qcXd70p07AVgFXAbMBVaJyPispU+hve+IzbNCb4wZvbq7u5k9e3bG18/3SmdEPxeoU9V9qvoFsAFYnGb73wK2qGqzqh4DtgCLzixqGlyh167uIR5ojDG5a+3atcycOTNr7aUz9D0HOJh0vwFvhJ6qWkSuAD4E7lfVgwOce07qiSJyF3AXwJQpU9JL3p/eQt/aeuZtGGMMsHn5Zg7XHs5qm2fHz2bRmsHHug0NDbz88susXLmSxx9/PCv/brZejH0RmKaqs/BG7c98lZNV9QlVnaOqc8rKys44RM/sS7yNCy444zaMMcZPy5cvZ/Xq1YwZk71rZdIZ0TcCk5Pux9y+BFU9mnT3SWB10rnzU87d9lVDpksmlfMwq3jElpw3xmRoqJH3cHjppZcoLy/nkksuYdu2bVlrN50/GW8A54vIdBHJB5YCG5MfICIVSXevB953278BrhaR8e5F2KvdvmHR+yEs9j4pY8xotH37djZu3Mi0adNYunQpNTU13H777Rm3O2ShV9Uu4B68Av0+8HNVfU9EHhWR693D7hWR90RkF3AvcIc7txn4e7w/Fm8Aj7p9w8IKvTFmNPvBD35AQ0MD9fX1bNiwgSuvvJLnnnsu43bTug5RVTcBm1L2PZS0vQJYMcC5TwNPZ5AxbVH35thweCT+NWOMGR0CdcH5ffdBczPcf7/fSYwxJjPz589n/vz5WWkrUIW+oAB+9CO/UxhjTG4J1Fo3xhhjvswKvTHGJMn15c3PJJ8VemOMcaLRKEePHs3ZYq+qHD16lGg0OvSDkwRqjt4YYzIRi8VoaGigqanJ7ygDikajxGKxr3SOFXpjjHHC4TDTp0/3O0bW2dSNMcYEnBV6Y4wJOCv0xhgTcJJrry6LSBPwSQZNTAT+kKU4w2U0ZATLmW2WM7tGQ86RzDhVVftd5z3nCn2mRORNVZ3jd47BjIaMYDmzzXJm12jImSsZberGGGMCzgq9McYEXBAL/RN+B0jDaMgIljPbLGd2jYacOZExcHP0xhhjThfEEb0xxpgkVuiNMSbgAlPoRWSRiOwVkToRedDvPMlEpF5E3hWRWhF50+2bICJbROQj93W8D7meFpHPRGR30r5+c4nnn13/viMiF/uc82ERaXR9Wisi1yYdW+Fy7hWRb41QxskislVE9rjPT77P7c+p/hwkZ671Z1REfi8iu1zOR9z+6SLyusvzvIjku/0Rd7/OHZ/mc86ficj+pP6Mu/3+/B6p6qi/AXnAx8C5QD6wC6j0O1dSvnpgYsq+1cCDbvtB4B99yHUFcDGwe6hcwLXAfwMCfBN43eecDwN/189jK933PwJMdz8XeSOQsQK42G0XAx+6LDnVn4PkzLX+FKDIbYeB110//RxY6vb/GLjbbf818GO3vRR4foT6c6CcPwNu6ufxvnzfgzKinwvUqeo+Vf0C2AAs9jnTUBYDz7jtZ4AbRjqAqv4f0Jyye6Bci4F/U88OYJyIVPiYcyCLgQ2q2qGq+4E6vJ+PYaWqh1T1bbf9OfA+cA451p+D5ByIX/2pqnrS3Q27mwJXAi+4/an92dvPLwBXiYj4mHMgvnzfg1LozwEOJt1vYPAf3pGmwP+IyFsicpfbN0lVD7ntw8Akf6J9yUC5crGP73FPf59OmvryPaebNpiNN7rL2f5MyQk51p8ikicitcBnwBa8ZxMtqtrVT5ZETnf8OHCWHzlVtbc//8H15z+JSCQ1pzMi/RmUQp/rLlfVi4FrgL8RkSuSD6r3nC7nrnPN1VzOvwDnAXHgEPCYv3E8IlIE/CewXFVPJB/Lpf7sJ2fO9aeqdqtqHIjhPYuY4XOkfqXmFJELgRV4eS8FJgDf9zFiYAp9IzA56X7M7csJqtrovn4G/Arvh/ZI71M29/Uz/xKeZqBcOdXHqnrE/YL1AP9K33SCbzlFJIxXPP9dVX/pdudcf/aXMxf7s5eqtgBbgXl4Ux29H5iUnCWR0x0vBY76lHORmyJTVe0AforP/RmUQv8GcL57RT4f78WYjT5nAkBECkWkuHcbuBrYjZdvmXvYMuC//En4JQPl2gj8pbtq4JvA8aQpiRGXMq+5BK9Pwcu51F2FMR04H/j9COQR4CngfVV9POlQTvXnQDlzsD/LRGSc2x4LLMR7PWErcJN7WGp/9vbzTUCNewblR84Pkv64C97rCMn9OfK/RyPxiu9I3PBezf4Qbx5vpd95knKdi3fVwi7gvd5sePOHrwAfAf8LTPAh23q8p+mdeHOFdw6UC+8qgXWuf98F5vic81mX4x28X56KpMevdDn3AteMUMbL8aZl3gFq3e3aXOvPQXLmWn/OAna6PLuBh9z+c/H+0NQBvwAibn/U3a9zx8/1OWeN68/dwHP0XZnjy/fdlkAwxpiAC8rUjTHGmAFYoTfGmICzQm+MMQFnhd4YYwLOCr0xxgScFXpjjAk4K/TGGBNw/w+ULVT33ghm5gAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":809},"id":"hQf_P3nE5gy4","executionInfo":{"status":"ok","timestamp":1617353326461,"user_tz":-330,"elapsed":2262,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"7d4a4f4f-a44c-4ca3-b84d-b1ca6b12a404"},"source":["import matplotlib.pyplot as plt\n","\n","plt.title(\"Training accuracy vs epoch\")\n","colors = [\"red\",\"blue\",\"green\",\"orange\",'purple']\n","for i in range(0,5):\n","  x_axis = np.arange(len(train_acc_fin[i]))\n","  y_axis= train_acc_fin[i]\n","  plt.plot(x_axis, y_axis, color = colors[i],label=str(i));\n","  plt.legend()\n","plt.savefig(\"/content/drive/My Drive/graph/Protein/Train_accuracy.png\")\n","plt.show()\n","\n","plt.title(\"Training f1 score vs epoch\")\n","colors = [\"red\",\"blue\",\"green\",\"orange\",'purple']\n","for i in range(0,5):\n","  x_axis = np.arange(len(train_f1_fin[i]))\n","  y_axis= train_f1_fin[i]\n","  plt.plot(x_axis, y_axis, color = colors[i],label=str(i));\n","  plt.legend()\n","plt.savefig(\"/content/drive/My Drive/graph/Protein/Train_f1_score.png\")\n","plt.show()\n","\n","\n","plt.title(\"Training roc_auc score vs epoch\")\n","colors = [\"red\",\"blue\",\"green\",\"orange\",'purple']\n","for i in range(0,5):\n","  x_axis = np.arange(len(train_roc_auc_fin[i]))\n","  y_axis= train_roc_auc_fin[i]\n","  plt.plot(x_axis, y_axis, color = colors[i],label=str(i));\n","  plt.legend()\n","plt.savefig(\"/content/drive/My Drive/graph/Protein/Train_roc_auc_score.png\")\n","plt.show()\n"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"z0XVssU20gMo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617353902531,"user_tz":-330,"elapsed":2160,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}},"outputId":"0a9a7bdb-4c6a-4799-cbd9-be08a085a01a"},"source":["model.load_state_dict(torch.load(config['path']+f'model_{fold}'))"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"cVH2C2aAPVdr","executionInfo":{"status":"ok","timestamp":1617353923783,"user_tz":-330,"elapsed":960,"user":{"displayName":"Rafa Beneir","photoUrl":"","userId":"08465001590311582184"}}},"source":["scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max', verbose=True) #scheduler_on='valid_acc'\n","\n","if scheduler is not None:\n","    if scheduler == 'valid_acc':\n","        scheduler.step(valid_acc_list[-1])"],"execution_count":23,"outputs":[]}]}